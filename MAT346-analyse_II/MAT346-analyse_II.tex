\documentclass{report}
\usepackage[letterpaper,portrait,margin=2cm]{geometry}
\usepackage{titlesec}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{indentfirst}
\usepackage{dsfont}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows.meta}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{xfrac}
\usepackage{fancyhdr}
\usepackage[french]{babel}
\usepackage[dvipsnames]{xcolor}

\hypersetup{
	colorlinks=false
}

\allowdisplaybreaks

\fancyfoot{}
\fancyhead{}
\fancyhead[l]{MAT346 - Analyse II}
\fancyhead[r]{\leftmark}
\fancyfoot[c]{\thepage}
\renewcommand{\headrulewidth}{.4pt}
\renewcommand{\footrulewidth}{0pt}

\setcounter{tocdepth}{3}

\pagestyle{fancy}

\title{MAT346 - Analyse II

Donn\'e par Mario Lambert}
\author{Julien Houle}
\date{Automne 2025}

\NewDocumentCommand{\bornee}{O{a,b}}{\mathcal{B}\left[ #1 \right]}
\NewDocumentCommand{\continue}{O{a,b}}{\mathcal{C}\left[ #1 \right]}
\NewDocumentCommand{\riemann}{O{a,b}}{\mathcal{R}\left[ #1 \right]}
\NewDocumentCommand{\partitions}{O{a,b}}{\Omega\left[ #1 \right]}
\NewDocumentCommand{\msup}{mO{a,b}}{\overline{M}\left( #1,\left[ #2 \right] \right)}
\NewDocumentCommand{\minf}{mO{a,b}}{\underline{M}\left( #1,\left[ #2 \right] \right)}
\NewDocumentCommand{\ssup}{mO{\Delta}}{\overline{S}\left( #1,#2 \right)}
\NewDocumentCommand{\sinf}{mO{\Delta}}{\underline{S}\left( #1,#2 \right)}
\NewDocumentCommand{\srie}{mO{\Delta}O{\{\bar{x}_i\}}}{S\left( #1,#2,#3 \right)}

\newcommand*{\Ssup}[1]{\overline{S}(#1)}
\newcommand*{\Sinf}[1]{\underline{S}(#1)}

\newcommand*{\dsum}[4]{\displaystyle\sum_{#1=#2}^{#3}#4}
\newcommand*{\dlim}[3]{\displaystyle\lim_{#1 \to #2}#3}
\newcommand*{\dint}[3]{\displaystyle\int_{#1}^{#2}#3}

\newcommand*{\raffinement}[2]{#1 \vee #2}
\newcommand*{\norme}[1]{\left\| #1 \right\|}
\newcommand*{\abs}[1]{\left| #1 \right|}

\newcommand*{\convuni}{\rightrightarrows}

\newcommand*{\eps}{\varepsilon}

\newcommand*{\lte}{\leqslant}
\newcommand*{\gte}{\geqslant}

\newcommand*{\reels}{\mathbb{R}}
\newcommand*{\entiers}{\mathbb{Z}}
\newcommand*{\rationels}{\mathbb{Q}}
\newcommand*{\naturels}{\mathbb{N}}
\newcommand*{\complexes}{\mathbb{C}}

\newcommand*{\sech}{\mathrm{sech}}

\renewcommand{\thesection}{ \arabic{chapter}.\arabic{section}}
\renewcommand{\thesubsection}{}
\renewcommand{\thesubsubsection}{}

\titleformat{\chapter}[hang]{\bfseries\huge\centering}{Chapitre \arabic{chapter}}{1em}{}[]
\titleformat{\section}[hang]{\bfseries\large}{Section\thesection}{1em}{}[]
\titleformat{\subsection}[hang]{\bfseries\normalsize}{}{0pt}{}[]
\titleformat{\subsubsection}[hang]{\slshape\normalsize}{}{0pt}{}[]

\newtheorem*{thm}{Th\'eor\`eme}
\newtheorem*{lem}{Lemme}
\newtheorem*{prop}{Proposition}
\newtheorem*{coro}{Corollaire}
\theoremstyle{definition}
\newtheorem*{defin}{D\'efinition}
\theoremstyle{remark}
\newtheorem*{exem}{Exemple}
\newtheorem*{exer}{Exercice}
\newtheorem*{nota}{Notation}
\newtheorem*{rema}{Remarque}
\newtheorem*{rapp}{Rappel}

\begin{document}
	\maketitle
	\tableofcontents
	\pagenumbering{roman}
	\newpage
	\pagenumbering{arabic}

	\chapter{Int\'egration}
	\section{Int\'egrales de Riemann}

	\begin{nota}
		~

		$\bornee[c,d]=\left\lbrace f:[a,b] \to \reels \middle| f \text{ est born\'ee} \right\rbrace$.

		$\riemann=\left\lbrace f:[a,b] \to \reels \middle| f \text{ est born\'ee et int\'egrable} \right\rbrace$.

		$\continue=\left\lbrace f:[a,b] \to \reels \middle| f \text{ est born\'ee et continue} \right\rbrace$.
	\end{nota}

	On suppose nos fonctions born\'ees.

	\begin{defin}
		~

		\begin{enumerate}[label=\alph*)]
			\item Une partition de $[a,b]$ est un ensemble fini de points $\Delta=\{x_0,x_1,\dotsc,x_n\} \subseteq [a,b]$ t.q. $a=x_0 < x_1 < x_2 < \dotsc < x_{n-1} < x_n=b$.
			\item L'ensemble des partitions de $[a,b]$ est $\partitions$.
			\item On dit $\Delta'$ est \emph{plus fine} que $\Delta$, not\'e $\Delta' \gte \Delta$, si $\Delta' \supseteq \Delta$.
			\item \emph{Raffinement commun} de $\Delta_1$ et $\Delta_2$, not\'e $\raffinement{\Delta_1}{\Delta_2}$, est la partition de $[a,b]$ form\'ee de $\Delta_1 \cup \Delta_2$ ordonn\'es.
			\item La \emph{norme} de $\Delta$, not\'ee $\norme{\Delta}$, est $\norme{\Delta}=\max\limits_{i=1}^{n}\abs{x_i-x_{i-1}}$.
			\item
			\begin{align*}
				\msup{f}[x_{i-1},x_1]&= \sup\limits_{x \in \left[ x_{i-1},x_1 \right]}f(x)\\
				\minf{f}[x_{i-1},x_1]&= \inf\limits_{x \in \left[ x_{i-1},x_1 \right]}f(x)
			\end{align*}
		\end{enumerate}
		\begin{rema}
			\begin{align*}
				\norme{x}&\gte0\\
				\norme{\lambda x}&=\abs{\lambda} \norme{x}\\
				\norme{x+y}&= \norme{x} + \norme{y}
			\end{align*}
		\end{rema}
	\end{defin}

	\begin{defin}
		~

		\begin{enumerate}[label=\alph*)]
			\item La \emph{somme de Riemann par exc\`es} (ou sup\'erieure) de $f$ pour la partition $\Delta$ est
			\[
			\ssup{f}= \displaystyle\sum_{i=1}^{n}\msup{f}[x_{i-1},x_i] \cdot (x_i-x_{i-1})
			\]
			\item La \emph{somme de Riemann par d\'efaut} (ou inf\'erieure) de $f$ pour la partition $\Delta$ est
			\[
			\sinf{f}= \displaystyle\sum_{i=1}^{n}\minf{f}[x_{i-1},x_i] \cdot (x_i-x_{i-1})
			\]
		\end{enumerate}
	\end{defin}

	\newpage
	\begin{prop}
		~

		\begin{enumerate}[label=\alph*)]
			\item
			\[
			\minf{f} \cdot (b-a) \lte \sinf{f}, \forall\Delta\in\partitions
			\]
			\item
			\[
			\sinf{f} \lte \ssup{f}
			\]
			\item
			\[
			\ssup{f} \lte \msup{f} \cdot (b-a)
			\]
		\end{enumerate}
	\end{prop}

	\begin{prop}
		Si $\Delta'\gte\Delta$, alors $\ssup{f}[\Delta']\lte\ssup{f}$.
		\begin{proof}~

			Sans perte de g\'en\'eralit\'e, supposons
			\[
			\Delta:a=x_0<x_1<\dotsc<x_{i-1}<x_i<\dotsc<x_n=b
			\]
			\[
			\Delta':a=x_0<x_1<\dotsc<x_{i-1}<\bar{x}<x_i<\dotsc<x_n=b
			\]

			On a
			\begin{align*}
				\ssup{f}-\ssup{f}[\Delta']&= \left[ \msup{f}[x_{i-1},x_i] \cdot (x_i-x_{i-1}) \right]\\
				&- \left[ \msup{f}[x_{i-1},\bar{x}] \cdot (\bar{x}-x_{i-1}) + \msup{f}[\bar{x},x_i] \cdot (x_i-\bar{x}) \right]\\
				&= (x_i-\bar{x}) \left[ \msup{f}[x_{i-1},x_i] - \msup{f}[\bar{x},x_i] \right]\\
				&+ (\bar{x}-x_{i-1}) \left[ \msup{f}[x_{i-1},x_i] - \msup{f}[x_{i-1},\bar{x}] \right]\\
				&\gte 0
			\end{align*}
		\end{proof}
	\end{prop}

	\begin{prop}
		Si $\Delta'\gte\Delta$, alors $\sinf{f}[\Delta'] \gte \sinf{f}$
		\begin{proof}~

			\begin{center}
				\begin{tikzpicture}
					\draw[->] (0,-.1) -- (0,2) node[above] {$y$};
					\draw[->] (-.1,0) -- (6.1,0) node[right] {$x$};
					\node[anchor=north] (x0) at (1,0) {$x_0$};
					\node[anchor=north] (xi-1) at (2,0) {$x_{i-1}$};
					\node[anchor=north] (x) at (3,0) {$\bar{x}$};
					\node[anchor=north] (xi) at (4,0) {$x_i$};
					\node[anchor=north] (xn) at (5,0) {$x_n$};
					\draw plot[domain=0:6] (\x,.3*\x) node[above left] {$f$};
					\node (y0) at (1,.3) {};
					\node (yi-1) at (2,.6) {};
					\node (y) at (3,.9) {};
					\node (yi) at (4,1.2) {};
					\node (yn) at (5,1.5) {};
					\filldraw[fill=red, fill opacity=.3] (yi-1) rectangle (xi.north);
					\filldraw[fill=blue, fill opacity=.3] (yi-1) rectangle (x.north);
					\filldraw[fill=blue, fill opacity=.3] (y) rectangle (xi.north);
				\end{tikzpicture}
			\end{center}
		\end{proof}
		\begin{rema}
			$\sinf{f}=-\ssup{-f}$.
		\end{rema}
		\begin{coro}
			$\forall \Delta_1,\Delta_2 \in \partitions, \sinf{f}[\Delta_1] \lte \ssup{f}[\Delta_2]$
			\begin{proof}~

				On a $\raffinement{\Delta_1}{\Delta_2} \gte \Delta_1$. Ainsi,
				\begin{align*}
					\sinf{f}[\Delta_1]&\lte \sinf{f}[\raffinement{\Delta_1}{\Delta_2}]\\
					&\lte \ssup{f}[\raffinement{\Delta_1}{\Delta_2}]\\
					&\lte \ssup{f}[\Delta_2]
				\end{align*}
			\end{proof}
		\end{coro}
	\end{prop}

	\newpage
	\begin{defin}
		~

		\begin{enumerate}[label=\alph*)]
			\item La somme par d\'efaut de $f$ est $\Sinf{f}=\sup\limits_{\Delta\in\partitions}\sinf{f}$.
			\item La somme par exc\`es de $f$ est $\Ssup{f}=\inf\limits_{\Delta\in\partitions}\ssup{f}$.
		\end{enumerate}
	\end{defin}

	\begin{thm}
		$\Sinf{f} \lte \Ssup{f}$
		\begin{proof}~

			Soit $\Delta_1 \in \partitions$

			$\Sinf{f}=\sup\sinf{f}$ est le plus petit majorant des $\sinf{f}$ avec $\Delta \in \partitions$.

			Du corollaire pr\'ec\'edant, on a que $\sinf{f} \lte \ssup{f}[\Delta_1]$.

			Donc, $\ssup{f}[\Delta_1]$ est un majorant des $\sinf{f}$.

			Ainsi, $\Sinf{f} \lte \ssup{f}[\Delta_1]$.

			De m\^eme, $\Ssup{f}=\inf\ssup{f}$ est le plus grand minorant des $\ssup{f}$ avec $\Delta \in \partitions$.

			Comme $\Sinf{f}$ est un minorant des $\ssup{f}$, on a que $\Sinf{f} \lte \Ssup{f}$.
		\end{proof}
	\end{thm}

	\begin{defin}
		~

		Soit $f \in \bornee$. On dit que $f$ est \emph{int\'egrable au sens de Riemann sur $[a,b]$} si $\Sinf{f}=\Ssup{f}$ et on note $f \in \riemann$. La valeur commune de $\Sinf{f}$ et $\Ssup{f}$ est not\'ee $\dint{a}{b}{f(x)dx}$.
	\end{defin}

	\subsection{Crit\`ere d'int\'egrabilit\'e}
	\begin{thm}[Crit\`ere d'int\'egrabilit\'e]
		~

		Soit $f \in \bornee$. Alors $f \in \riemann$ si, et seulement si, $\left( \forall \eps >0 \right) \left( \exists\Delta = \Delta(\eps) \in \partitions \right)$ t.q. $\ssup{f}-\sinf{f} < \eps$.
		\begin{proof}~

			\begin{itemize}
				\item[$(\Rightarrow)$] Supposons $f \in \riemann$.

				Soit $\eps>0$.

				On a $\dint{a}{b}{f}=\Ssup{f}=\inf\ssup{f}$.

				Comme $\Ssup{f}+\dfrac{\eps}{2}$ ne peut minorer $\ssup{f}$, alors $\exists\Delta_1 \in \partitions$ t.q. $\ssup{f}[\Delta_1] < \Ssup{f}+\dfrac{\eps}{2}$.

				De m\^eme, $\dint{a}{b}{f}=\Sinf{f}=\sup\sinf{f}$.

				Comme $\Sinf{f}-\dfrac{\eps}{2}$ ne peut majorer $\sinf{f}$, alors $\exists\Delta_2 \in \partitions$ t.q. $\sinf{f}[\Delta_2] > \Sinf{f}-\dfrac{\eps}{2}$.

				Posons $\Delta = \Delta(\eps) = \raffinement{\Delta_1}{\Delta_2}$.

				On a
				\begin{align*}
					\ssup{f} - \sinf{f}&\lte \ssup{f}[\Delta_1] - \sinf{f}[\Delta_2]\\
					&< \Ssup{f} + \dfrac{\eps}{2} - \left( \Sinf{f} - \dfrac{\eps}{2} \right)\\
					&= \left( \Ssup{f} - \Sinf{f} \right) + \eps\\
					&= \eps
				\end{align*}
				\newpage
				\item[$(\Leftarrow)$] Soit $\eps>0$.

				Alors $\exists\Delta$ t.q. $\ssup{f}-\sinf{f}<\eps$.

				Mais alors,
				\begin{align*}
					\eps&> \ssup{f}-\sinf{f}\\
					&\gte \Ssup{f}-\Sinf{f}\\
					&\gte 0
				\end{align*}

				Du th\'eor\`eme du sandwich, $\Ssup{f}=\Sinf{f}$, car $\eps>0$ est arbitraire.

				Donc, $f \in \riemann$.
			\end{itemize}
		\end{proof}
		\begin{coro}
			S'il existe $\Delta \in \partitions$ t.q. $\ssup{f}=\sinf{f}$, alors $f \in \riemann$.
		\end{coro}
	\end{thm}
	\begin{thm}
		Toute fonction continue sur $[a,b]$ est int\'egrable sur $[a,b]$.
		\begin{proof}~

			Soit $f \in \continue$.

			Soit $\eps>0$.

			Par la proposition d'Archim\`ede, $\exists n\in\entiers$ t.q. $n\eps>b-a$.

			\begin{rapp}~

				$f$ est uniform\'ement continue sur $[a,b]$ si $\left( \forall\eps>0 \right) \left( \exists\delta>0 \right)$ t.q. pour $x,y \in [a,b]$, $\abs{x-y}<\delta \Rightarrow \abs{f(x)-f(y)}<\eps$.
			\end{rapp}
			\begin{rapp}~

				Si $f$ est continue sur $[a,b]$, alors $f$ est uniform\'ement continue sur $[a,b]$.
			\end{rapp}

			Comme $f \in \continue$, elle est uniform\'ement continue sur $[a,b]$.

			Alors, $\exists\delta>0$ t.q. pour $x,y \in [a,b]$, $\abs{x-y}<\delta \Rightarrow \abs{f(x)-f(y)}<\frac{1}{n}$.

			Soit donc $\Delta \in \partitions: a=x_0<x_1,\dotsc<x_n=b$ avec $\norme{\Delta}<\delta$.

			Alors, $\msup{f}[x_{i-1},x_i] - \minf{f}[x_{i-1},x_i]<\frac{1}{n}$.
			\begin{rema}
				$\msup{f}[x_{i-1},x_i] - \minf{f}[x_{i-1},x_i]$ peut \^etre not\'e $\mathrm{osc}_f(\left[ x_{i-1},x_i \right])$.
			\end{rema}

			On obtient
			\begin{align*}
				\ssup{f}-\sinf{f}&= \sum_{i=1}^{n}\left[ \msup{f}[x_{i-1},x_i] - \minf{f}[x_{i-1},x_i] \right] \left( x_i-x_{i-1} \right)\\
				&< \dfrac{1}{n} \sum_{i=1}^{n}\left( x_i-x_{i-1} \right)\\
				&=\dfrac{b-a}{n}\\
				&< \eps
			\end{align*}

			Donc $f \in \riemann$.
		\end{proof}
	\end{thm}
	\begin{thm}
		Toute $f:[a,b] \to \reels$ monotone est int\'egrable.
		\begin{proof}~

			\begin{enumerate}[label=(\arabic*)]
				\item Si $f$ est constante, alors $\ssup{f}-\sinf{f}=0<\eps$.
				\item Si $f$ est croissante,

				Soit $\eps>0$.

				Soit $n \in \naturels$ t.q. $n\eps>(b-a)(f(b)-f(a))$.

				Soit $\Delta:a=x_0<x_1<\dotsc<x_n=b$ avec $x_i=a+i\frac{b-a}{n}, i \in \{1,2,\dots,n\}$.

				On a
				\begin{align*}
					\ssup{f}-\sinf{f}&= \sum_{i=1}^{n}\left[ \msup{f}[x_{i-1},x_i] - \minf{f}[x_{i-1},x_i] \right] (x_i-x_{i-1})\\
					&= \sum_{i=1}^{n}\left[ f(x_i) - f(x_{i-1}) \right] \left( \frac{b-a}{n} \right)\\
					&= \frac{b-a}{n} \left[ f(b)-f(a) \right]\\
					&< \eps
				\end{align*}

				Donc, $f \in \riemann$.
				\item Si $f$ est d\'ecroissante, alors $-f$ est croissante et $-f \in \riemann$.

				Donc, $f \in \riemann$.
			\end{enumerate}
		\end{proof}
	\end{thm}
	\begin{thm}
		~

		Si $f_1,f_2 \in \riemann$, alors $f_1+f_2 \in \riemann$ et $\dint{}{}{\left( f_1+f_2 \right)} =\dint{}{}{f_1} + \dint{}{}{f_2}$.
		\begin{proof}~

			Soit $\eps>0$.

			Comme $f_i \in \riemann$, $\exists\Delta_i \in \partitions$ t.q. $\ssup{f_i}[\Delta_i]-\sinf{f_i}[\Delta_i]<\dfrac{\eps}{2}$.

			Soit $\Delta = \raffinement{\Delta_1}{\Delta_2}$.

			Alors, $\ssup{f_i}-\sinf{f_i}<\dfrac{\eps}{2}$.

			Supposons $\Delta:a=x_0<x_1<\dotsc<x_n=b$.

			On a
			\begin{align*}
				\ssup{f_1+f_2}&\lte \ssup{f_1} + \ssup{f_2}\\
				\sinf{f_1+f_2}&\gte \sinf{f_1} + \sinf{f_2}
			\end{align*}

			Car $\sup(f_1+f_2) \lte \sup f_1 + \sup f_2$ et $\inf(f_1+f_2) \gte \inf f_1 + \inf f_2$.

			Alors,
			\begin{align*}
				\ssup{f_1+f_2}-\sinf{f_1+f_2}&\lte \ssup{f_1} + \ssup{f_2} - \sinf{f_1} - \sinf{f_2}\\
				&< \dfrac{\eps}{2} + \dfrac{\eps}{2}\\
				&= \eps
			\end{align*}

			Donc, $f_1+f_2 \in \riemann$.

			De plus,
			\begin{align*}
				\dint{a}{b}{f_1+f_2}&\lte \ssup{f_1+f_2}\\
				&\lte \ssup{f_1} + \ssup{f_2}\\
				&< \sinf{f_1}+\dfrac{\eps}{2} + \sinf{f_2}+\dfrac{\eps}{2}\\
				&\lte \dint{a}{b}{f_1}+\dfrac{\eps}{2} + \dint{a}{b}{f_2}+\dfrac{\eps}{2}
			\end{align*}

			Ainsi, $\dint{a}{b}{f_1+f_2} < \dint{a}{b}{f_1} + \dint{a}{b}{f_2} + \eps$, $\forall\eps>0$.

			Donc, $\dint{a}{b}{f_1+f_2} \lte \dint{a}{b}{f_1} + \dint{a}{b}{f_2}$.

			De m\^eme, on peut montrer que $\dint{a}{b}{f_1+f_2} \gte \dint{a}{b}{f_1} + \dint{a}{b}{f_2}$.

			Donc, $\dint{a}{b}{f_1+f_2} = \dint{a}{b}{f_1} + \dint{a}{b}{f_2}$.
		\end{proof}
	\end{thm}
	\begin{thm}
		~

		Si $f \in \riemann$ et $\lambda \in \reels$, alors $\lambda f \in \riemann$ et $\dint{}{}{\lambda f} = \lambda \dint{}{}{f}$.
		\begin{proof}~

			Soit $\eps>0$.

			Comme $f \in \riemann$, $\exists\Delta \in \partitions$ t.q. $\ssup{f} - \sinf{f} < \dfrac{\eps}{\lambda}$.

			On a
			\begin{align*}
				\ssup{\lambda f}&= \lambda \ssup{f}\\
				\sinf{\lambda f}&= \lambda \sinf{f}
			\end{align*}

			Car $\sup(\lambda f) = \lambda \sup f$ et $\inf(\lambda f) = \lambda \inf f$.

			Alors,
			\begin{align*}
				\ssup{\lambda f} - \sinf{\lambda f}&= \lambda \ssup{f} - \lambda \sinf{f}\\
				&= \lambda \left( \ssup{f} - \sinf{f} \right)\\
				&< \lambda \cdot \dfrac{\eps}{\lambda}\\
				&= \eps
			\end{align*}

			Donc, $\lambda f \in \riemann$.

			De plus,
			\begin{align*}
				\dint{a}{b}{\lambda f}&\lte \ssup{\lambda f}\\
				&= \lambda \ssup{f}\\
				&< \lambda \left( \sinf{f} + \dfrac{\eps}{\lambda} \right)\\
				&= \lambda \sinf{f} + \eps\\
				&\lte \lambda \dint{a}{b}{f} + \eps
			\end{align*}

			Ainsi, $\dint{a}{b}{\lambda f} < \lambda \dint{a}{b}{f} + \eps$, $\forall\eps>0$.

			Donc, $\dint{a}{b}{\lambda f} \lte \lambda \dint{a}{b}{f}$.

			De m\^eme, on peut montrer que $\dint{a}{b}{\lambda f} \gte \lambda \dint{a}{b}{f}$.

			Donc, $\dint{a}{b}{\lambda f} = \lambda \dint{a}{b}{f}$.
		\end{proof}
		\begin{coro}
			~

			Si $f,g \in \riemann$, alors $f \lte g \Rightarrow \dint{}{}{f} \lte \dint{}{}{g}$.
			\begin{proof}~

				$g-f \gte 0 \Rightarrow \dint{}{}{g-f} \gte 0 \Rightarrow \dint{}{}{g} - \dint{}{}{f} \gte 0$.
			\end{proof}
		\end{coro}
	\end{thm}

	\subsection{In\'egalit\'e du triangle}
	\begin{thm}[In\'egalit\'e du triangle]
		~

		Si $f \in \riemann$, alors $\abs{f} \in \riemann$ et $\abs{\dint{}{}{f}} \lte \dint{}{}{\abs{f}}$.
		\begin{proof}~

			Soit $\eps>0$

			Alors, $\exists\Delta \in \partitions$ t.q. $\ssup{f}-\sinf{f}<\eps$.

			On a
			\begin{align*}
				\ssup{\abs{f}}-\sinf{\abs{f}}&= \dsum{i}{1}{n}{\left[ \msup{\abs{f}}[x_{i-1},x_i] - \minf{\abs{f}}[x_{i-1},x_i] \right] \left( x_i-x_{i-1} \right)}\\
				&\lte \dsum{i}{1}{n}{\left[ \msup{f}[x_{i-1},x_i] - \minf{f}[x_{i-1},x_i] \right] \left( x_i-x_{i-1} \right)}\\
				&= \ssup{f}-\sinf{f}\\
				&< \eps
			\end{align*}

			Donc, $\abs{f} \in \riemann$.

			Enfin,
			\begin{align*}
				-\abs{f} \lte f \lte \abs{f}&\Rightarrow -\dint{}{}{\abs{f}} \lte \dint{}{}{f} \lte \dint{}{}{\abs{f}}\\
				&\Rightarrow \dint{}{}{f} \lte \dint{}{}{\abs{f}}
			\end{align*}
		\end{proof}
	\end{thm}
	\begin{thm}
		~

		Si $f \in \riemann$ et $a \lte c < d \lte b$, alors $\left. f \right|_{[c,d]} \in \riemann$.
		\begin{proof}~

			Soit $\eps>0$

			Comme $f \in \riemann$, $\exists\Delta_1 \in \partitions$ t.q. $\ssup{f}[\Delta_1]-\sinf{f}[\Delta_1] < \eps$.

			Soit $\Delta_2$ le raffinement de $\Delta_1$ en ajoutant les points $c$ et $d$.

			Alors, $\ssup{f}[\Delta_2]-\sinf{f}[\Delta_2] \lte \ssup{f}[\Delta_1]-\sinf{f}[\Delta_1] < \eps$

			Donc, $f \in \riemann[c,d]$.
		\end{proof}
	\end{thm}
	\begin{thm}
		~

		Si $f \in \riemann$ et $a<c<b$, alors $\dint{a}{b}{f} = \dint{a}{c}{f} + \dint{c}{b}{f}$.
		\begin{proof}~

			Soit $\eps>0$

			$f \in \riemann \Rightarrow f \in \riemann[a,c] \Rightarrow \exists\Delta_1 \in \partitions[a,c]$ t.q. $\ssup{f}[\Delta_1] - \sinf{f}[\Delta_1] < \dfrac{\eps}{2}$.

			De m\^eme, $\exists\Delta_2 \in \partitions[c,b]$ t.q. $\ssup{f}[\Delta_2] - \sinf{f}[\Delta_2] < \dfrac{\eps}{2}$.

			Posons $\Delta = \raffinement{\Delta_1}{\Delta_2}$. Alors, $\Delta \in \partitions$ et
			\begin{align*}
				\dint{a}{b}{f}&\lte \ssup{f}\\
				&= \ssup{f}[\Delta_1] + \ssup{f}[\Delta_2]\\
				&< \sinf{f}[\Delta_1] + \dfrac{\eps}{2} + \sinf{f}[\Delta_2] + \dfrac{\eps}{2}\\
				&= \sinf{f}[\Delta_1] + \sinf{f}[\Delta_2] + \eps\\
				&\lte \dint{a}{c}{f} + \dint{c}{b}{f} + \eps
			\end{align*}

			Comme $\eps>0$ est arbitraire, on a $\dint{a}{b}{f} \lte \dint{a}{c}{f} + \dint{c}{b}{f}$.

			De m\^eme, $\dint{a}{b}{f} \gte \dint{a}{c}{f} + \dint{c}{b}{f}$.
		\end{proof}
	\end{thm}
	\begin{thm}
		Soit $f \in \bornee$. Soit $n \in \naturels$.

		Si $f$ poss\`ede $n$ discontinuit\'es dans $[a,b]$, alors $f \in \riemann$.
		\begin{proof}~

			Pour $n=0$, $f \in \continue$, donc $f \in \riemann$ est un r\'esultat connu.

			Supposons l'\'enonc\'e vrai pour $n$.

			Supposons que $f \in \bornee$ admet $n+1$ discontinuit\'es.

			Soit $\eps>0$.

			Soit $M=\sup\limits_{x\in[a,b]}\abs{f(x)}$

			Il y a deux cas \`a consid\'erer

			\begin{enumerate}
				\item $a$ ou $b$ est une discontinuit\'e

				Sans perte de g\'en\'eralit\'e, supposons que $a$ est la discontinuit\'e.

				Soit $\eta \in \reels^+$ t.q. $a$ est l'unique discontinuit\'e de $[a,a+\eta]$ et $\eta < \dfrac{\eps}{4M}$.

				Alors, $[a+\eta,b]$ contient $n$ discontinuit\'es.

				De l'hypoth\`ese de r\'ecurrence, $f \in \riemann[a+\eta,b]$.

				Il existe donc $\Delta \in \partitions[a+\eta,b]$ t.q. $\ssup{f} - \sinf{f} < \dfrac{\eps}{2}$.

				Posons $\Delta_\eps = \raffinement{\Delta}{\{a\}}$.

				On a donc
				\begin{align*}
					\ssup{f}[\Delta_\eps] - \sinf{f}[\Delta_\eps]&= \left( \ssup{f} - \sinf{f} \right) + \left( \msup{f}[a,a+\eta] - \minf{f}[a,a+\eta] \right) \eta\\
					&< \dfrac{\eps}{2} + 2M\eta\\
					&< \dfrac{\eps}{2} + \dfrac{\eps}{2}\\
					&= \eps
				\end{align*}
				\item ni $a$ ni $b$ ne sont des discontinuit\'es

				Soit $c \in ]a,b[$ qui est une discontinuit\'e de $f$.

				Soit $\eta \in \reels^+$ t.q. $c$ est l'unique discontinuit\'e de $[c-\eta,c+\eta] \subset [a,b]$ et $\eta < \dfrac{\eps}{8M}$.

				Alors, $[a,c-\eta]$ et $[c+\eta,b]$ contiennent au plus $n$ discontinuit\'es, donc par l'hypoth\`ese de r\'ecurrence:

				$\exists\Delta_1\in \partitions[a,c-\eta]$ t.q.  $\ssup{f}[\Delta_1] - \sinf{f}[\Delta_1] < \dfrac{\eps}{4}$ et $\exists\Delta_2\in \partitions[c+\eta,b]$ t.q.  $\ssup{f}[\Delta_2] - \sinf{f}[\Delta_2] < \dfrac{\eps}{4}$.

				Posons $\Delta_\eps = \raffinement{\Delta_1}{\Delta_2}$.

				On a donc
				\begin{align*}
					\ssup{f}[\Delta_\eps] - \sinf{f}[\Delta_\eps] &= \left[ \ssup{f}[\Delta_1] - \sinf{f}[\Delta_1] \right] + \left[ \ssup{f}[\Delta_2] - \sinf{f}[\Delta_2] \right]\\
					&+ \left[ \msup{f}[c-\eta,c+\eta] - \minf{f}[c-\eta,c+\eta] \right] \left( 2\eta \right)\\
					&< \dfrac{\eps}{4} + \dfrac{\eps}{4} + 4M\eta\\
					&< \dfrac{\eps}{4} + \dfrac{\eps}{4} + \dfrac{\eps}{2}\\
					&= \eps
				\end{align*}
			\end{enumerate}
		\end{proof}
	\end{thm}

	\begin{thm}
		Soient $f:[a,b] \to [c,d] \in \riemann$ et $g:[c,d] \to \reels \in \continue[c,d]$.

		Alors $g \circ f \in \riemann$.

		\begin{rema}
			L'hypoth\`ese que $g \in \continue[c,d]$ est n\'ecessaire.

			\begin{exem}
				~

				$
				\begin{array}{rcl}
					f:[0,1]&\to&\reels\\
					x&\mapsto&\left\lbrace \begin{array}{lcl}
						\frac{1}{n}&\text{si}&x=\frac{m}{n} \text{ et } \mathtt{pgcd}(m,n)=1\\
						0&\text{sinon}
					\end{array}\right.
				\end{array}$

				Fonction de Dirichlet modifi\'ee.

				$
				\begin{array}{rcl}
					g:[0,1]&\to&\reels\\
					x&\mapsto&\left\lbrace \begin{array}{lcl}
						1&\text{si}&x>0\\
						0&\text{sinon}
					\end{array}\right.
				\end{array}$

				$f,g \in \riemann$.

				$g \circ f(x)=\left\lbrace \begin{array}{lcl}
					1&\text{si}&x \in \rationels\\
					0&\text{sinon}
				\end{array}\right.$

				$g \circ f \not\in \riemann$.

				Fonction de Dirichlet.
			\end{exem}
		\end{rema}
	\end{thm}

	\begin{lem}
		Si $f \in \bornee$, $\Delta,\Delta' \in \partitions$ et $\Delta'$ s'obtient de $\Delta$ en ajoutant un unique point, alors $\ssup{f} - \ssup{f}[\Delta'] \lte 2\msup{\abs{f}}[a,b] \cdot \norme{\Delta}$.

		\begin{proof}~

			Soient $\Delta:a=x_0 < x_1 < \dotsc < x_{i-1} < x_i < \dotsc < x_n=b$ et

			$\Delta':a=x_0 < x_1 < \dotsc < x_{i-1} < \bar{x} < x_i < \dotsc < x_n=b$.

			\begin{align*}
				\ssup{f} - \ssup{f}[\Delta'] &= \msup{f}[x_{i-1},x_i] \cdot \left( x_i-x_{i-1} \right) - \msup{f}[x_{i-1},\bar{x}] \cdot \left( \bar{x}-x_{i-1} \right) - \msup{f}[\bar{x},x_i] \cdot \left( x_i-\bar{x} \right)\\
				&= \left( \bar{x}-x_{i-1} \right) \left( \msup{f}[x_{i-1},x_i] - \msup{f}[x_{i-1},\bar{x}] \right) + \left( x_i-\bar{x} \right) \left( \msup{f}[x_{i-1},x_i] - \msup{f}[\bar{x},x_i] \right)\\
				&\lte 2\msup{\abs{f}}[x_{i-1},x_i] \left( \left( \bar{x}-x_{i-1} \right) - \left( x_i-\bar{x} \right) \right)\\
				&\lte 2\msup{\abs{f}} \norme{\Delta}
			\end{align*}
		\end{proof}

		\begin{coro}
			Si $f \in \bornee$, $\Delta,\Delta' \in \partitions$ et $\Delta'$ s'obtient de $\Delta$ en ajoutant $p$ points, au plus un point par sous-intervalle de $\Delta$, alors $\ssup{f} - \ssup{f}[\Delta'] \lte 2p\msup{\abs{f}}[a,b] \cdot \norme{\Delta}$.
		\end{coro}
	\end{lem}

	\subsection{Th\'eor\`eme de Darboux}
	\begin{thm}[Darboux, 1875]
		~

		Si $f \in \bornee$, alors
		\begin{align*}
			\begin{split}
				\Ssup{f}&= \dlim{\norme{\Delta}}{0}{\ssup{f}}
			\end{split}
			&
			\begin{split}
				\Sinf{f}&= \dlim{\norme{\Delta}}{0}{\sinf{f}}
			\end{split}
		\end{align*}

		\begin{proof}~

			Soit $\eps>0$.

			Puisque $\Ssup{f} = \inf \ssup{f}$, on a que $\Ssup{f} + \dfrac{\eps}{2}$ n'est pas un minorant des $\ssup{f}$.

			Ainsi, $\exists\Delta_0 : a=x_0 < \dotsc < x_n=b$ t.q. $\ssup{f}[\Delta_0] < \Ssup{f} + \dfrac{\eps}{2}$.

			Soit $\delta>0$ t.q. $\delta < \min\limits_{i \in \{1,2,\dots,n\}}\abs{x_i-x_{i-1}}$ et $\delta < \dfrac{\eps}{4 (n-1) \msup{\abs{f}}}$.

			Soit $\Delta \in \partitions$ t.q. $\norme{\Delta} < \delta$.

			Alors, $\norme{\Delta} \xrightarrow[n \to \infty]{} 0$.

			Consid\'erons $\Delta' = \raffinement{\Delta}{\Delta_0}$.

			Comme $\norme{\Delta'} \lte \norme{\Delta} < \norme{\Delta_0}$, aucun sous-intervalle ouvert de $\Delta$ ne contient plus d'un point de $\Delta_0$.

			Comme $\Delta'$ s'obtient de $\Delta$ en ajoutant au plus $n-1$ points $\left( x_1, x_2, \dotsc, x_{n-1} \right)$,
			\begin{align*}
				\ssup{f} - \ssup{f}[\Delta'] &\lte 2(n-1) \msup{\abs{f}} \norme{\Delta}\\
				&< 2(n-1) \msup{f} \delta\\
				&< \dfrac{\eps}{2}
			\end{align*}

			On a donc
			\begin{align*}
				\ssup{f} &\lte \ssup{f}[\Delta'] + \dfrac{\eps}{2}\\
				&< \ssup{f}[\Delta_0] + \dfrac{\eps}{2}\\
				&< \Ssup{f} + \dfrac{\eps}{2} + \dfrac{\eps}{2}\\
				&= \Ssup{f} + \eps
			\end{align*}

			Comme $\eps>0$ est arbitraire, on a donc
			\begin{align*}
				\dlim{\norme{\Delta}}{0}{\ssup{f}}&= \Ssup{f}
			\end{align*}

			Enfin,
			\begin{align*}
				\dlim{\norme{\Delta}}{0}{\sinf{f}}&= \dlim{\norme{\Delta}}{0}{-\ssup{-f}}\\
				&= -\dlim{\norme{\Delta}}{0}{\ssup{-f}}\\
				&= -\Ssup{-f}\\
				&= \Sinf{f}
			\end{align*}
		\end{proof}
	\end{thm}

	\begin{defin}


		Soit $f \in \bornee$.

		Soit $\Delta : a=x_0 < x_1 < \dotsc < x_n=b \in \partitions$.

		Soient $\bar{x}_i \in [x_{i-1},x_i]$, pour $i \in \{1,2,\dots,n\}$.

		Le nombre r\'eel
		\begin{align*}
			\srie{f}&= \dsum{i}{1}{n}{f(\bar{x}_i) \cdot (x_i-x_{i-1})}
		\end{align*}

		est appel\'e \emph{somme de Riemann} de la fonction $f$ correspondant \`a la partition $\Delta$ et aux points $\{\bar{x}_i\}_{i \in \{1,2,\dots,n\}}$.
	\end{defin}

	\begin{thm}
		~

		Soit $f \in \riemann$.

		Alors, $(\forall\eps>0)$, $(\exists\delta=\delta(\eps))$ t.q. pour toute partition $\Delta$ de $[a,b]$ avec $\norme{\Delta}<\delta$ et pour tout choix de points $\{\bar{x}_i\}$, on a
		\[
		\abs{\dint{a}{b}{f} - S(f, \Delta, \{\bar{x}_i\})} < \eps
		\]

		c'est-\`a-dire.
		\[
		\dlim{\norme{\Delta}}{0}{\srie{f}} = \dint{a}{b}{f}
		\]
		\begin{proof}~

			On a $\sinf{f} \lte S(f, \Delta, \{\bar{x}_i\}) \lte \ssup{f}$.

			Donc,
			\[
			\Sinf{f} = \dlim{\norme{\Delta}}{0}{\sinf{f}} \lte \dlim{\norme{\Delta}}{0}{\srie{f}} \lte \dlim{\norme{\Delta}}{0}{\ssup{f}} = \Ssup{f}
			\]

			Comme $f \in \riemann$, on a $\Sinf{f} = \Ssup{f} = \dint{a}{b}{f}$.

			Par le th\'eor\`eme du sandwich, $\srie{f} = \dint{a}{b}{f}$.
		\end{proof}
	\end{thm}

	\subsection{Loi de la moyenne}
	\begin{thm}[Loi de la moyenne]~

		Soit $f \in \riemann$.

		Alors, $\exists\mu \in \left[ \minf{f}[a,b], \msup{f}[a,b] \right]$ t.q. $\dint{a}{b}{f} = (b-a) \cdot \mu$.
		\begin{proof}~

			Soit $\phi$ la fonction donn\'ee par $\phi(x)=(b-a)x$.

			On a $\minf{f} \lte f \lte \msup{f}$.

			Donc
			\[
			\phi(\minf{f}) = (b-a)\minf{f} = \dint{a}{b}{\minf{f}} \lte \dint{a}{b}{f} \lte \dint{a}{b}{\msup{f}} = (b-a)\msup{f} = \phi(\msup{f})
			\]
			\begin{rapp}
				\begin{thm}[Th\'eor\`eme de valeur interm\'ediaire]~

					$f$ continue sur $[a,b]$, $f(a)<c<f(b)$ implique $\exists x_0 \in [a,b]$ t.q. $f(x_0)=c$.
				\end{thm}
			\end{rapp}

			Comme $\phi$ est continue sur $[\minf{f},\msup{f}]$, du TVI, $\exists\mu\in[\minf{f},\msup{f}]$ t.q. $\phi(\mu)=c$ pour tout $c \in [\phi(\minf{f}),\phi(\msup{f})]$.

			En particulier, si $c=\dint{a}{b}{f}$, $\exists\mu$ t.q. $\phi(\mu)=\dint{a}{b}{c}$, c'est-\`a-dire t.q. $(b-a)\mu=\dint{a}{b}{f}$.
		\end{proof}
	\end{thm}


	\subsection{Th\'eor\`eme fondamental du calcul diff\'erentiel et int\'egral}
	\begin{thm}
		~

		Soit $f \in \riemann$.

		Soit
		$\begin{array}{rcl}
			F:[a,b]&\to&\reels\\
			x&\mapsto&F(x) = \displaystyle\int_{a}^{x}f(t) dt
		\end{array}$

		Alors,
		\begin{enumerate}[label=\alph*)]
			\item $\abs{F(x_1)-F(x_2)} \lte \msup{\abs{f}}(b-a) \cdot \abs{x_1-x_2}$ pour tous $x_1,x_2 \in [a,b]$;
			\item $F$ est uniform\'ement continue sur $[a,b]$;
			\item Si $f$ est continue, alors $F$ est diff\'erentiable et $F'=f$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item Supposons que $x_1>x_2$

				On a
				\begin{align*}
					\abs{F(x_1)-F(x_2)}&= \abs{\dint{a}{x_1}{f} - \dint{a}{x_2}{f}}\\
					&= \abs{\dint{x_2}{x_1}{f}}\\
					&\lte \dint{x_2}{x_1}{\abs{f}}\\
					&\lte \dint{x_2}{x_1}{\msup{\abs{f}}}\\
					&= \msup{\abs{f}} \cdot \abs{x_1-x_2}
				\end{align*}
				\item Soit $\eps>0$.

				Prenons $\delta = \dfrac{\eps}{\msup{\abs{f}}}$.

				Soient $x,y \in [a,b]$ avec $\abs{x-y}<\delta$.

				Alors,
				\begin{align*}
					\abs{F(x)-F(y)}&\lte \msup{\abs{f}} \cdot \abs{x-y}\\
					&< \msup{\abs{f}} \cdot \delta\\
					&= \eps
				\end{align*}
				\item Soit $x_0 \in [a,b]$.

				On a
				\begin{align*}
					F'(x_0)&= \dlim{x}{x_0}{\dfrac{F(x)-F(x_0)}{x-x_0}}\\
					&= \dlim{x}{x_0}{\dfrac{\dint{a}{x}{f} - \dint{a}{x_0}{f}}{x-x_0}}\\
					&= \dlim{x}{x_0}{\dfrac{\dint{x_0}{x}{f}}{x-x_0}}\\
					&\overset{\text{Loi de la moyenne}}{=} \dlim{x}{x_0}{\dfrac{(x-x_0)f(x_0+\theta(x-x_0))}{x-x_0}}&&\theta \in [0,1]\\
					&= \dlim{x}{x_0}{f(x_0+\theta(x-x_0))}\\
					&= f(x_0)
				\end{align*}
			\end{enumerate}
		\end{proof}
	\end{thm}
	\begin{nota}
		$F$ est une primitive de $f$.
	\end{nota}
	\begin{coro}
		Si $f$ est continue, alors $f$ admet au moins une primitive.
	\end{coro}
	\begin{coro}
		Si $F_1$ et $F_2$ sont deux primitives de $f$, alors $F_1-F_2=C$ pour une constante $C$.
	\end{coro}
	\begin{thm}[Th\'eor\`eme fondamental du calcul int\'egral]~

		Si $f \in \riemann$ et $F$ est une primitive de $f$, alors $\dint{a}{b}{f}=F(b)-F(a)$.
		\begin{proof}~

			Soit $\Delta:a=x_0<x_1<\dotsc<x_n=b \in \partitions$.

			Comme $F$ est continue et diff\'erentiable sur $[a,b]$ et a fortiori sur $[x_{i-1},x_i]$, le th\'eor\`eme de la moyenne donne $t_i \in [x_{i-1},x_i]$ t.q. $\dfrac{F(x_i) - f(x_{i-1})}{x_i-x_{i-1}} = F'(t_i) = f(t_i)$.

			On a
			\begin{align*}
				F(b)-F(a)&= \dsum{i}{1}{n}{\left[ F(x_i)-F(x_{i-1}) \right]}\\
				&= \dsum{i}{1}{n}{(x_i-x_{i-1}) \cdot f(t_i)}
			\end{align*}

			De plus,
			\[
			\begin{array}{rrcccl}
				&\minf{f}[x_{i-1},x_i] &\lte& f(t_i) &\lte& \msup{f}[x_{i-1},x_i]\\
				\Rightarrow&\dsum{i}{1}{n}{(x_i-x_{i-1})\minf{f}[x_{i-1},x_i]} &\lte& \dsum{i}{1}{n}{(x_i-x_{i-1})f(t_i)} &\lte& \dsum{i}{1}{n}{(x_i-x_{i-1})\msup{f}[x_{i-1},x_i]}\\
				\Rightarrow&\sinf{f} &\lte& F(b)-F(a) &\lte& \ssup{f}\\
				\Rightarrow&\dint{a}{b}{f}=\Sinf{f}=\dlim{\norme{\Delta}}{0}{\sinf{f}} &\lte& F(b)-F(a) &\lte& \dlim{\norme{\Delta}}{0}{\ssup{f}}=\Ssup{f}=\dint{a}{b}{f}
			\end{array}
			\]

			Donc, $\dint{a}{b}{f}=F(b)-F(a)$.
		\end{proof}
	\end{thm}
	\begin{prop}
		Soit $f:[a,b] \to \reels$ t.q. $f(x)=0$ sauf peut-\^etre en un nombre fini de points. Alors,
		\begin{enumerate}[label=\alph*)]
			\item $f \in \riemann$;
			\item $\dint{a}{b}{f}=0$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item d\'ej\`a fait, car $f$ est continue sauf en un nombre fini de points.
				\item Soit $p$ le nombre de points o\`u $f \neq 0$.

				Pour $p=0$, c'est trivial.

				Supposons que la propri\'et\'e est vraie pour $p$.

				Supposons que $f \neq 0$ en $p+1$ points.

				Il y a deux cas \`a consid\'erer
				\begin{enumerate}[label=\arabic*)]
					\item $\exists c \in ]a,b[$ avec $f(c) \neq 0$.

					Soit $\eps>0$.

					Soit $\eta>0$ t.q.
					\begin{enumerate}[label=\roman*)]
						\item $a<c-\eta<c+\eta<b$;
						\item $c$ est le seul point de $[c-\eta,c+\eta]$ o\`u $f\neq0$;
						\item $\eta<\min\left\lbrace \dfrac{\eps}{4\msup{f}}, \dfrac{-\eps}{4\minf{f}} \right\rbrace$.
					\end{enumerate}

					Par l'hypoth\`ese de r\'ecurrence,
					\[
					\begin{array}{rcccl}
						\displaystyle\int_{a}^{c-\eta}f&=&0&=&\displaystyle\int_{c+\eta}^{b}f
					\end{array}
					\]

					Du crit\`ere d'int\'egrabilit\'e, $\exists \Delta_1:a<x_0<x_1,\dotsc<x_n=c-\eta$, $\exists \Delta_2:c+\eta=y_0<y_1<\dotsc<y_n=b$ t.q. $\ssup{f}[\Delta_i] \lte \ssup{f}[\Delta_i]-\sinf{f}[\Delta_i]<\dfrac{\eps}{4}$, pour $i\in\{1,2\}$.

					Prenons $\Delta=\raffinement{\Delta_1}{\Delta_2}$.

					On a
					\begin{align*}
						\begin{split}
							\ssup{f}&= \ssup{f}[\Delta_1] + 2\eta \msup{f}[c-\eta,c+\eta] + \ssup{f}[\Delta_2]\\
							&\lte \ssup{f}[\Delta_1] + 2\eta \msup{f} + \ssup{f}[\Delta_2]\\
							&< \dfrac{\eps}{4} + \dfrac{\eps}{2} + \dfrac{\eps}{4}\\
							&= \eps
						\end{split}
					\end{align*}

					De m\^eme, $\sinf{f}[\Delta_i] \lte \ssup{f}[\Delta_i] < \dfrac{\eps}{4}$, pour $i\in\{1,2\}$.

					et
					\begin{align*}
						\sinf{f}&= \sinf{f}[\Delta_1] + 2\eta \minf{f}[c-\eta,c+\eta] + \sinf{f}[\Delta_2]\\
						&\gte \sinf{f}[\Delta_1] + 2\eta \minf{f} + \sinf{f}[\Delta_2]\\
						&> -\dfrac{\eps}{4} - \dfrac{\eps}{2} - \dfrac{\eps}{4}\\
						&= -\eps
					\end{align*}

					Donc, $-\eps < \sinf{f} \lte \ssup{f} < \eps$.

					Comme $\eps>0$ est arbirtaire, on en d\'eduit que $\dint{a}{b}{f}=0$.
					\item $f(c)\neq0$ en $a$ ou en $b$.

					On proc\`ede de la m\^eme mani\`ere avec un sous-intervalle de largeur $\eta$ autour de $a$ et de $b$ t.q. $a$ et $b$ sont les seules discontinuit\'es dans ces intervalles.
				\end{enumerate}
			\end{enumerate}
		\end{proof}
	\end{prop}
	\begin{coro}
		Si $f \in \riemann$ et $g:[a,b] \to \reels$ t.q. $f=g$ sauf peut-\^etre en un nombre fini de points, alors $\dint{a}{b}{f} = \int_{a}^{b}g$.
	\end{coro}

\newpage
	\section{Techniques d'int\'egration}
	\begin{thm}[Int\'egration par parties]~

		Soient $f,g:[a,b] \to \reels$ deux fonctions diff\'erentiables t.q. $f',g' \in \riemann$. Alors,
		\[
		\dint{a}{b}{f}g' = \left. fg \right|_a^b-\dint{a}{b}{gf'}
		\]
		\begin{proof}~

			Posons $h=fg$.

			Alors,
			\begin{align*}
				h'&= f'g + fg'\\
				\dint{a}{b}{h'}&= \dint{a}{b}{f'g} + \dint{a}{b}{fg'}\\
				\dint{a}{b}{fg'}&= \dint{a}{b}{h} - \dint{a}{b}{f'g}\\
				&= \left. h \right|_a^b - \dint{a}{b}{f'g}\\
				&= \left. fg \right|_a^b - \dint{a}{b}{f'g}
			\end{align*}
		\end{proof}
	\end{thm}
	\begin{thm}[Changement de variable/Substitution]~

		Soient $f:[a,b] \to \reels$ continue et $\phi:[\alpha,\beta] \to [a,b]$ de classe $C^1$, c'est-\`a-dire $\phi$ est d\'erivable et $\phi'$ est continue.

		Si $\phi(\alpha)=a$ et $\phi(\beta)=b$, alors
		\begin{align*}
			\dint{a}{b}{f(x) dx}&= \dint{\alpha}{\beta}{f(\phi(t))\phi'(t) dt}
		\end{align*}
		\begin{proof}~

			Posons $h(x)=\dint{a}{x}{f(t) dt}$.

			Du th\'eor\`eme fondamental, $h$ est uniform\'ement continue, diff\'erentiable et $h'=f$.

			Soit $g(t)=(h \circ \phi)(t) = h(\phi(t)) = \dint{a}{\phi(t)}{f(x) dx}$.

			On a $h,\phi$ diff\'erentiables, donc $g$ l'est aussi et
			\begin{align*}
				g'(t)&= h'(\phi(t)) \cdot \phi'(t)\\
				&= f(\phi(t)) \cdot \phi'(t)
			\end{align*}

			Enfin,
			\begin{align*}
				\dint{\alpha}{\beta}{f(\phi(t)) \cdot \phi'(t) dt}&= \dint{\alpha}{\beta}{g'(t) dt}\\
				&= g(\beta)-g(\alpha)\\
				&= h(\phi(\beta)) - h(\phi(\alpha))\\
				&= h(b)-h(a)\\
				&= \dint{a}{b}{f(t) dt} - \dint{a}{a}{f(t) dt}\\
				&= \dint{a}{b}{f(t) dt}
			\end{align*}
		\end{proof}
	\end{thm}

	\subsection{Fractions partielles}
	\begin{multline*}
		\dfrac{P(x)}{(x-a)^n(x^2+bx+c)^m} = \dfrac{A_1}{x-a} + \dfrac{A_2}{(x-a)^2} + \dotsb + \dfrac{A_n}{(x-a)^n}+\\
		\dfrac{B_1x+C_1}{x^2+bx+c} + \dfrac{B_2x+C_2}{(x^2+bx+c)^2} + \dotsb + \dfrac{B_mx+C_m}{(x^2+bx+c)^m}
	\end{multline*}

	Avec $b^2-4ac<0$.

	On ram\`ene sur d\'enominateurs communs.

	On ram\`ene en une fraction.

	On r\'esoud le syst\`eme d'\'equations avec $P(x)$.

	On int\`egre chaque fraction.

	\subsubsection{Quelques substitutions}
	\begin{enumerate}
		\item $f\left( x,\left( \frac{ax+b}{cx+d} \right)^\frac{m_1}{n_1}, \left( \frac{ax+b}{cx+d} \right)^\frac{m_2}{n_2}, \dotsb \right)$, ou $f$ est une fonction rationnelle $f=\frac{P(x)}{Q(x)}$.

		On pose $t^n=\frac{ax+b}{cx+d}$ o\`u $n$ est un multiple commun de $n_1,n_2,\dotsb$.
		\begin{exem}
			~

			$\dint{}{}{\dfrac{x^2}{\sqrt{x-1}}} = \dint{}{}{x^2(x-1)^{\sfrac{-1}{2}}}$.

			Posons $x-1=t^2$.

			Alors, $dx=2t dt$.

			On obtient $\dint{}{}{x^2(x-1)^{\sfrac{-1}{2}}} = \dint{}{}{(t^2-1)^2(t^2)^{\sfrac{-1}{2}}2tdt} = 2 \dint{}{}{(t^2+1)^2 dt}$.
		\end{exem}
		\item $\dint{}{}{x^\alpha(a+bx^\beta)^\gamma dx}$ avec $\alpha,\beta,\gamma \in \rationels$.

		On pose $t=x^\beta$.

		Alors, $dt = \beta x^{\beta-1} dx$.

		Donc, $dx = \dfrac{dt}{\beta x^{\beta-1}} = \dfrac{dt}{\beta t^{\sfrac{(\beta-1)}{\beta}}}$.
		\begin{exem}~

			$\dint{}{}{\dfrac{dx}{x^4\sqrt{1+x^2}}} = \dint{}{}{x^{-4}(1+x^2)^{\sfrac{-1}{2}} dx}$.

			Posons $t=x^2$.

			On a $dt=2xdx \Rightarrow dx=\dfrac{dt}{2x} = \dfrac{dt}{2\sqrt{t}}$.

			On obtient
			\begin{align*}
				\dint{}{}{x^{-4}(1+x^2)^{\sfrac{-1}{2}} dx}&= \dint{}{}{t^{-2} (1+t)^{\sfrac{-1}{2}} \dfrac{dt}{2\sqrt{t}}}\\
				&= \dfrac{1}{2} \dint{}{}{t^{\sfrac{-5}{2}}(1+t)^{\sfrac{-1}{2}} dt}\\
				&=\dfrac{1}{2}\dint{}{}{t^{-3}\left(\dfrac{1+t}{t}\right)^{\sfrac{-1}{2}} dt}
			\end{align*}

			Posons $u^2=\dfrac{1+t}{t} = 1+\dfrac{1}{t}$. On a $u^2-1=\dfrac{1}{t} \Rightarrow t=\dfrac{1}{u^2-1}$.

			Alors, $dt = (-1) (u^2-1)^{-2} (2u) du$.

			Ainsi,
			\begin{align*}
				\dfrac{1}{2} \dint{}{}{t^{-3} \left( \dfrac{1+t}{t} \right)^{\sfrac{-1}{2}} dt}&= -\dfrac{1}{2} \dint{}{}{(u^2-1)^3 u^{-1} (u^2-1)^{-2} 2udu}\\
				&= -\dint{}{}{(u^2-1) du}
			\end{align*}
		\end{exem}
		\item $f(\sin x, \cos x)$.

		On pose $t=\tan\frac{x}{2}$. On a $x=2 \arctan t$.

		Alors, $dx = \dfrac{2}{1+t^2} dt$.
		\begin{exem}~

			$\dint{}{}{\dfrac{dx}{2+\cos x}}$.

			On a
			\begin{align*}
				\cos x&= \cos^2\frac{x}{2} - \sin^2\frac{x}{2}\\
				&= \dfrac{\cos^2\frac{x}{2}} {\cos^2\frac{x}{2} - \sin^2\frac{x}{2}} - \dfrac{\sin^2\frac{x}{2}} {\cos^2\frac{x}{2} + \sin^2\frac{x}{2}}\\
				&= \dfrac{1}{\dfrac{\cos^2\frac{x}{2} + \sin^2\frac{x}{2}}{\cos^2\frac{x}{2}}} - \dfrac{\dfrac{1}{\cos^2\frac{x}{2}}\left(\sin^2\frac{x}{2}\right)} {\dfrac{1}{\cos^2\frac{x}{2}} \left(\cos^2\frac{x}{2} + \sin^2\frac{x}{2}\right)}\\
				&= \dfrac{1}{1 + \tan^2 \frac{x}{2}} - \dfrac{\tan^2 \frac{x}{2}} {1 + \tan^2 \frac{x}{2}}\\
				&= \dfrac{1 - \tan^2 \frac{x}{2}}{1 + \tan^2 \frac{x}{2}}\\
				&= \dfrac{1-t^2}{1+t^2}
			\end{align*}

			Alors,
			\begin{align*}
				\dint{}{}{\dfrac{dx}{2+\cos x}}&= \dint{}{}{\dfrac{2dt}{1+t^2} \dfrac{1}{2 + \dfrac{1 - t^2}{1 + t^2}}}\\
				&= \dint{}{}{\dfrac{2dt}{3+t^2}}\\
				&= 2\dint{}{}{\dfrac{dt}{t^2+\sqrt{3}^2}}\\
				&= \dfrac{2}{\sqrt{3}} \arctan\dfrac{t}{\sqrt{3}}\\
				&= \dfrac{2}{\sqrt{3}} \arctan \dfrac{\tan \frac{x}{2}}{\sqrt{3}}
			\end{align*}
		\end{exem}
		\item $f\left( x,\sqrt{a^2-x^2} \right)$.

		On pose $x=a\sin t$. On a $dx=a\cos t dt$.
		\begin{exem}
			\begin{align*}
				\dint{}{}{x^2\sqrt{a^2-x^2} dx}&= \dint{}{}{a^2\sin^2t \sqrt{a^2-a^2\sin^2t} a\cos t dt}\\
				&= \dint{}{}{a^4 \sin^2t \cos^2 t dt}\\
				&= \dint{}{}{a^4 \dfrac{1}{4} \sin^2 2t dt}\\
				&= \dint{}{}{\dfrac{a^4}{4} \cdot \dfrac{1-\cos 4t}{2} dt}\\
				&= \dfrac{a^4}{8} \left[ t - \dfrac{\sin 4t}{4} \right]
			\end{align*}
		\end{exem}
		\newpage
		\item
		\begin{rapp}
			\begin{align*}
				\begin{split}
					\sinh x&= \dfrac{e^x-e^{-x}}{2}
				\end{split}
				&
				\begin{split}
					\cosh x&= \dfrac{e^x+e^{-x}}{2}
				\end{split}
				&
				\begin{split}
					\tanh x&= \dfrac{\sinh x}{\cosh x}\\
					&= \dfrac{e^{2x}-1}{e^{2x}+1}
				\end{split}
			\end{align*}
			\begin{align*}
				\begin{split}
					(\sinh x)'&= \dfrac{e^x+e^{-x}}{2}\\
					&= \cosh x
				\end{split}
				&
				\begin{split}
					(\cosh x)'&= \dfrac{e^x-e^{-x}}{2}\\
					&= \sinh x
				\end{split}
			\end{align*}
			\begin{align*}
					-\cosh^2x+\sinh^2x&= -\left( \dfrac{e^x+e^{-x}}{2} \right)^2 + \left( \dfrac{e^x-e^{-x}}{2} \right)^2\\
					&= -\dfrac{e^{2x}+2e^xe^{-x}+2^{-2x}}{4} + \dfrac{e^{2x}-2e^xe^{-x}+2^{-2x}}{4}\\
					&= -1
			\end{align*}

			Donc, $\cosh^2x-\sinh^2=1$.

			Alors, $1-\tanh^2x = \sech^2x \Rightarrow \sech^2x+\tanh^2x = 1$.

			Formellement,
			\begin{align*}
				\begin{split}
					\sinh x&= \dfrac{e^z-e^{-z}}{2}
				\end{split}
				&
				\begin{split}
					\cosh x&= \dfrac{e^z+e^{-z}}{2}
				\end{split}
			\end{align*}
			avec $z \in \complexes$.
		\end{rapp}

		$f\left( x,\sqrt{x^2-a^2} \right)$.

		On pose $x = a \cosh t$. On a $dx = a \sinh t dt$.
		\begin{exem}
			\begin{align*}
				\dint{}{}{\dfrac{x^2}{\sqrt{x^2-a^2}} dx}&= \dint{}{}{\dfrac{a^2\cosh^2t}{\sqrt{a^2\cosh^2t-a^2}}a\sinh tdt}\\
				&= \dint{}{}{\dfrac{a^2\cosh^2t}{a\sinh t}a\sinh tdt}\\
				&= \dint{}{}{a^2\cosh^2tdt}\\
				&= \dint{}{}{a^2 \dfrac{a+\cosh 2t}{2}dt}\\
				&= \dfrac{a^2t}{2} + \dfrac{a^2}{2}\dfrac{\sinh2t}{2}
			\end{align*}
		\end{exem}
		\begin{rema}
			$\mathrm{arccosh}t = \ln\left( t+\sqrt{t^2-1} \right)$, $\mathrm{arcsinh}t = \ln\left( t+\sqrt{1+t^2} \right)$.
		\end{rema}
		\newpage
		\item $f\left( x, \sqrt{x^2+a^2} \right)$.

		On pose $x = a\sinh t$. On a $dx = a\cosh t dt$.
		\begin{exem}
			\begin{align*}
				\dint{}{}{\dfrac{x^3}{(x^2+a^2)^{\sfrac{3}{2}}} dx}&= \dint{}{}{\dfrac{a^3\sinh^3t}{(a^2\sinh^2t+a^2)^{\sfrac{3}{2}}} a\cosh t dt}\\
				&= \dint{}{}{\dfrac{a^3\sinh^3t}{a^3\cosh^3t} a\cosh t dt}\\
				&= a\dint{}{}{\dfrac{\sinh^3t}{\cosh^2t} dt}\\
				&= a\dint{}{}{\dfrac{\sinh t \sinh^2t}{\cosh^2t} dt}\\
				&= a\dint{}{}{\dfrac{\sinh t (\cosh^2t-1)}{\cosh^2t} dt}\\
				&= a\dint{}{}{\left( \sinh t - \dfrac{\sinh t}{\cosh^2t} \right) dt}\\
				&\text{posons }u=\cosh t, du=\sinh t dt\\
				&= a\cosh t + \dfrac{a}{\cosh t}\\
				&= a\sqrt{\cosh^2t} + \dfrac{a}{\sqrt{\cosh^2t}}\\
				&= a\sqrt{1+\sinh^2t} + \dfrac{a}{\sqrt{1+\sinh^2t}}\\
				&= a\sqrt{1+ \left( \frac{x}{a} \right) ^2} + \dfrac{a}{\sqrt{1+ \left( \frac{x}{a} \right) ^2}}
			\end{align*}
		\end{exem}
		\item $f\left( x,\sqrt{x^2+2bx+c} \right)$, avec $x^2+2bx+c$ irr\'eductible dans $\reels$.

		On a $x^2+2bx+c = (x+b)^2+(c-b^2)$.

		On pose $t = x+b$. On a $dt = dx$.
		\begin{exem}
			\begin{align*}
				\dint{}{}{\dfrac{x}{\sqrt{x^2+4x+5}} dx}&= \dint{}{}{\dfrac{x}{\sqrt{(x+2)^2+1}} dx}\\
				&\text{posons }t=x+2, dt=dx\\
				&= \dint{}{}{\dfrac{t-2}{\sqrt{t^2+1}} dt}\\
				&= \dint{}{}{\dfrac{t}{\sqrt{t^2+1}} dt} - 2\dint{}{}{\dfrac{dt}{\sqrt{t^2+1}}}\\
				&\text{posons }u=t^2+1, du=2tdt\\
				&\text{posons }t=\sinh v, dt = \cosh v dv\\
				&= \dfrac{1}{2}\dint{}{}{\dfrac{du}{\sqrt{u}}} - 2\dint{}{}{\dfrac{\cosh v dv}{\sqrt{\sinh^2v+1}}}\\
				&= \sqrt{u} - 2\dint{}{}{dv}\\
				&= \sqrt{u} - 2v\\
				&= \sqrt{t^2+1} - 2 \mathrm{arcsinh}t\\
				&= \sqrt{t^2+1} - 2\ln(t+\sqrt{1+t^2})\\
				&= \sqrt{(x+2)^2+1} - 2\ln\left( x+2+\sqrt{1+(x+2)^2} \right)
			\end{align*}
		\end{exem}
	\end{enumerate}

	\section{Int\'egrales impropres}
	\begin{defin}
		$f:[a,\infty[$ continue par morceaux.

		L'int\'egrale impropre (de 1\textsuperscript{\`ere} esp\`ece) de $f$ est $\dint{a}{\infty}{f(x)dx} = \dlim{y}{\infty}{\dint{a}{y}{f(x)dx}}$.

		Si la limite existe, on dit que l'int\'egrale converge.
		\begin{exem}~

			\begin{enumerate}
				\item \begin{align*}
					\dint{1}{\infty}{\dfrac{dx}{x}}&= \dlim{y}{\infty}{\dint{1}{y}{dfrac{dx}{x}}}\\
					&= \dlim{y}{\infty}{(\ln y - \ln1)}\\
					&= \infty
				\end{align*}
				diverge
				\item \begin{align*}
					\dint{1}{\infty}{\dfrac{dx}{x^p}}&= \dlim{y}{\infty}{\dint{1}{y}{x^{-p}dx}}\\
					&= \left. \dlim{y}{\infty}{\dfrac{x^{-p+1}}{-p+1}} \right| ^y_1\\
					&= \dlim{y}{\infty}{\left( \dfrac{y^{1-p}}{1-p} - \dfrac{1}{1-p} \right)}
				\end{align*}

				Si $p>1$, alors $1-p<0$ et $y^{1-p} \xrightarrow[y \to \infty]{} 0$.

				On a alors $\dint{1}{\infty}{\dfrac{dx}{x^p}} = \dfrac{1}{1-p}$.

				Si $p<1$, alors $1-p>0$ et $y^{1-p} \xrightarrow[y \to \infty]{} \infty$.

				On a alors que $\dint{1}{\infty}{\dfrac{dx}{x^p}}$ diverge.

				Si $p=1$, c'est le cas 1, qui diverge.
				\item \begin{align*}
					\dint{0}{\infty}{e^{-sx}dx}&= \dlim{y}{\infty}{\dint{0}{y}{e^{-sx}}}\\
					&= \left. \dlim{y}{\infty}{\dfrac{e^{-sx}}{-s}} \right|^y_0\\
					&= \dlim{y}{\infty}{\left( \dfrac{e^{-sy}}{-s} + \dfrac{1}{s} \right)}
				\end{align*}

				Si $s<0$, alors $-sy>0$ et l'int\'egrale diverge.

				Si $s>0$, alors $-sy<0$ et l'int\'egrale converge vers $\frac{1}{s}$.

				Si $s=0$, alors $\dint{0}{\infty}{e^{-sx}dx} = \dint{0}{\infty}{dx}$ diverge.
				\item \begin{align*}
					\dint{0}{\infty}{\dfrac{dx}{x^2+1}}&= \dlim{y}{\infty}{\dint{0}{\infty}{\dfrac{dx}{x^2+1}}}\\
					&= \dlim{y}{\infty}{(\arctan y - \arctan0)}\\
					&= \frac{\pi}{2}
				\end{align*}
			\end{enumerate}
		\end{exem}
	\end{defin}
	\begin{defin}
		$f:]a,b]$ continue, mais t.q. $\dlim{x}{a^+}{f(x)}$ n'existe pas.

		L'int\'egrale impropre (de 2\textsuperscript{\`eme} esp\`ece) de $f$ est $\dint{a}{b}{f}(x)dx = \dlim{y}{a^+}{\dint{y}{b}{f(x)dx}}$.

		Si la limite existe, on dit que l'int\'egrale converge.
		\begin{exem}~

			\begin{enumerate}
				\item \begin{align*}
					\dint{0}{1}{\dfrac{dx}{x}}&= \dlim{y}{0^+}{\dint{y}{b}{\dfrac{dx}{x}}}\\
					&= \dlim{y}{0^+}{(\ln1-\ln y)}\\
					&= \infty
				\end{align*}
				diverge
				\item \begin{align*}
					\dint{0}{1}{\dfrac{dx}{x^p}}&= \dlim{y}{0^+}{\dint{y}{1}{\dfrac{dx}{x^p}}}\\
					&= \left. \dlim{y}{0^+}{\dfrac{x^{-p+1}}{-p+1}} \right|^1_y\\
					&= \dfrac{1}{1-p} - \dlim{y}{0^+}{\dfrac{y^{1-p}}{1-p}}
				\end{align*}

				Si $p>1$, alors $1-p<0$ et l'int\'egrale diverge.

				Si $p<1$, alors $1-p>0$ et l'int\'egrale converge vers $\frac{1}{1-p}$.

				Si $p=1$, alors c'est le cas 1, qui diverge.
				\item \begin{align*}
					\dint{0}{1}{\dfrac{dx}{\sqrt{1-x^2}}}&= \dlim{y}{1^-}{\dint{0}{y}{\dfrac{dx}{\sqrt{1-x^2}}}}\\
					&= \dlim{y}{1^-}{(\arcsin y - \arcsin0)}\\
					&= \dfrac{\pi}{2}
				\end{align*}
			\end{enumerate}
		\end{exem}
	\end{defin}
	\begin{rema}~

		\begin{enumerate}
			\item \begin{align*}
				\dint{0}{\infty}{\dfrac{dx}{x}}&= \overbrace{\dint{0}{b}{\dfrac{dx}{x}}}^{\text{2\textsuperscript{\`eme} esp}} + \overbrace{\dint{b}{\infty}{\dfrac{dx}{x}}}^{\text{1\textsuperscript{\`ere} esp}}\\
				&= \dlim{y}{0^+}{\dint{y}{b}{\dfrac{dx}{x}}} + \dlim{y}{\infty}{\dint{b}{y}{\dfrac{dx}{x}}}
			\end{align*}

			$\dint{0}{\infty}{\dfrac{dx}{x}}$ converge si, et seulement si, les deux limites existent.
			\item \begin{align*}
				\dint{-\infty}{\infty}{\sin xdx}&= \dlim{y}{\infty}{\dint{-y}{y}{\sin xdx}}\\
				&= \left. \dlim{y}{\infty}{\cos x} \right|^y_{-y}\\
				&= \dlim{y}{\infty}{(\cos y - \cos (-y))} = \dlim{y}{\infty}{0}\\
				&= 0
			\end{align*}

			Cependant,
			\begin{align*}
				\dint{-\infty}{\infty}{\sin xdx}&= \dint{-\infty}{0}{\sin xdx} + \dint{0}{\infty}{\sin xdx}\\
				&= \dlim{y}{\infty}{\dint{-y}{0}{\sin xdx}} + \dlim{y}{\infty}{\dint{0}{y}{\sin xdx}}\\
				&= \dlim{y}{\infty}{(\cos0-\cos(-y))} + \dlim{y}{\infty}{(\cos0-\cos y)}
			\end{align*}
			diverge

			Ainsi, l'int\'egrale diverge.
		\end{enumerate}
	\end{rema}
	\begin{thm}[Crit\`ere de Cauchy]~

		$\dint{a}{\infty}{f(x)dx}$ converge si, et seulement si, $(\forall\eps>0) (\exists M \gte a)$ t.q. $M \lte y_1 \lte y_2 \Rightarrow \abs{\dint{y_1}{y_2}{f(x)dx}}<\eps$.
		\begin{proof}~

			Posons $F(y) = \dint{a}{y}{f(x)dx}$.
			\begin{itemize}
				\item[$(\Rightarrow)$] Supposons que $\dint{a}{\infty}{f(x)dx}$ converge.

				Soit $L = \dlim{y}{\infty}{\dint{a}{y}{f(x)dx}}$.

				Alors, $(\forall\eps>0) (\exists M \gte a)$ t.q. $y \lte M \Rightarrow \abs{F(y)-L}<\dfrac{\eps}{2}$.

				Soient $y_1,y_2$ avec $M \lte y_1 \lte y_2$.

				On a
				\begin{align*}
					\abs{\dint{y_1}{y_2}{f(x)dx}}&= \abs{F(y_2)-F(y_1)}\\
					&= \abs{F(y_2)-L+L-F(y_1)}\\
					&\lte \abs{F(y_2)-L} + \abs{F(y_1)-L}\\
					&< \dfrac{\eps}{2} + \dfrac{\eps}{2}\\
					&= \eps
				\end{align*}
				\item[$(\Leftarrow)$] Supposons que $(\forall\eps>0)(\exists M \gte a)$, $M \lte y_1 \lte y_2 \Rightarrow \abs{\dint{y_1}{y_2}{f(x)dx}} < \eps$.

				Soit $n \in \naturels$.

				En particulier, on a $(\forall\eps>0) (\exists M \gte a)$, $M \lte n \lte y \Rightarrow \abs{F(y)-F(n)}<\dfrac{\eps}{2}$.

				Consid\'erons la suite $\{F(n)\}_{n \in \naturels}$.
				\begin{rapp}
					$\{a_n\}_{n \in \naturels}$ est une \emph{suite de Cauchy} si $(\forall\eps>0) (\exists N>0)$, $m>n>N \Rightarrow \abs{a_m-a_n}<\eps$.
				\end{rapp}

				La suite $\{F(n)\}_{n \in \naturels}$ est de Cauchy et elle est convergente. Soit $L = \dlim{n}{\infty}{F(n)}$.

				Alors, $(\forall\eps>0) (\exists N>0)$, $n>N \Rightarrow \abs{F(n)-L}<\dfrac{\eps}{2}$.

				Il reste \`a montrer que $\{F(y)\}_{y \in \reels}$ converge aussi vers $L$.

				\`A partir d'un certain rang appropri\'e, on a
				\begin{align*}
					\abs{F(y)-L}&= \abs{F(y) - F(n) + F(n) - L}\\
					&\lte \abs{F(y)-F(n)} + \abs{F(n)-L}\\
					&< \dfrac{\eps}{2} + \dfrac{\eps}{2}\\
					&= \eps
				\end{align*}
			\end{itemize}
		\end{proof}
		\begin{rema}
		Si $f \gte 0$, alors $F$ est croissante, donc $\lim F(y)$ converge ou tend vers $\infty$.

		Ainsi, $\dint{a}{\infty}{f(x)dx}$ converge si, et seulement si, $\dint{a}{\infty}{f(x)dx} < \infty$.
		\end{rema}
	\end{thm}
	\begin{prop}[Test de comparaison]~

		Supposons que $0 \lte f(x) \lte g(x)$, $(\forall x \gte a)$.

		Alors, $\dint{a}{\infty}{g(x)dx}$ converge implique $\dint{a}{\infty}{f(x)dx}$ converge.
		\begin{proof}~

			$\dint{a}{\infty}{g(x)dx}$ converge, alors $(\forall\eps>0) (\exists M \gte a)$, $M \lte y_1 \lte y_2 \Rightarrow \abs{\dint{y_1}{y_2}{g(x)dx}}<\eps$.

			On a
			\begin{align*}
				0 \lte \dint{y_1}{y_2}{f(x)dx} \lte \dint{y_1}{y_2}{g(x)dx} = \abs{\dint{y_1}{y_2}{g(x)dx}} < \eps
			\end{align*}

			Donc, $\dint{a}{\infty}{f(x)dx}$ converge.
		\end{proof}
	\end{prop}
	\begin{exem}
		~

		D\'eterminer si $\dint{1}{\infty}{e^{-x^2}}$ converge.

		Pour $x \gte 1$, on a $x^2 \gte x$, donc $-x^2 \lte -x$ et $e^{-x^2} \lte e^{-x}$.

		Or, $\dint{1}{\infty}{e^{-x}dx} = \dlim{y}{\infty}{\dint{1}{y}{e^{-x}dx}} = \left. \dlim{y}{\infty}{-e^{-x}} \right|^y_1 = \dlim{y}{\infty}{(e^{-1} - e^{-y})} = e^{-1}$.

		Comme $e^y \gte 0, \forall y \in \reels$, on a que $\dint{1}{\infty}{e^{-x^2}dx}$ converge.
	\end{exem}
	\begin{prop}[Test de comparaison limite]~

		Supposons $a \lte b \lte x$ et $f(x),g(x) \gte 0$, $(\forall x \gte b)$.

		Si $C = \dlim{x}{\infty}{\dfrac{f(x)}{g(x)}}$ existe, alors $\dint{a}{\infty}{g(x)dx}$ converge implique $\dint{a}{\infty}{f(x)dx}$ converge.

		De plus, si $C \neq 0$, $\dint{a}{\infty}{g(x)dx}$ converge si, et seulement si, $\dint{a}{\infty}{f(x)dx}$ converge.
	\end{prop}
	\begin{prop}[Convergence absolue]~

		\begin{enumerate}[label=\alph*)]
			\item $\dint{a}{\infty}{\abs{f(x)}dx} < \infty$, alors $\dint{a}{\infty}{f(x)dx} < \infty$.
			\item $\abs{\dint{a}{\infty}{f(x)dx}} \lte \dint{a}{\infty}{\abs{f(x)}dx}$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item Si $\dint{a}{\infty}{\abs{f(x)}dx} < \infty$, alors $(\forall\eps>0) (\exists M \gte a)$ t.q. $M \lte y_1 \lte y_2 \Rightarrow \abs{\dint{y_1}{y_2}{\abs{f(x)}dx}}<\eps$.

				Or, $\abs{\dint{y_1}{y_2}{f(x)dx}} \lte \dint{y_1}{y_2}{\abs{f(x)}dx} = \abs{\dint{y_1}{y_2}{\abs{f(x)}dx}} < \eps$.

				Du crit\`ere de Cauchy, $\displaystyle\int_{a}^{\infty}f(x)dx$ converge.
				\newpage
				\item
				\begin{align*}
					\abs{\dint{a}{\infty}{f(x)dx}}&= \abs{\dlim{y}{\infty}{\dint{a}{y}{f(x)dx}}}\\
					&= \dlim{y}{\infty}{\abs{\dint{a}{y}{f(x)dx}}}\\
					&\lte \dlim{y}{\infty}{\dint{a}{y}{\abs{f(x)}dx}}\\
					&= \dint{a}{\infty}{\abs{f(x)}dx}
				\end{align*}
			\end{enumerate}
		\end{proof}
	\end{prop}
	\begin{rema}
		$\dint{a}{\infty}{f} < \infty \nRightarrow \dint{a}{\infty}{\abs{f}} < \infty$.
		\begin{exem}[En effet]
			\begin{align*}
				\dint{a}{\infty}{\dfrac{\sin x}{x} dx}&= \dlim{y}{\infty}{\dint{a}{y}{\dfrac{\sin x}{x} dx}}\\
				u=\frac{1}{x}&\Rightarrow du=\frac{-dx}{x^2}\\
				dv=\sin x&\Rightarrow v=-\cos x\\
				&= \dlim{y}{\infty} {\left( \left. \dfrac{-\cos x}{x} \right|^y_{\sfrac{\pi}{2}} - \dint{\sfrac{\pi}{2}}{y}{\dfrac{\cos x}{x^2} dx} \right)}\\
				&= \dlim{y}{\infty} {\left( \dfrac{\cos\sfrac{\pi}{2}}{\sfrac{\pi}{2}} - \dint{\sfrac{\pi}{2}}y{\dfrac{\cos x}{x^2} dx} \right)}\\
				&= \dlim{y}{\infty}{-\dint{\sfrac{\pi}{2}}{y}{\dfrac{\cos x}{x^2} dx}}
			\end{align*}

			Or, $\dint{\sfrac{\pi}{2}}{\infty}{\abs{\dfrac{\cos x}{x^2}} dx} < \dint{\sfrac{\pi}{2}}{\infty}{\dfrac{dx}{x^2}} = \dlim{y}{\infty}{\dint{\sfrac{\pi}{2}}y{\dfrac{dx}{x^2} dx}} = \dlim{y}{\infty} {\left. \dfrac{-1}{x} \right|^y_{\sfrac{\pi}{2}}} = \dlim{y}{\infty}{\left( \dfrac{2}{\pi} - \dfrac{1}{y} \right)} = \dfrac{2}{\pi}$.

			Donc, $\dint{\sfrac{\pi}{2}}{\infty}{\dfrac{\cos x}{x^2} dx} < \infty$. Alors, $\dint{\sfrac{\pi}{2}}{\infty}{\dfrac{\sin x}{x^2} dx} < \infty$.
			\begin{proof}[Montrons que]
				$\dint{\sfrac{\pi}{2}}{\infty}{\abs{\dfrac{\sin x}{x}} dx}$ diverge.

				Consid\'erons les intervalles $I_k = \left[ 2k\pi, 2k\pi+\dfrac{\pi}{2} \right]$, avec $k \in \naturels$.

				Sur $I_k$, $\sin x$ cro\^it de $0$ \`a $1$.

				En particulier, $\exists x_k \in I_k$ t.q. $\sin x_k \gte \dfrac{\sqrt{2}}{2}$.

				Ainsi, $\abs{\dfrac{\sin x_k}{x_k}} \gte \dfrac{\sqrt{2}}{2x_k}$.

				Or, $x_k \lte 2k\pi+\dfrac{\pi}{2} \lte 8k+\dfrac{\pi}{2} \lte 8k+2k = 10k$.

				Alors, $\dfrac{1}{x_k} \gte \dfrac{1}{10} \cdot \dfrac{1}{k} = c \cdot \dfrac{1}{k}$.

				Ainsi, $\dint{I_k}{}{\abs{\dfrac{\sin x_k}{x_k}} dx} >  \dint{I_k}{}{\dfrac{c}{k} dx} = \dfrac{c}{k} \cdot \dfrac{\pi}{2}$.

				Enfin, $\dint{\sfrac{\pi}{2}}{\infty}{\abs{\dfrac{\sin x}{x}} dx} \gte \dsum{k}{1}{\infty}{\dint{I_k}{}{\abs{\dfrac{\sin x_k}{x_k}} dx}} > \dsum{k}{1}{\infty}{\dfrac{c}{k} \cdot \dfrac{\pi}{2}} = \dfrac{c\pi}{2} \dsum{k}{1}{\infty}{\dfrac{1}{k}}$, la s\'erie harmonique qui diverge.
			\end{proof}
		\end{exem}
	\end{rema}
	\begin{thm}[Test de l'int\'egrale]~

		Soit $f: [1,\infty[ \to [0,\infty[$ monotone d\'ecroissante.

		Alors, $\dint{1}{\infty}{f(x)dx} < \infty$ si, et seulement si, $\dsum{k}{1}{\infty}{f(k)} < \infty$.
		\begin{proof}~

			Soit $\Delta: 1 = x_0 < x_1 < x_2 < \dotsb$, avec $x_i=i+1$, pour $i \in \naturels$.

			On a
			\begin{align*}
				\srie{f}[\Delta][\{x_i\}]&= \dsum{i}{1}{\infty}{f(x_i) \cdot (x_i-x_{i-1})}\\
				&= \dsum{i}{1}{\infty}{f(i+1)}\\
				&= \dsum{j}{2}{\infty}{f(j)}
			\end{align*}

			De m\^eme, $\srie{f}[\Delta][\{x_{i-1}\}] = \dsum{i}{1}{\infty}{f(x_{i-1})(x_i-x_{i-1})} = \dsum{i}{1}{\infty}{f(i)}$.

			On a donc
			\[
			\dsum{j}{2}{\infty}{f(j)} \lte \dint{1}{\infty}{f(x)dx} \lte \dsum{i}{1}{\infty}{f(i)}
			\]
			\begin{itemize}
			\item[$(\Rightarrow)$] Si $\dint{1}{\infty}{f(x)dx}$ converge, alors $\dsum{j}{2}{\infty}{f(j)}$ converge. Donc, $\dsum{i}{1}{\infty}{f(i)}$ converge.
			\item[$(\Leftarrow)$] Si $\dsum{i}{1}{\infty}{f(i)}$ converge, alors $\dint{1}{\infty}{f(x)dx}$ converge.
			\end{itemize}
		\end{proof}
	\end{thm}
	\begin{exem}~

		\begin{proof}[m.q.]
			$\dsum{n}{1}{\infty}{\dfrac{1}{n^p}}$ converge $\forall p > 1$.

			\underline{D'Alembert}:
			\[
			\dlim{n}{\infty}{\dfrac{a_n}{a_{n+1}}} = \dlim{n}{\infty}{\dfrac{\sfrac{1}{(n+1)^p}}{\sfrac{1}{n^p}}} = \dlim{n}{\infty}{\left( \dfrac{n}{n+1} \right)^p} = 1
			\]

			\underline{Cauchy}:
			\[
			\dlim{n}{\infty}{\sqrt[n]{a_n}} = \dlim{n}{\infty}{\sqrt[n]{n^{-p}}} = \dlim{n}{\infty}{n^{\sfrac{-p}{n}}} = \dlim{n}{\infty}{e^{\ln n^{\sfrac{-p}{n}}}} = \dlim{n}{\infty}{e^{-p\frac{\ln n}{n}}} = e^{-p \dlim{n}{\infty}{\sfrac{\ln n}{n}}} = e^{-p \dlim{n}{\infty}{\sfrac{1}{n}}} = 1
			\]

			\underline{Test de l'int\'egrale}:

			Posons $f(x) = \dfrac{1}{x^p}$.

			On a $f'(x) = -px^{-p-1}<0$, donc $f$ est monotone d\'ecroissante.

			De plus, $\dsum{n}{1}{\infty}{f(n)} = \dsum{n}{1}{\infty}{\dfrac{1}{n^p}}$ converge si, et seulement si, $\dint{1}{\infty}{f(x)dx}$ converge.

			Or, $\dint{1}{\infty}{f(x)dx} = \dint{1}{\infty}{\dfrac{dx}{x^p}}$ converge si $p>1$.

			Donc, $\dsum{n}{1}{\infty}{\dfrac{1}{n^p}}$ converge si $p>1$.
		\end{proof}
	\end{exem}

	\chapter{Suites de fonctions}
	\begin{align*}
		\dlim{n}{\infty}{\dlim{x}{x_0}{f_n(x)}} &\overset{?}{=} \dlim{x}{x_0}{\dlim{n}{\infty}{f_n(x)}}\\
		\dlim{n}{\infty}{\dint{}{}{f_n(x)dx}} &\overset{?}{=} \dint{}{}{\dlim{n}{\infty}{f_n(x)}dx}\\
		\dlim{n}{\infty}{\dfrac{d}{dx}f_n(x)} &\overset{?}{=} \dfrac{d}{dx}\dlim{n}{\infty}{f_n(x)}
	\end{align*}
	\begin{exem}
		~

		\begin{enumerate}
			\item Posons $f_n(x) = x^n$ sur $[0,1]$.

			On a $\dlim{n}{\infty}{\dlim{x}{1}{f_n(x)}} = \dlim{n}{\infty}{\left( \dlim{x}{1}{x^n} \right)} = \dlim{n}{\infty}{1^n} = 1$.

			Cependant, $\dlim{x}{1}{\dlim{n}{\infty}{f_n(x)}} = \dlim{x}{1}{\left( \dlim{n}{\infty}{x^n} \right)} = \dlim{x}{1}{f(x)} = 0$ o\`u $f:[0,1] \to \reels$, avec $x \mapsto \left\lbrace \begin{array}{lll}
				0&\text{si}&0 \lte x<1\\
				1&\text{si}&x=1
			\end{array} \right.$.
			\item Sur $[0,1]$, posons $f_n(x) = \left\lbrace \begin{array}{lll}
				n^2x&\text{si}&x \lte \frac{1}{n}\\
				-n^2x+2n&\text{si}&\frac{1}{n}<x<\frac{2}{n}\\
				0&\text{si}&x \gte \frac{2}{n}
			\end{array} \right.$.

			Posons $f(x)= 0$. On a $\dlim{n}{\infty}{f_n(x)} = f(x)$.

			Ainsi, $\dint{0}{1}{\dlim{n}{\infty}{f_n(x)}dx} = \dint{0}{1}{f(x)dx} = 0$.

			Cependant, $\dlim{n}{\infty}{\dint{0}{1}{f_n(x)dx}} = \dlim{n}{\infty}{\frac{bh}{2}} = \dlim{n}{\infty}{1} = 1$.
			\item Sur $\reels$, posons $f_n(x) = \left\lbrace \begin{array}{lll}
				nx^2+\frac{1}{4n}&\text{si}&\frac{-1}{2n} \lte x \lte \frac{1}{2n}\\
				\abs{x}&\multicolumn{2}{l}{\text{sinon}}
			\end{array} \right.$. On a $f_n'(x) = \left\{ \begin{array}{lll}
				-1&\text{si}&x \lte \frac{-1}{2n}\\
				2nx&\text{si}&\frac{-1}{2n} \lte x \lte \frac{1}{2n}\\
				1&\text{si}&x \gte \frac{1}{2n}
			\end{array} \right.$.

			Ainsi, $\dlim{n}{\infty}{\dfrac{d}{dx}f_n(x)} = \dlim{n}{\infty}{\left\{ \begin{array}{lll}
					-1&\text{si}&x \lte \frac{-1}{2n}\\
					2nx&\text{si}&\frac{-1}{2n} \lte x \lte \frac{1}{2n}\\
					1&\text{si}&x \gte \frac{1}{2n}
				\end{array} \right.} = \left\{ \begin{array}{lll}
				-1&\text{si}&x<0\\
				0&\text{si}&x=0\\
				1&\text{si}&x>0
			\end{array} \right.$.

			Cependant, $\dfrac{d}{dx}\dlim{n}{\infty}{f_n(x)} = \dfrac{d}{dx}\abs{x}$, qui n'existe pas en $x=0$.
		\end{enumerate}
		\begin{center}
			\begin{tikzpicture}[x=.2\textwidth,y=.2\textwidth,smooth]
				\begin{scope}
					\draw[help lines] (0,0) grid (1.1,1.1);

					\draw[->] (-.1,0) -- (1.1,0) node[below] {$x$};
					\draw[->] (0,-.1) -- (0,1.1) node[left] {$y$};

					\node[anchor=north east] (00) at (0,0) {0};
					\draw (1,0) -- ++(0,-.05) node[below] {1};
					\draw (0,1) -- ++(-.05,0) node[left] {1};

					\fill (1,1) circle (2pt) node[above] {(1,1)};

					\draw[thick,red] plot[domain=0:1] (\x,\x);
					\draw[thick,Blue] plot[domain=0:1] (\x,{\x^5});
					\draw[thick,ForestGreen] plot[domain=0:1] (\x,{\x^20});

					\node[red,anchor=west] () at (0,1) {$n=1$};
					\node[Blue,anchor=west] () at (0,.9) {$n=5$};
					\node[ForestGreen,anchor=west] () at (0,.8) {$n=20$};
				\end{scope}
				\begin{scope}[xshift=.3\textwidth]
					\draw[help lines] (0,0) grid (1.1,1.1);

					\draw[->] (-.1,0) -- (1.1,0) node[below] {$x$};
					\draw[->] (0,-.1) -- (0,1.1) node[left] {$y$};

					\node[anchor=north east] (00) at (0,0) {0};
					\draw (1,0) -- ++(0,-.05) node[below] {1};
					\draw (0,1) -- ++(-.05,0) node[left] {1};

					\begin{scope}
						\clip (0,0) rectangle (1,1.12);
						\draw[thick,red] (0,0) -- (1,1);
						\draw[thick,Blue] plot[domain=0:.25] (\x,16*\x) plot[domain=.25:.5] (\x,8-16*\x) plot[domain=.5:1] (\x,0);
						\draw[thick,ForestGreen] plot[domain=0:.1] (\x,100*\x) plot[domain=.1:.2] (\x,20-100*\x) plot[domain=.2:1] (\x,0);
					\end{scope}
					\node[red,anchor=west] () at (.75,.6) {$n=1$};
					\node[Blue,anchor=west] () at (.75,.5) {$n=4$};
					\node[ForestGreen,anchor=west] () at (.75,.4) {$n=10$};
				\end{scope}
				\begin{scope}[xshift=.8\textwidth]
					\draw[help lines] (-1.1,0) grid (1.1,1.1);

					\draw[->] (-1.1,0) -- (1.1,0) node[below] {$x$};
					\draw[->] (0,0) -- (0,1.1) node[left] {$y$};

					\draw (0,0) -- ++(0,-.05) node[below] {0};
					\draw (1,0) -- ++(0,-.05) node[below] {1};
					\draw (-1,0) -- ++(0,-.05) node[below] {-1};
					\draw (-.05,1) -- ++(.1,0) node[above right=-1pt and -4pt] {1};

					\draw[ultra thick,red] plot[domain=-1:-.5] (\x,-\x) plot[domain=-.5:.5] (\x,\x*\x+.25) plot[domain=.5:1] (\x,\x);
					\draw[very thick,Blue] plot[domain=-1:-.25] (\x,-\x) plot[domain=-.25:.25] (\x,2*\x*\x+.125) plot[domain=.25:1] (\x,\x);
					\draw[thick,ForestGreen] plot[domain=-1:-.05] (\x,-\x) plot[domain=-.05:.05] (\x,10*\x*\x+.025) plot[domain=.05:1] (\x,\x);

					\node[red,anchor=west] () at (-.1,.8) {$n=1$};
					\node[Blue,anchor=west] () at (-.1,.7) {$n=2$};
					\node[ForestGreen,anchor=west] () at (-.1,.6) {$n=10$};
				\end{scope}
			\end{tikzpicture}
		\end{center}
	\end{exem}

	\begin{rapp}~

		$(f_n) \to f$ (convergence ponctuelle)

		$(\forall  x \in \mathcal{D}), (f_n(x)) \to f(x)$ ou encore, $\dlim{n}{\infty}{f_n(x)} = f(x)$, c'est-\`a-dire $(\forall\eps>0), (\exists N>0)$ t.q. $n>N \Rightarrow \abs{f_n(x) - f(x)} < \eps$.
	\end{rapp}
	\begin{defin}
		~

		\begin{enumerate}
			\item La \emph{norme supremum} de $f$, not\'ee $\norme{f}$, est $\norme{f} = \sup\limits_{x \in \mathcal{D}}\abs{f(x)}$, o\`u $f:\mathcal{D}\to\reels$.
			\item La \emph{distance} entre $f,g:\mathcal{D}\to\reels$ est $\mathrm{dist}(f,g) = \norme{f-g}$.
			\item On dit que $(f_n)_{n \in \naturels}$ \emph{converge uniform\'ement} vers $f$ si $\dlim{n}{\infty}{\mathrm{dist}(f_n,f)}=0$.
		\end{enumerate}
	\end{defin}
	\begin{exem}
		~

		\begin{enumerate}
			\item Sur $[0,\frac{1}{2}]$, prenons $f_n(x)=x^n$ et $f(x) = 0$. On a
			\begin{align*}
				\dlim{n}{\infty}{\mathrm{dist}(f_n,f)}&= \dlim{n}{\infty}{\norme{f_n-0}}\\
				&= \dlim{n}{\infty}{\sup\limits_{x \in [0,\sfrac{1}{2}]}\abs{f_n(x)}}\\
				&= \dlim{n}{\infty}{\left(\dfrac{1}{2}\right)^n}\\
				&= 0
			\end{align*}
			\item Sur $[0,1]$, prenons $f_n(x)=x^n$ et $f(x) = \left\lbrace \begin{array}{lll}
				0&\text{si}&0\lte x<1\\
				1&\text{si}&x=1
			\end{array}\right.$. On a
			\begin{align*}
				\dlim{n}{\infty}{\mathrm{dist}(f_n,f)}&= \dlim{n}{\infty}{\sup\limits_{x \in [0,1]}\abs{f_n(x)-f(x)}}\\
				&= \dlim{n}{\infty}{\sup\limits_{x \in [0,1[}\abs{f_n(x)-f(x)}}&\text{car }f_n(1)-f(1)&=0\\
				&= \dlim{n}{\infty}{\sup\limits_{x \in [0,1[}\abs{x^n}}\\
				&= \dlim{n}{\infty}{1}\\
				&= 1
			\end{align*}

			Donc, $f_n \not\convuni f$ sur $[0,1]$.
		\end{enumerate}
		\begin{nota}
			On note la convergence uniforme et la convergence ponctuelle d'une suite de fonction vers une fonction $f_n \convuni f$ et $f_n \to f$ respectivement.
		\end{nota}
	\end{exem}
	\begin{prop}
		$f_n \convuni f \Rightarrow f_n \to f$.
		\begin{proof}~

			$f_n \convuni f \Rightarrow \dlim{n}{\infty}{\sup\limits_{x \in \mathcal{D}}\abs{f_n(x)-f(x)}}=0$.

			Alors, $\dlim{n}{\infty}{\abs{f_n(x)-f(x)}}=0$, $\forall x \in \mathcal{D}$.

			Ainsi, $f_n \to f$.
		\end{proof}
	\end{prop}
	\begin{prop}
		Si $f_n \to f$ et $f_n \convuni g$, alors $f=g$.
		\begin{proof}~

			$f_n \to f \Rightarrow f_n(x) \to f(x)$, $\forall x \in \mathcal{D}$.

			$f_n \convuni g \Rightarrow f_n \to g \Rightarrow f_n(x) \to g(x)$, $\forall x \in \mathcal{D}$.

			Ainsi, $f(x)=g(x)$, $\forall x \in \mathcal{D}$.
		\end{proof}
	\end{prop}
	\begin{thm}
		~

		Supposons que $(f_n)$ sont continues sur $\mathcal{D}$.

		Si $f_n \convuni f$, alors $f$ est continue sur $\mathcal{D}$.
		\begin{proof}~

			Soit $\eps>0$.

			Soit $x_0 \in \mathcal{D}$.

			On veut montrer que $f$ est continue en $x_0$, c'est-\`a-dire $\exists\delta>0$ t.q. $\abs{x-x_0}<\delta \Rightarrow \abs{f(x)-f(x_0)}<\eps$.

			Comme $(f_n) \convuni f$, on a $\dlim{n}{\infty}{\mathrm{dist}(f_n,f)}=0$.

			Ainsi, $\exists M>0$ t.q. $n \gte M \Rightarrow \mathrm{dist}(f_n,f) < \dfrac{\eps}{3}$.

			En particulier, $\mathrm{dist}(f_M,f) < \dfrac{\eps}{3}$, c'est-\`a-dire $\sup\limits_{x \in \mathcal{D}}\abs{f_M(x)-f(x)} < \dfrac{\eps}{3}$ et donc, $\abs{f_M(x_0)-f(x_0)} < \dfrac{\eps}{3}$.

			De plus, $f_n$ continue sur $\mathcal{D} \Rightarrow f_M$ continue en $x_0$.

			Ainsi, $(\exists\delta>0)$ t.q. $\abs{x-x_0} < \delta \Rightarrow \abs{f_M(x)-f_M(x_0)} < \dfrac{\eps}{3}$.

			Supposons donc que $\abs{x-x_0} < \delta$. On a
			\begin{align*}
				\abs{f(x)-f(x_0)}&= \abs{f(x) - f_M(x) + f_M(x) - f_M(x_0) + f_M(x_0) - f(x_0)}\\
				&\lte \abs{f(x)-f_M(x)} + \abs{f_M(x)-f_M(x_0)} + \abs{f_M(x_0)-f(x_0)}\\
				&< \dfrac{\eps}{3} + \dfrac{\eps}{3} + \dfrac{\eps}{3}\\
				&= \eps
			\end{align*}
		\end{proof}
		\begin{coro}
			~

			Si $f_n$ continues et $f_n \convuni f$, alors $\dlim{n}{\infty}{\dlim{x}{x_0}{f_n(x)}} = \dlim{x}{x_0}{\dlim{n}{\infty}{f_n(x)}}$.

			Comme $f_n$ est continue en $x_0$, $\dlim{n}{\infty}{\dlim{x}{x_0}{f_n(x)}} = \dlim{n}{\infty}{f_n(x_0)} = f(x_0)$.

			Comme $f$ est continue en $x_0$, $f(x_0) = \dlim{x}{x_0}{f(x)} = \dlim{x}{x_0}{\dlim{n}{\infty}{f_n(x)}}$.
		\end{coro}
	\end{thm}
	\begin{thm}~

		Soient $(f_n)_{n \in \naturels}$ continues sur $[a,b]$.

		Si $f_n \convuni f$, alors
		\[
		\dlim{n}{\infty}{\dint{a}{b}{f_n(x)dx}} = \dint{a}{b}{\underbrace{\dlim{n}{\infty}{f_n(x)}}_{f}dx}
		\]
		\begin{proof}~

			$f_n$ continues et $f_n \convuni f$, alors $f \in \continue$, donc $f \in \riemann$.

			On a
			\begin{align*}
				\dlim{n}{\infty}{\abs{\dint{a}{b}{f_n(x)dx} - \dint{a}{b}{f(x)dx}}}&= \dlim{n}{\infty}{\abs{\dint{a}{b}{(f_n-f)(x)dx}}}\\
				&\lte \dlim{n}{\infty}{\dint{a}{b}{\abs{f_n(x)-f(x)}dx}}\\
				&\lte \dlim{n}{\infty}{(b-a) \sup\limits_{x \in [a,b]}\abs{f_n(x)-f(x)}}\\
				&= (b-a) \dlim{n}{\infty}{\mathrm{dist}(f_n,f)}\\
				&= 0&\text{car }f_n \convuni f
			\end{align*}
		\end{proof}
	\end{thm}
	\begin{thm}~

		Soient $(f_n)_{n \in \naturels}$ des fonctions de classe $C^1$ (c'est-\`a-dire d\'erivable \`a d\'eriv\'ee continue).

		Supposons
		\begin{enumerate}[label=\roman*)]
			\item $f_n' \convuni g$;
			\item $\dlim{n}{\infty}{f_n(a)}$ existe pour au moins un $a$.
		\end{enumerate}

		Alors,
		\begin{enumerate}[label=\alph*)]
			\item $f_n$ converge ponctuellement vers $f$;
			\item $f \in C^1$;
			\item $f'=g$, c'est-\`a-dire $\dfrac{d}{dx}\dlim{n}{\infty}{f_n(x)} = \dlim{n}{\infty}{\dfrac{d}{dx}f_n(x)}$.
		\end{enumerate}
		\begin{proof}~

			Supposons $L = \dlim{n}{\infty}{f_n(a)}$ pour un certain $a$.

			On a $f_n \in C^1$, alors $f_n'$ est continue.

			De plus, $f_n' \convuni g$, donc $g$ est continue.

			Alors, $\dlim{n}{\infty}{\dint{a}{x}{f_n'(t)dt}} = \dint{a}{x}{\dlim{n}{\infty}{f_n'(t)}dt} = \dint{a}{x}{g(t)dt}$, pour tout $x$.

			Du th\'eor\`eme fondamental du calcul, $\dint{a}{x}{f_n'(t)dt} = f_n(x)-f_n(a)$.

			On a
			\begin{align*}
				f(x)&= \dlim{n}{\infty}{f_n(x)}\\
				&= \dlim{n}{\infty}{\left[ \dint{a}{x}{f_n'(t)dt} + f_n(a) \right]}\\
				&= L + \dlim{n}{\infty}{\dint{a}{x}{f_n'(t)dt}}\\
				&= L + \dint{a}{x}{\dlim{n}{\infty}{f_n'(t)}dt}\\
				&= L + \dint{a}{x}{g(t)dt}
			\end{align*}

			Ainsi, $f'(x) = \dfrac{d}{dx}\left( L + \dint{a}{x}{g(t)dt} \right) = \dfrac{d}{dx}\dint{a}{x}{g(t)dt} = g(x)$.

			D'o\`u b) et c), $f \in C^1$ avec $f'=g$.
		\end{proof}
	\end{thm}

	\chapter{S\'eries de fonctions}
	\section{Convergence uniforme de s\'erie}
	\begin{defin}~

		Soient $(f_k)_{k \in \naturels}$ des fonctions $f_k:A \to \reels$.

		La \emph{s\'erie} des $f_k$ est la suite $(s_n)_{n \in \naturels}$, o\`u $s_n(x) = \dsum{k}{0}{n}{f_k(x)}$.

		Si la suite $(s_n(x))$ converge ponctuellement vers une fonction $s(x)$, alors $\dlim{n}{\infty}{s_n(x)}$ est appel\'ee la \emph{somme} de la s\'erie, c'est-\`a-dire, $s = \dlim{n}{\infty}{s_n(x)} = \dsum{k}{0}{\infty}{f_k(x)}$.
	\end{defin}
	\begin{exem}~

		$f_k(x) = x^k$, pour $x \in \reels$.

		On cherche $\dsum{k}{0}{\infty}{f_k(x)} = \dsum{k}{0}{\infty}{x^k}$.

		D'Alembert: $L = \dlim{k}{\infty}{\abs{\dfrac{x^{k+1}}{x^k}}} = \dlim{k}{\infty}{\abs{x}} = \abs{x}$. On a convergence si $L<1$, c'est-\`a-dire $-1<x<1$.

		Si $x=-1$, alors $\dsum{k}{0}{\infty}{x^k} = \dsum{k}{0}{\infty}{(-1)^k}$ oscille.

		Si $x=1$, alors $\dsum{k}{0}{\infty}{x^k} = \dsum{k}{0}{\infty}{1^k}$ diverge.

		Donc, la s\'erie converge sur $]-1,1[$.

		On a, sur $]-1,1[$, $s = \dlim{n}{\infty}{s_n} = \dlim{n}{\infty}{\dsum{k}{0}{n}{x^k}} = \dlim{n}{\infty}{\dfrac{1-x^{n+1}}{1-x}} = \dfrac{1}{1-x}$.
	\end{exem}
	\begin{defin}~

		La s\'erie de fonctions $\dsum{k}{0}{\infty}{f_k}$ \emph{converge uniform\'ement} sur $A$ vers une fonction $s:A \to \reels$ si $\left(s_n=\dsum{k}{0}{n}{f_k}\right)_{n \in \naturels} \convuni s$, c'est-\`a-dire si $\dlim{n}{\infty}{\sup\limits_{x \in A}\abs{s_n(x)-s(x)}}=0$.
	\end{defin}
	\begin{exem}~

		\begin{enumerate}[label=\alph*)]
			\item $f_k(x)=x^k$ sur $A=\left[ -\frac{1}{2}, \frac{1}{2} \right]$. On a
			\begin{align*}
				\dlim{n}{\infty}{\sup\limits_{x \in A}\abs{\dsum{k}{0}{n}{x^k} - \dsum{k}{0}{\infty}{x^k}}}&= \dlim{n}{\infty}{\sup\limits_{x \in A}\abs{-\dsum{k}{n+1}{\infty}{x^k}}}\\
				&\lte \dlim{n}{\infty}{\sup\limits_{x \in A}\dsum{k}{n+1}{\infty}{\abs{x^k}}}\\
				&= \dlim{n}{\infty}{\dsum{k}{n+1}{\infty}{\left(\frac{1}{2}\right)^k}}\\
				&= \dlim{n}{\infty}{\left(\frac{1}{2}\right)^{n+1}\dsum{k}{0}{\infty}{\left(\frac{1}{2}\right)^k}}\\
				&= \dlim{n}{\infty}{\left(\frac{1}{2}\right)^{n+1} \cdot \dfrac{1}{1-\frac{1}{2}}}\\
				&= \dlim{n}{\infty}{\left(\frac{1}{2}\right)^n} = 0
			\end{align*}

			Donc, $\dsum{k}{0}{\infty}{x^k} \convuni \dfrac{1}{1-x}$ sur $\left[-\frac{1}{2}, \frac{1}{2}\right]$.
			\item $f_k(x) = x^k$ sur $A=\left]-1,1\right[$.
			\begin{align*}
				\dlim{n}{\infty}{\sup\limits_{x \in A}\abs{\dsum{k}{0}{n}{x^k} - \dsum{k}{0}{\infty}{x^k}}}&= \dlim{n}{\infty}{\sup\limits_{x \in A}\abs{\dsum{k}{n+1}{\infty}{x^k}}}\\
				&= \dlim{n}{\infty}{\abs{\dsum{k}{n+1}{\infty}{1^k}}}\\
				&\neq 0
			\end{align*}
		\end{enumerate}
	\end{exem}
	\begin{thm}[Crit\`ere de Weierstrass]~

		Soient $(f_k:A \to \reels)_{k \in \naturels}$ t.q.
		\begin{enumerate}[label=\roman*),nosep]
			\item $(\forall k)(\exists M=M_k)(\forall x \in A), \abs{f_k(x)} \lte M_k$;
			\item $\dsum{k}{0}{\infty}{M_k}$ converge.
		\end{enumerate}

		Alors, $\dsum{k}{0}{\infty}{f_k}$ converge uniform\'ement.
		\begin{proof}~

			Soit $x \in A$.

			On a $\dsum{k}{0}{\infty}{\abs{f_k(x)}} \lte \dsum{k}{0}{\infty}{M_k}$, par \textit{i)}, qui converge, par \textit{ii)}.

			Donc, $\dsum{k}{0}{\infty}{f_k(x)}$ converge absolument et donc converge.

			De plus, sur $A$,
			\begin{align*}
				\dlim{n}{\infty}{\sup\limits_{x \in A}\abs{s(x)-s_n(x)}}&= \dlim{n}{\infty}{\sup\limits_{x \in A}\abs{\dsum{k}{n+1}{\infty}{f_k(x)}}}\\
				&\lte \dlim{n}{\infty}{\sup\limits_{x \in A}\dsum{k}{n+1}{\infty}{\abs{f_k(x)}}}\\
				&\lte \dlim{n}{\infty}{\dsum{k}{n+1}{\infty}{M_k}}
			\end{align*}
			d'o\`u la convergence uniforme.
		\end{proof}
	\end{thm}
	\begin{exem}~

		\'Etudions la convergence uniforme de $\dsum{k}{1}{\infty}{\dfrac{\cos kx}{k^2}}$.

		On a
		\begin{enumerate}[label=\roman*)]
			\item $\abs{\dfrac{\cos kx}{k^2}} \lte \dfrac{1}{k^2}$;
			\item $\dsum{k}{1}{\infty}{\dfrac{1}{k^2}} = \dfrac{\pi^2}{6}$ converge.
		\end{enumerate}

		Donc, $\dsum{k}{1}{\infty}{\dfrac{\cos kx}{k^2}}$ converge uniform\'ement.
	\end{exem}
	\begin{thm}~

		$(f_k:A \to \reels)$, $f_k$ continue, $\dsum{k}{0}{\infty}{f_k} \convuni s$, alors $s$ est continue sur $A$.
		\begin{proof}~

			$\dsum{k}{0}{\infty}{f_k} \convuni s \Rightarrow (s_n) \convuni s$.

			Or, $s_n = \dsum{k}{0}{n}{f_k}$ est continue.

			Alors, $s$ est continue.
		\end{proof}
	\end{thm}
	\begin{thm}~

		$f_k$ continue et $\dsum{k}{0}{\infty}{f_k}$ converge uniform\'ement, alors $\dsum{k}{0}{\infty}{\dint{a}{b}{f_k(x)dx}} = \dint{a}{b}{\dsum{k}{0}{\infty}{f_k(x)}dx}$.
		\begin{proof}~

			\begin{align*}
				\dsum{k}{0}{\infty}{\dint{a}{b}{f_k(x)dx}}&= \dlim{n}{\infty}{\dsum{k}{0}{n}{\dint{a}{b}{f_k(x)dx}}}\\
				\text{\footnotesize puisque la somme est finie}&= \dlim{n}{\infty}{\dint{a}{b}{\dsum{k}{0}{n}{f_k(x)}dx}}\\
				&= \dlim{n}{\infty}{\dint{a}{b}{s_n(x)dx}}
			\end{align*}
			Or, $f_k$ continue $\Rightarrow$ $s_n$ continue et $\dsum{k}{0}{\infty}{f_k}$ converge uniform\'ement $\Leftrightarrow$ $(s_n)_{n \in \naturels}$ converge uniform\'ement.
			\begin{align*}
				\dlim{n}{\infty}{\dint{a}{b}{s_n(x)dx}}&= \dint{a}{b}{\dlim{n}{\infty}{s_n(x)}dx}\\
				&= \dint{a}{b}{\dlim{n}{\infty}{\dsum{k}{0}{n}{f_k(x)}}dx}\\
				&= \dint{a}{b}{\dsum{k}{0}{\infty}{f_k(x)}dx}
			\end{align*}
		\end{proof}
	\end{thm}
	\begin{thm}~

		$f_k \in C^1$ sur $A$, $\dsum{k}{0}{\infty}{f_k'} \convuni u$ et $\dsum{k}{0}{\infty}{f_k(a)}$ converge pour au moins un $a \in A$, alors
		\begin{enumerate}[label=\alph*)]
			\item $\dsum{k}{0}{\infty}{f_k}$ converge uniform\'ement vers $s$;
			\item $s \in C^1$ sur $A$;
			\item $s'=u$, c'est-\`a-dire $\dfrac{d}{dx}\dsum{k}{0}{\infty}{f_k} = \dsum{k}{0}{\infty}{\dfrac{d}{dx}f_k(x)}$.
		\end{enumerate}
		\begin{proof}~

			Comme au chapitre pr\'ec\'edent.
		\end{proof}
	\end{thm}
	\begin{exem}~

		$f_k(x) = \dfrac{\sin kx}{k^3}$, $k \in \naturels_*$.

		On a
		\begin{enumerate}[label=\roman*)]
			\item $f_k \in C^1$ sur $\reels$;
			\item $\dsum{k}{0}{\infty}{f_k'(x)} = \dsum{k}{0}{\infty}{\dfrac{\cos kx}{k^2}}$ converge uniform\'ement (Weierstrass);
			\item $\dsum{k}{0}{\infty}{f_k(0)} = \dsum{k}{0}{\infty}{\dfrac{\sin 0k}{k^3}} = 0$ converge.
		\end{enumerate}

		Alors, $\dfrac{d}{dx}\dsum{k}{0}{\infty}{f_k(x)} = \dsum{k}{0}{\infty}{\dfrac{d}{dx}f_k(x)} = \dsum{k}{0}{\infty}{\dfrac{\cos kx}{k^2}} = \dfrac{d}{dx}\dsum{k}{0}{\infty}{\dfrac{\sin kx}{x^3}}$
	\end{exem}
	\section{S\'eries de puissances}
	\begin{defin}~

		Si $f_k(x) = a_k \cdot (x-x_0)^k$, alors $\dsum{k}{0}{\infty}{f_k(x)}$ est une \emph{s\'erie de puissance}.
	\end{defin}
	\begin{exem}~

		$f(x) = \dsum{i}{0}{\infty}{\dfrac{x^i}{i!}} = \dsum{i}{0}{\infty}{\dfrac{1}{i!} \cdot (x-0)^i}$, o\`u $a_i=\frac{1}{i!}$ et $x_0=0$.
	\end{exem}
	\begin{thm}~

		Soit $R = \dlim{k}{\infty}{\abs{\dfrac{a_k}{a_{k+1}}}}$. Alors,
		\begin{enumerate}[label=\alph*)]
			\item $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ converge sur $]x_0-R, x_0+R[$;
			\item Si $R>0$ et $0<r<R$, alors $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ converge uniform\'ement sur $[x_0-r, x_0+r]$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item Fixons $x$.

				Posons $b_k = a_k(x-x_0)^k$.

				Consid\'erons la s\'erie r\'eelle $\dsum{k}{0}{\infty}{b_k}$.

				De d'Alembert, la s\'erie converge si, et seulement si, $L<1$, avec $L = \dlim{n}{\infty}{\abs{\dfrac{b_{n+1}}{b_n}}} = \dlim{n}{\infty}{\abs{\dfrac{a_{n+1}(x-x_0)^{n+1}}{a_n(x-x_0)^n}}} = \abs{x-x_0} \dlim{n}{\infty}{\abs{\dfrac{a_{n+1}}{a_n}}} = \dfrac{\abs{x-x_0}}{\dlim{n}{\infty}{\abs{\dfrac{a_n}{a_{n+1}}}}} = \dfrac{\abs{x-x_0}}{R}$.

				Donc, $\dsum{k}{0}{\infty}{b_k}$ converge si, et seulement si, $L<1$, c'est-\`a-dire $\dfrac{\abs{x-x_0}}{R}<1 \Leftrightarrow \abs{x-x_0} < R \Leftrightarrow x \in ]x_0-R, x_0+R[$.
				\item Supposons que $R>0$ et soit $0<r<R$.

				Pour $x \in [x_0-r, x_0+r]$, on a
				\begin{enumerate}[label=\roman*)]
					\item $\abs{f_k(x)} = \abs{a_k(x-x_0)^k} = \abs{a_k} \abs{x-x_0}^k \lte \abs{a_k} r^k$
					\item $\dsum{k}{0}{\infty}{\abs{a_k}r^k}$ converge.

					En effet, $L = \dlim{n}{\infty}{\abs{\dfrac{a_{n+1}r^{n+1}}{a_nr^n}}} = r \dlim{n}{\infty}{\abs{\dfrac{a_{n+1}}{a_n}}} = \dfrac{r}{\dlim{n}{\infty}{\abs{\dfrac{a_n}{a_{n+1}}}}} = \dfrac{r}{R}$.

					Ainsi, $L<1 \Leftrightarrow \dfrac{r}{R}<1 \Leftrightarrow r<R$.
				\end{enumerate}

				De Weierstrass, $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ converge uniform\'ement sur $[x_0-r, x_0+r]$.
			\end{enumerate}
		\end{proof}
	\end{thm}
	\begin{defin}~

		$R=\dlim{k}{\infty}{\abs{\dfrac{a_k}{a_{k+1}}}}$ est le \emph{rayon de convergence} de la s\'erie.
	\end{defin}
	\begin{exem}~

		\begin{enumerate}[label=\alph*)]
			\item $\dsum{i}{0}{\infty}{\dfrac{x^i}{i!}} = \dsum{i}{0}{\infty}{\frac{1}{i!}(x-0)^i}$

			$R = \dlim{i}{\infty}{\abs{\dfrac{\frac{1}{i!}}{\frac{1}{(i+1)!}}}} = \dlim{i}{\infty}{(i+1)} = \infty$.

			Donc, $\dsum{i}{0}{\infty}{\dfrac{x^i}{i!}}$ converge sur tout $\reels$.
			\item $\dsum{k}{1}{\infty}{\dfrac{x^k}{k}} = \dsum{k}{1}{\infty}{\frac{1}{k}(x-0)^k}$

			$R \dlim{k}{\infty}{\abs{\dfrac{\sfrac{1}{k}}{\sfrac{1}{(k+1)}}}} = \dlim{k}{\infty}{\abs{\dfrac{k+1}{k}}} = 1$.

			Donc, $\dsum{k}{1}{\infty}{\dfrac{x^k}{k}}$ converge sur $]-1,1[$ converge unifirm\'ement sur $[-r,r]$ avec $0<r<1$.

			Pour $x=\frac{1}{2}$, on a $\dsum{k}{1}{\infty}{\dfrac{1}{k \cdot 2^k}} = \dsum{k}{1}{\infty}{\dfrac{(\sfrac{1}{2})^k}}{k} = \dsum{k}{1}{\infty}{\dint{0}{\sfrac{1}{2}}{x^{k-1}dx}}$.

			Puisque $\frac{x^k}{k}$ est continue pour tout $k$ et $\sum\frac{x^k}{k}$ converge uniform\'ement, on a $\dsum{k}{1}{\infty}{\dint{0}{\sfrac{1}{2}}{x^{k-1}dx}} = \dint{0}{\sfrac{1}{2}}{\dsum{k}{1}{\infty}{x^{k-1}}dx} = \dint{0}{\sfrac{1}{2}}{\dsum{k}{0}{\infty}{x_k}dx} = \dint{0}{\sfrac{1}{2}}{\dfrac{1}{1-x}dx} = -\ln\abs{1-x}\big|_0^{\sfrac{1}{2}} = -\ln\frac{1}{2} + \ln1 = \ln2$.
		\end{enumerate}
	\end{exem}
	\begin{coro}~

		Supposons que $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ converge vers $f$ sur $]x_0-R,x_0+R[$. Alors,
		\begin{enumerate}[label=\alph*)]
			\item $\dsum{k}{0}{\infty}{\dfrac{d}{dx}(a_k(x-x_0)^k)}$ est une s\'erie de puissance qui converge sur $]x_0-R,x_0+R[$;
			\item $f \in C^\infty$ sur $]x_0-R,x_0+R[$;
			\item $\dfrac{d^n}{dx^n}f = \dfrac{d^n}{dx^n}\dsum{k}{0}{\infty}{a_k(x-x_0)^k} = \dsum{k}{0}{\infty}{\dfrac{d^n}{dx^n}(a_k(x-x_0)^k)}$.
		\end{enumerate}\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item $\dsum{k}{0}{\infty}{\dfrac{d}{dx}(a_k(x-x_0)^k)} = \dsum{k}{0}{\infty}{ka_k(x-x_0)^{k-1}} = \dsum{k}{1}{\infty}{ka_k(x-x_0)^{k-1}} = \dsum{k}{0}{\infty}{(k+1)a_{k+1}(x-x_0)^k}$ qui est effectivement une s\'erie de puissance.

				$\dlim{k}{\infty}{\abs{\dfrac{(k+1)a_{k+1}}{(k+2)a_{k+2}}}} = \dlim{k}{\infty}{\abs{\dfrac{k+1}{k+2}}} \cdot \dlim{k}{\infty}{\abs{\dfrac{a_{k+1}}{a_{k+2}}}} = 1 \cdot \dlim{k}{\infty}{\abs{\dfrac{a_k}{a_{k+1}}}} = R$.
				\item[b),c)] Soit $x \in ]x_0-R,x_0+R[$. Alors, $\exists 0<r<R$ t.q. $x \in [x_0-r,x_0+r]$. On sait que $\dsum{k}{0}{\infty}{\dfrac{d}{dx}(a_k(x-x_0)^k)}$ converge uniform\'ement sur $[x_0-r,x_0+r]$.

				De plus, $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ converge pour au moins un $a \in [x_0-r,x_0+r]$.

				Du th\'eor\`eme, $f'(x) = \dfrac{d}{dx}\dsum{k}{0}{\infty}{a_k(x-x_0)^k} = \dsum{k}{0}{\infty}{\dfrac{d}{dx}(a_k(x-x_0)^k)} = \dsum{k}{1}{\infty}{ka_k(x-x_0)^{k-1}}$.

				Donc, $f'$ est continue et $\dfrac{d}{dx}\dsum{k}{0}{\infty}{a_k(x-x_0)^k} = \dsum{k}{0}{\infty}{\dfrac{d}{dx}(a_k(x-x_0)^k)}$.

				Par r\'ecurrence, on obtient les r\'esultats.
			\end{enumerate}
		\end{proof}
	\end{coro}
	\begin{coro}~

		Supposons que $\dsum{k}{0}{\infty}{a_k(x-x_0)^k} = f$, sur $]x_0-R, x_0+R[$. Alors, $a_k = \dfrac{\left(\dfrac{d^k}{dx^k}f\right)(x_0)}{k!}$.
		\begin{proof}~

			\begin{align*}
				f^{(n)}(x)&= \dfrac{d^n}{dx^n}\dsum{k}{0}{\infty}{a_K(x-x_0)^k}\\
				&= \dsum{k}{0}{\infty}{\dfrac{d^n}{dx^n}(a_k(x-x_0)^k)}\\
				&= \dfrac{d^n}{dx^n}(a_0) + \dfrac{d^n}{dx^n}(a_1(x-x_0)) + \dotsb + \dfrac{d^n}{dx^n}(a_n(x-x_0)^n) + \dfrac{d^n}{dx^n}(a_{n+1}(x-x_0)^{n+1}) + \dotsb\\
				&= 0 + 0 + \dotsb + a_n(n)(n-1)\dotsb(2)(1) + a^{n+1}(n+1)(n)(n-1)\dots(3)(2)(x-x_0) + \dotsb
			\end{align*}

			Ainsi, $f^{(n)}(x_0) = 0 + \dotsb + 0 + a_n \cdot n! + 0 + \dotsb = a_n \cdot n!$, donc $a_n = \dfrac{f^{(n)}(x_0)}{n!}$.
		\end{proof}
	\end{coro}

	\section{S\'eries de Taylor}
	\begin{thm}~

		Soient $n \in \naturels$, $f:A \to \reels$ de classe $C^{n+1}$ sur $A$ et $x_0 \in A$.

		Alors, $(\forall x \in A)$, $f(x) = \dsum{k}{0}{n}{\dfrac{f^{(k)}(x_0)}{k!}(x-x_0)^k} + R_n(x_0, x)$, o\`u $R_n(x_0, x) = \dint{x_0}{x}{\dfrac{f^{(n+1)}(t)(x-t)^n}{n!} dt}$.
		\begin{proof}~

			\begin{itemize}
				\item[Base:] Pour $n=0$, la formule devient
				\begin{align*}
					f(x)&= \dfrac{f^{(0)}(x_0)}{0!}(x-x_0)^0 + R_0(x_0, x)\\
					&= f(x_0) + \dint{x_0}{x}{f'(t) dt}\\
					\dint{x_0}{x}{f'(t) dt}&= f(x)-f(x_0)
				\end{align*}
				qui est le th\'eor\`eme fondamental du calcul.
				\item[Hyp:] Supposons vrai pour $n$.
				\item[Pas:] On a $f(x) = \dsum{k}{0}{n}{\dfrac{f^{(k)}(x_0)}{k!}(x-x_0)^k} + R_n(x_0, x)$.

				Or,
				\begin{align*}
					R_n(x_0, x)&= \dint{x_0}{x}{\dfrac{f^{(n+1)}(t)}{n!}(x-t)^n dt}
				\end{align*}
				posons $u = f^{(n+1)}(t)$, donc $du = f^{(n+2)}(t)dt$ et $dv = \dfrac{(x-t)^n}{n!}dt$, donc $v = -\dfrac{(x-t)^{n+1}}{(n+1)!}$.
				\begin{align*}
					&= \left. \dfrac{f^{(n+1)}(t)(x-t)^{n+1}}{(n+1)!} \right|_{x_0}^x + \dint{x_0}{x}{\dfrac{f^{(n+2)}(t)}{(n+1)!}(x-t)^{n+1} dt}\\
					&= \dfrac{f^{(n+1)}(x_0)}{(n+1)!}(x-x_0)^{n+1} + R_{n+1}(x_0, x)
				\end{align*}

				Donc, $f(x) = \dsum{k}{0}{n+1}{\dfrac{f^{(k)}(x_0)}{k!}(x-x_0)^k} + R_{n+1}(x_0, x)$.
			\end{itemize}
		\end{proof}
	\end{thm}
	\begin{thm}~

		S'il existe $M>0$ t.q. $\abs{f^{(n+1)}(t)} \lte M^{n+1}$ pour tout $t \in [x_0, x]$, alors
		\[
			R_n(x_0, x) \xrightarrow{n \to \infty} 0
		\]
		\begin{proof}~

			\begin{align*}
				\abs{R_n(x_0, x)}&= \abs{\dint{x_0}{x}{\dfrac{f^{(n+1)}(t)}{n!}(x-t)^n dt}}\\
				&\lte \dint{x_0}{x}{\dfrac{\abs{f^{(n+1)}(t)}}{n!}(x-t)^n dt}\\
				&\lte \dfrac{M^{n+1}}{n!}\dint{x_0}{x}{(x-t)^n dt}\\
				&= \dfrac{M^{n+1}}{n!} \cdot \left. \dfrac{-(x-t)^{n+1}}{n+1} \right|_{x_0}^x\\
				&= \dfrac{M^{n+1}}{(n+1)!}(x-x_0)^{n+1}\\
				&= \dfrac{(M(x-x_0))^{n+1}}{(n+1)!}\\
				\text{\footnotesize Stirling: $n! \simeq \sqrt{2\pi n}\left(\frac{n}{e}\right)^n$}\\
				&\xrightarrow{n \to \infty} 0
			\end{align*}
		\end{proof}
	\end{thm}
	\begin{coro}~

		Sous ces conditions, $f(x) = \dsum{k}{0}{\infty}{\dfrac{f^{(n)}(x_0)}{k!}(x-x_0)^k}$, la s\'erie de Taylor de $f$ autour de $x_0$.
	\end{coro}
	\begin{coro}~

		Si la s\'erie de puissance $\dsum{k}{0}{\infty}{a_k(x-x_0)^k}$ a comme limite $f$, alors la s\'erie de puissance est la s\'erie de Taylor de $f$ autour de $x_0$.
	\end{coro}
	\begin{exem}~

		\begin{enumerate}[label=\alph*)]
			\item $\cos x$, avec $x_0=0$.
			\[
			\begin{array}{rlrcl}
				\cos x&:\qquad&\cos0&=&0\\
				-\sin x&:&-\sin0&=&0\\
				-\cos x&:&-\cos0&=&-1\\
				\sin x&:&\sin0&=&0
			\end{array}
			\]

			Ainsi, $\cos x = 1 - \dfrac{x^2}{2!} + \dfrac{x^4}{4!} - \dfrac{x^6}{6!} + \dotsb + \dfrac{(-1)^n}{(2n)!}x^{2n} + R_n(0, x)$.

			On a
			\begin{align*}
				R&= \dlim{k}{\infty}{\abs{\dfrac{a_k}{a_{k+1}}}}\\
				&= \dlim{k}{\infty}{\abs{\dfrac{\dfrac{(-1)^k}{(2k)!}}{\dfrac{(-1)^{k+1}}{(2(k+1))!}}}}\\
				&= \dlim{k}{\infty}{\abs{(2k+2)(2k+1)}}\\
				&= \infty
			\end{align*}

			On veut montrer que $R_n(0, x) \xrightarrow{n \to \infty} 0, (\forall x \in \reels)$.

			Pour $x>0$, on a
			\begin{align*}
				R_n(0, x)&= \dint{0}{x}{\dfrac{\cos^{(n+1)}(t) (x-t)^n}{n!} dt}\\
				&\lte \dint{0}{x}{\dfrac{(x-t)^n}{n!} dt}\\
				&= \left. \dfrac{-(x-t)^{n+1}}{(n+1)!} \right|_0^x\\
				&= \dfrac{x^{n+1}}{(n+1)!}\\
				&= \dfrac{\abs{x}^{n+1}}{(n+1)!}
			\end{align*}

			Pour $x<0$, $R_n(0, x) \gte \dfrac{-\abs{x}^{n+1}}{(n+1)!}$.

			Donc, $\abs{R_n(0, x)} \lte \dfrac{\abs{x}^{n+1}}{(n+1)!} \xrightarrow{n \to \infty} 0$.

			Donc, $\cos x = \dsum{k}{0}{\infty}{\dfrac{(-1)^kx^{2k}}{(2k)!}}$.
			\item $f(x)=\frac{1}{x}$, avec $x_0=1$.
			\[
			\begin{array}{rcllrcl}
				f(x)&=&\frac{1}{x}&:\qquad&f(1)&=&1\\
				f'(x)&=&-x^{-2}&:&f'(1)&=&-1\\
				f''(x)&=&2x^{-3}&:&f''(1)&=&2\\
				f^{(3)}(x)&=&-6x^{-4}&:&f^{(3)}(1)&=&-6\\
				f^{(4)}(x)&=&24x^{-5}&:&f^{(4)}(1)&=&24\\
				f^{(n)}(x)&=&(-1)^nn!x^{-(n+1)}
			\end{array}
			\]

			Donc, $f(x) = 1 - (x-1) + \dfrac{2}{2!}(x-1)^2 - \dfrac{6}{3!}(x-1)^3 + \dfrac{24}{4!}(x-1)^4 + \dotsb + (-1)^n(x-1)^n + \dotsb + R_n(1, x)$.

			On a
			\begin{align*}
				R&= \dlim{n}{\infty}{\abs{\dfrac{a_n}{a_{n+1}}}}\\
				&= \dlim{n}{\infty}{\abs{\dfrac{(-1)^n}{(-1)^{n+1}}}}\\
				&= 1
			\end{align*}

			Il y a donc convergence sur $]0,2[$.
			\begin{align*}
				\abs{R_n(1, x)}&= \abs{\dint{1}{x}{\dfrac{f^{(n+1)}(t)}{n!}(x-t)^n dt}}\\
				&= \abs{\dint{1}{x}{\dfrac{(-1)^{n+1}(n+1)!t^{-(n+2)}}{n!}(x-t)^n dt}}\\
				&\lte \dint{1}{x}{\abs{(n+1)t^{-(n+2)}\abs{x-t}^n dt}}\\
				&\lte (n+1) \dint{1}{x}{\abs{x-t}^n dt}\\
				&= \left. \abs{x-t}^{n+1} \right|_1^x\\
				&= \abs{x-1}^{n+1}\\
				\text{\footnotesize car $x \in ]0,2[$}&\xrightarrow{n \to \infty} 0
			\end{align*}

			Donc, $\dfrac{1}{x} = \dsum{k}{0}{\infty}{(-1)^k(x-1)^k}$.
		\end{enumerate}
	\end{exem}

	\chapter{Int\'egrales avec param\`etres}
	\begin{align*}
		\mathscr{L}\{t^n\}(s)&= \dint{0}{\infty}{t^ne^{-st} dt} = \dfrac{n!}{s^{n+1}}\\
		\mathscr{L}\{t^2\}(s)&= \dfrac{2}{s^3}\\
		\mathscr{L}\{t^3\}(s)&= \dfrac{6}{s^4}
	\end{align*}

	\section{Fonction Gamma}
	\begin{defin}~

		$\Gamma(y) = \dint{0}{\infty}{t^{y-1}e^{-t} dt}$, pour $y>0$.
	\end{defin}
	\begin{prop}~

		$\Gamma(y)$ converge pour tout $y>0$.
		\begin{proof}~

			\begin{enumerate}
				\item $y \gte 1$.

				On a donc $y-1 \gte 0$ et c'est une int\'egrale impropre de premi\`ere esp\`ece.

				On utilise le test de comparaison limite.

				Posons $f(t) = t^{y-1}e^{-t}$ et $g(t) = e^{\sfrac{-t}{2}}$.

				On a
				\begin{align*}
					C&= \dlim{t}{\infty}{\dfrac{f(t)}{g(t)}}\\
					&= \dlim{t}{\infty}{\dfrac{t^{y-1}e^{-t}}{e^{\sfrac{-t}{2}}}}\\
					&= \dlim{t}{\infty}{\dfrac{t^{y-1}}{e^{\sfrac{t}{2}}}}\\
					&\overset{H}{=} \dlim{t}{\infty}{\dfrac{(y-1)t^{y-2}}{\frac{1}{2}e^{\sfrac{t}{2}}}}\\
					&\overset{H}{=} \dlim{t}{\infty}{\dfrac{(y-1)(y-2)t^{y-3}}{\left(\frac{1}{2}\right)^2e^{\sfrac{t}{2}}}}\\
					&\overset{H}{=} \dotsb\\
					&\overset{H}{=} \dlim{t}{\infty}{\dfrac{(y-1)(y-2)\dotsb(y-k)}{\left(\frac{1}{2}^ke^{\sfrac{t}{2}}\right)t^{k-y}}}&\text{avec }y-k&<0\\
					&= 0
				\end{align*}

				Or, $\dint{0}{\infty}{g(t) dt} = \dint{0}{\infty}{e^{-\sfrac{t}{2}} dt} = \dotsb = 2$.

				Comme $\int g$ converge, on a $\int f$ converge.

				Donc, $\Gamma(y)$ converge si $y \gte 1$.
				\item $0<y<1$.

				On a $\Gamma(y) = \underbrace{\dint{0}{1}{t^{y-1}e^{-t} dt}}_{\text{2\textsuperscript{\`eme} esp}} + \underbrace{\dint{1}{\infty}{t^{y-1}e^{-t} dt}}_{\text{1\textsuperscript{\`ere} esp}}$.

				On obtient
				\begin{align*}
					\dint{0}{1}{t^{y-1}e^{-t} dt}&\lte \dint{0}{1}{t^{y-1} dt}\\
					&= \dlim{h}{0^+}{\dint{h}{1}{t^{y-1} dt}}\\
					&= \dlim{h}{0^+}{\left. \dfrac{t^y}{y} \right|_{t=h}^1}\\
					&= \dfrac{1}{y}
				\end{align*}

				La 2\textsuperscript{\`eme} int\'egrale s'obtient comme au 1\textsuperscript{er} cas.
			\end{enumerate}
		\end{proof}
	\end{prop}
	\begin{prop}~

		\begin{enumerate}[label=\alph*)]
			\item $\Gamma(1)=1$;
			\item $\Gamma(y)=(y-1) \Gamma(y-1)$, si $y>1$;
			\item $\Gamma(y)=(y-1)(y-2)\dotsb(y-k) \Gamma(y-k)$, si $y>k$;
			\item $\Gamma(n+1)=n!$, si $n \in \naturels$;
			\item $\Gamma(\sfrac{1}{2})=\sqrt{\pi}$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\alph*)]
				\item \begin{align*}
					\Gamma(1)&= \dint{0}{\infty}{t^{1-1}e^{-t} dt}\\
					&= \left. -e^{-t} \right|_{t=0}^\infty\\
					&= 1
				\end{align*}
				\item Posons $u=t^{y-1}$, $du=(y-1)t{y-2}$, $dv=e^{-t}dt$, $v=-e^{-t}$.

				\begin{align*}
					\Gamma(y)&= \left. -t^{y-1}e^{-t} \right|_{t=0}^\infty + (y-1) \dint{0}{\infty}{t^{y-2}e^{-t} dt}\\
					&= -\dlim{t}{\infty}{\dfrac{t^{y-1}}{e^t}} + (y-1)\Gamma(y-1)\\
					&= (y-1)\Gamma(y-1)
				\end{align*}
				\item r\'ecurrence du b)
				\item suit de c) et a)
				\item \begin{align*}
					\Gamma(\sfrac{1}{2})&= \dint{0}{\infty}{t^{-\sfrac{1}{2}}e^{-t} dt}\\
					\left.\begin{array}{l}
						t=x^2\\
						dt=2xdx
					\end{array}\right\}&= \dint{0}{\infty}{(x^2)^{-\sfrac{1}{2}}e^{-x^2} 2xdx}\\
					&= 2 \dint{0}{\infty}{e^{-x^2} dx}\\
					\left.\begin{array}{l}
						X \sim N(\mu, \sigma^2)\\
						f_X(x)=\dfrac{1}{\sigma\sqrt{2\pi}}e^{\frac{-(x-\mu)^2}{2\sigma^2}}
					\end{array}\right\}&= 2\sqrt{\pi} \mathbb{P}(X>0)&\text{lorsque } X \sim N(0, \sfrac{1}{2})\\
					&= \sqrt{\pi}
				\end{align*}
			\end{enumerate}
		\end{proof}
	\end{prop}
	\begin{rema}[Utilit\'e]~

		\begin{enumerate}[label=\alph*)]
			\item $\Gamma(\alpha, \lambda)$: $f(x) = \dfrac{\lambda e^{-\lambda x} (\lambda x)^{\alpha-1}}{\Gamma(\alpha)}$, $x \gte 0$;
			\item $\chi^2_n$: $f(x) = \dfrac{1}{2^{\sfrac{n}{2}} \Gamma(\sfrac{n}{2})} \chi^{\frac{n}{2}-1} e^{-\sfrac{x}{2}}$;
			\item Transform\'ee de Laplace: $\mathscr{L}\{t^n\}(s) = \dint{0}{\infty}{t^n e^{-st} dt} = \dfrac{\Gamma(n+1)}{s^{n+1}}$, $s>0, n>-1$;
			\item Une compagnie d'assurance a $240~000$ clients.

			Soit $N(t)$ le nombre de d\'ec\`es jusqu'au temps $t$.

			Supposons que le taux de mortalit\'e annuelle est $\sfrac{1}{10~000}$.

			Supposons
			\begin{enumerate}[label=\roman*)]
				\item $N(0)=0$;
				\item $N(t+s)-N(s) \sim P(\lambda t)$, $(\forall s,t \gte 0) (\forall\lambda>0)$;
				\item $N(b_2)-N(a_2)$ est ind\'ependant de $N(b_1)-N(a_1)$ lorsque $[a_1,b_1] \cap [a_2,b_2] = \emptyset$.
			\end{enumerate}

			On dit que $N(t)$ est un \emph{processus de Poisson} d'intensit\'e $\lambda$.

			On a $N(t)-N(0) = N(t) \sim P(\lambda t)$ et $E[N(t)] = \lambda t$, d'o\`u $E\left[\frac{N(t)}{t}\right]=\lambda$.

			Donc $\lambda$ est le nombre moyen d'\'ev\'enements sur une p\'eriode donn\'ee. Ainsi, $\lambda=\frac{240~000}{10~000} = 24$.

			Soit $T_1$ le temps avant un 1\textsuperscript{er} d\'ec\`es.

			On a
			\begin{align*}
				F_{T_1}&= \mathbb{P}(T_1 \lte t)\\
				&= 1 - \mathbb{P}(T_1 > t)\\
				&= 1-\mathbb{P}(N(t)=0)\\
				&= 1-\mathbb{P}(P(\lambda t)=0)\\
				&= 1-\dfrac{e^{-\lambda t}(\lambda t)^0}{0!}\\
				&= 1-e^{-\lambda t}
			\end{align*}

			On en d\'eduit que $f_{T_1} = \dfrac{d}{dt}F_{T_1} = \lambda e^{-\lambda t}$.

			Ainsi, $T_1 \sim \exp(\lambda)$.

			De m\^eme, si $T_i$ d\'esigne le temps entre le $(i-1)$\textsuperscript{\`eme} d\'ec\`es et le $i$\textsuperscript{\`eme} d\'ec\`es, on peut montrer que $\{T_i\}$ sont iid $\exp(\lambda)$.

			On cherche \`a trouver le temps moyen pour avoir $4$ d\'ec\`es \`a partir d'un moment donn\'e.
			\begin{align*}
				E\left[T_{i_0} + T_{i_0+1} + T_{i_0+2} + T_{i_0+3}\right]&= E\left[\Gamma(4, 24)\right]\\
				&= \frac{4}{24} = \frac{2}{12}
			\end{align*}

			Il faut donc en moyenne $2$ mois pour avoir $4$ d\'ec\`es.
			\item $\dint{0}{\infty}{x^5e^{-3x}dx}$.

			Posons $t=3x$, $dt=3dx$, alors
			\begin{align*}
				\dint{0}{\infty}{x^5e^{-3x}dx}&= \dint{0}{\infty}{\left(\dfrac{t}{3}\right)^5e^{-t} \frac{dt}{3}}\\
				&= \dfrac{1}{3^6} \dint{0}{\infty}{t^5e^{-t}dt}\\
				&= \dfrac{\Gamma(6)}{3^6}\\
				&= \dfrac{5!}{3^6}
			\end{align*}
		\end{enumerate}
	\end{rema}

	\section{Fonction B\^eta}
	\begin{defin}
		\begin{equation*}
			\begin{array}{rcl}
				\beta: \reels_*^+ \times \reels_*^+ &\to& \reels\\
				(m,n) &\mapsto& \beta(m,n) = \dint{0}{1}{t^{m-1}(1-t)^{n-1} dt}
			\end{array}
		\end{equation*}
	\end{defin}
	\begin{prop}~

		$\beta(m,n)$ converge $(\forall m,n > 0)$.
		\begin{proof}~

			Si $m,n \gte 1$, c'est une int\'egrale d\'efinie.

			Si $0<m<1$ et $n \gte 1$, alors
			\begin{align*}
				\dint{0}{1}{t^{m-1}(1-t)^{n-1}dt}&= \dint{0}{1}{\dfrac{(1-t)^{n-1}}{t^{1-m}} dt}\\
				&= \dlim{y}{0^+}{\dint{y}{1}{\dfrac{(1-t)^{n-1}}{t^{1-m}} dt}}\\
				&\lte \dlim{y}{0^+}{\dint{y}{1}{\dfrac{1}{t^{1-m}} dt}}\\
				&= \dlim{y}{0^+}{\left. \dfrac{t^m}{m} \right|_{t=y}^1}\\
				&= \dfrac{1}{m} - \dlim{y}{0^+}{\dfrac{y^m}{m}}\\
				&=\dfrac{1}{m}
			\end{align*}

			Si $m \gte 1$ et $0<n<1$, alors
			\begin{align*}
				\dint{0}{1}{t^{m-1}(1-t)^{n-1}dt}&= \dint{0}{1}{\dfrac{t^{m-1}}{(1-t)^{1-n}} dt}\\
				&= \dlim{y}{1^-}{\dint{0}{y}{\dfrac{t^{m-1}}{(1-t)^{1-n}} dt}}\\
				&\lte \dlim{y}{1^-}{\dint{0}{y}{\dfrac{1}{(1-t)^{1-n}} dt}}\\
				&= \dlim{y}{1^-}{\left. \dfrac{-(1-t)^n}{n} \right|_{t=0}^y}\\
				&= \dlim{y}{1^-}{\dfrac{-(1-y)^n}{n}} + \dfrac{1}{n}\\
				&= \dfrac{1}{n}
			\end{align*}

			Si $0<m,n<1$, alors
			\begin{align*}
				\dint{0}{1}{t^{m-1}(1-t)^{n-1} dt}&= \dint{0}{\sfrac{1}{2}}{\dfrac{(1-t)^{n-1}}{t^{1-m}} dt} + \dint{\sfrac{1}{2}}{1}{\dfrac{t^{m-1}}{(1-t)^{1-n}} dt}
			\end{align*}

			On fait comme les deux cas pr\'ec\'edents.%TODO finir la preuve
		\end{proof}
	\end{prop}
	\begin{prop}
		$\beta(m,n) = \beta(n,m)$.
		\renewcommand{\qedsymbol}{\#}
		\begin{proof}[Id\'ee de la d\'emonstration]
			On effectue le changement de variables $s=1-t$, donc $t=1-s$ et $ds=dt$. On a donc que les r\^oles de $m$ et $n$ sont invers\'es.
		\end{proof}
		\renewcommand{\qedsymbol}{$\square$}
	\end{prop}
	\begin{prop}
		\begin{equation*}
			\beta(m,n) = \dfrac{\Gamma(m)\Gamma(n)}{\Gamma(m+n)}
		\end{equation*}
		\begin{proof}~

			On a
			\begin{align*}
				\Gamma(m)\Gamma(n)&= \left( \dint{0}{\infty}{t^{m-1}e^{-t} dt} \right) \left( \dint{0}{\infty}{s^{n-1}e^{-s} ds} \right)\\
				\left.\begin{matrix}
					\text{posons } t=x^2, s=y^2\\
					\text{donc } 2xdx, ds=2ydy
				\end{matrix}\right\}&= \left( \dint{0}{\infty}{x^{2m-2}e^{-x^2} 2xdx} \right) \left( \dint{0}{\infty}{y^{2n-2}e^{-y^2} 2ydy} \right)\\
				&= 4 \dint{0}{\infty}{\dint{0}{\infty}{x^{2m-1}y^{2n-1} e^{-(x^2+y^2)} dxdy}}\\
				\left.\begin{matrix}
					\text{posons } x=r\cos\theta, y=r\sin\theta\\
					\text{donc } dxdy=rdrd\theta
				\end{matrix}\right\}&= 4 \dint{0}{\sfrac{\pi}{2}}{\dint{0}{\infty}{r^{2m-1}\cos^{2m-1}\theta r^{2n-1}\sin^{2n-1}\theta e^{-r^2} rdrd\theta}}\\
				&= 4 \dint{0}{\sfrac{\pi}{2}}{\cos^{2m-1}\theta \sin^{2n-1}\theta d\theta} \dint{0}{\infty}{r^{2(m+n)-1} e^{-r^2} dr}\\
				&= 4 \dint{0}{\sfrac{\pi}{2}}{\cos^{2m-2}\theta \sin^{2n-2}}\theta \dfrac{2\cos\theta \sin\theta d\theta}{2} \dint{0}{\infty}{r^{2(m+n-1)} e^{-r^2} \dfrac{2rdr}{2}}\\
				\left.\begin{matrix}
					\text{posons } u=\sin^2\theta, v=r^2\\
					\text{donc } du=2\sin\theta\cos\theta d\theta, dv=2rdr
				\end{matrix}\right\}&= \dint{0}{1}{(1-u)^{m-1} u^{n-1} du} \dint{0}{\infty}{v^{m+n-1} e^{-v} dv}\\
				&= \beta(n,m) \Gamma(m+n)\\
				&= \beta(m,n) \Gamma(m+n)
			\end{align*}
		\end{proof}
	\end{prop}
	\begin{exem}~

		\begin{enumerate}[label=\alph*)]
			\item
			\begin{align*}
				\beta\left( \frac{1}{2}, \frac{1}{2} \right)&= \dint{0}{1}{t^{-\sfrac{1}{2}} (1-t)^{-\sfrac{1}{2}} dt}\\
				\left.\begin{matrix}
					\text{posons } t=\sin^2\theta\\
					\text{donc } dt=2\sin\theta \cos\theta d\theta
				\end{matrix}\right\}&= \dint{0}{\sfrac{\pi}{2}}{\sin^{-1}\theta \cos^{-1}\theta 2\sin\theta\cos\theta d\theta}\\
				&= 2\dint{0}{\sfrac{\pi}{2}}{d\theta}\\
				&= \pi
			\end{align*}

			On a aussi
			\begin{align*}
				\beta(\frac{1}{2}, \frac{1}{2})&= \dfrac{\Gamma(\frac{1}{2}) \Gamma(\frac{1}{2})}{\Gamma(\frac{1}{2} + \frac{1}{2})}\\
				&= \dfrac{\sqrt{\pi}\sqrt{\pi}}{0!}\\
				&= \pi
			\end{align*}
			\item $\dint{0}{a}{x^m\sqrt[n]{a^n-x^n} dx} = \dfrac{a^{m+2}}{n} \beta\left( \frac{m+1}{n}, \frac{n+1}{n} \right)$.

			On a
			\begin{align*}
				\dfrac{a^{m+2}}{n}\beta\left( \frac{m+1}{n}, \frac{n+1}{n} \right)&= \dfrac{a^{m+2}}{n} \dint{0}{1}{t&{\frac{m+1}{n}-1} (1-t)^{\frac{n+1}{n}-1} dt}\\
				&= \dfrac{a^{m+2}}{n} \dint{0}{1}{t^{\frac{m-n+1}{n}} (1-t)^{\sfrac{1}{n}} dt}\\
				\left.\begin{matrix}
					\text{posons } x^n=a^nt\\
					\text{donc } nx^{n-1}dx=a^ndt
				\end{matrix}\right\}&= \dfrac{a^{m+2}}{n} \dint{0}{a}{\left( \left( \frac{x}{a} \right)^n \right)^{\frac{m-n+1}{n}} (1-\frac{x^n}{a^n})^{\sfrac{1}{n}} \frac{nx^{n-1} dx}{a^n}}\\
				&= \dfrac{a^{m+2}}{n} \dint{0}{a}{\dfrac{x^{m-n+1}}{a^{m-n+1}} \dfrac{\sqrt[n]{a^n-x^n}}{a} \dfrac{nx^{n-1}dx}{a_n}}\\
				&= \dint{0}{a}{x^m \sqrt[n]{a^n-x^n} dx}
			\end{align*}

			Ainsi, $\dint{0}{2}{x^4 \sqrt{2^2-x^2} dx}$, on a $a=2, n=2, m=4$.
			\begin{align*}
				\dint{0}{2}{x^4 \sqrt{2^2-x^2} dx}&= \dfrac{2^6}{2} \beta\left( \frac{5}{2}, \frac{3}{2} \right)\\
				&= 2^5 \dfrac{\Gamma\left( \frac{5}{2} \right) \Gamma\left( \frac{3}{2} \right)}{\Gamma(4)}\\
				&= \dfrac{2^5 \cdot \frac{3}{2} \cdot \frac{1}{2} \cdot \sqrt{\pi} \cdot \frac{1}{2} \cdot \sqrt{\pi}}{3!}\\
				&= 2\pi
			\end{align*}
		\end{enumerate}
	\end{exem}
	\begin{rema}[Utilit\'e]~

		\begin{enumerate}[label=\alph*)]
			\item Loi $B(a,b)$ a comme densit\'e $B_{a,b}(x) = \dfrac{x^{a-1}(1-x)^{b-1}}{\beta(a,b)}$ si $0<x<1$.
			\item On tire au hasard $10$ nombres r\'eels dans $[0,1]$.

			On cherche \`a savoir la probabilit\'e que le 2\textsuperscript{e} plus petit soit inf\'erieur \`a $0.2$.

			Soit $\mathcal{U}_{(2)}$ la valeur du 2\textsuperscript{e} plus petit nombre tir\'e.

			Alors, $\mathcal{U}_{(2)} \sim B(k, n+1-k)$, o\`u $n$ est le nombre de valeurs tir\'ees.

			Ici, $\mathcal{U}_{(2)} \sim B(2,9)$. On a
			\begin{equation*}
				\mathbb{P}(\mathcal{U}_{(2)} < 0.2) = \dint{0}{0.2}{\dfrac{x^1(1-x)^8}{\beta(2,9)} dx}
			\end{equation*}

			Or, $\beta(2,9) = \dfrac{\Gamma(2) \Gamma(9)}{\Gamma(11)} = \dfrac{1!8!}{10!} = \dfrac{1}{90}$.

			La probabilit\'e cherch\'ee est
			\begin{equation*}
				\dint{0}{0.2}{90x(1-x)^8 dx} \approx 72.42\%
			\end{equation*}
		\end{enumerate}
	\end{rema}

	\chapter{S\'eries de Fourier}
	\section{D\'efinitions}
	\begin{defin}
		Une fonction $f:\reels\to\reels$ est \emph{p\'eriodique} de \emph{p\'eriode $T$} si $f(t+T)=f(t)$ $(\forall t \in \reels)$.
		\begin{exem}~

			$f(t)=\cos 5 \pi t$ est p\'eriodique.
			\begin{equation*}
				\cos 5\pi t = f(t) = f(t+T) = \cos 5\pi (t+T)
			\end{equation*}
			\begin{equation*}
				\cos(5\pi t+2k\pi) = \cos(5\pi t+5\pi T)
			\end{equation*}

			Si on prend $2k\pi=5\pi T$, l'\'equation est v\'erifi\'ee, c'est-\`a-dire $T=\frac{2k\pi}{5\pi} = \frac{2}{5}k$.

			Ainsi, $\cos 5\pi t$ est p\'eriodique de p\'eriode $\frac{2}{5}$.
		\end{exem}
	\end{defin}
	\begin{prop}
		$f,g$ p\'eriodiques de p\'eriode $T$. Alors, $f+g$ est p\'eriodique de p\'eriode $T$.
		\begin{proof}~

			\begin{align*}
				(f+g)(t+T)&= f(t+T)+g(t+T)\\
				&= f(t)+g(t)\\
				&= (f+g)(t)
			\end{align*}
		\end{proof}
	\end{prop}
	\begin{prop}
		$f(t) = a_1\cos\omega_1t + a_2\cos\omega_2t$ est p\'eriodique de p\'eriode $T$ si, et seulement si, $\exists m_1,m_2 \in \entiers$ t.q. $\omega_1T = 2\pi m_1$ et $\omega_2T = 2\pi m_2$. Alors, $\dfrac{\omega_1}{\omega_2} = \dfrac{m_1}{m_2} \in \rationels$ et $\omega_1=\dfrac{2\pi m_1}{T}, \omega_2=\dfrac{2\pi m_2}{T}$.
		\begin{proof}~

			\begin{itemize}
				\item[$(\Leftarrow)$]
				\begin{align*}
					f(t+T)&= a_1\cos\omega_1(t+T) + a_2\cos\omega_2(t+T)\\
					&= a_1\cos\omega_1t\cos\omega_1T - a_1\sin\omega_1t\sin\omega_1T + a_2\cos\omega_2t\cos\omega_2T - a_2\sin\omega_2t\sin\omega_2T\\
					&= a_1\cos\omega_1t+a_2\cos\omega_2t\\
					&= f(t)
				\end{align*}
				\item[$(\Rightarrow)$] Supposons $\omega_1 \neq \omega_2$.

				On veut montrer que $\cos\omega_1t$ et $\cos\omega_2t$ sont lin\'eairement ind\'ependantes.

				Soient $c_1, c_2$ t.q. $c_1\cos\omega_1t + c_2\cos\omega_2t = 0$, $(\forall t \in \reels)$.

				On applique $\dfrac{d^2}{dt^2}$: $-c_1\omega_1^2\cos\omega_1t - c_2\omega_2^2\cos\omega_2t = 0$, $(\forall t \in \reels)$.

				En $t=0$, on a
				\[
				\left\{ \begin{array}{rcrcl}
					c_1&+&c_2&=&0\\
					-c_1\omega_1^2&-&c_2\omega_2^2&=&0
				\end{array} \right. \quad\Rightarrow\quad \begin{pmatrix}
					1&1\\
					-\omega_1^2&\omega_2^2
				\end{pmatrix} \begin{pmatrix}
					c_1\\c_2
				\end{pmatrix} = \begin{pmatrix}
					0\\0
				\end{pmatrix}
				\]

				Comme $\det\begin{pmatrix}
					1&1\\
					-\omega_1^2&-\omega_2^2
				\end{pmatrix} \neq 0$, la seule solution est $(c_1,c_2)=(0,0)$.

				Comme $f$ est p\'eriodique de p\'eriode $T$, on a
				\begin{align*}
					a_1\cos\omega_1t+a_2\cos\omega_2t&= f(t)\\
					&= f(t+T)\\
					a_1\cos\omega_1(t+T)+a_2\cos\omega_2(t+T)
				\end{align*}

				Alors,
				\begin{align*}
					a_1\left[ \underbrace{\cos\omega_1(t+T) - \cos\omega_1t}_{g_1(t)} \right] + a_2\left[ \underbrace{\cos\omega_2(t+T) - \cos\omega_2t}_{g_2(t)} \right]&= 0
				\end{align*}

				Or, par $\cos(x+\alpha)-\cos x = -2\sin\left( x+\frac{\alpha}{2} \right)\sin\frac{\alpha}{2}$, on a
				\begin{align*}
					g_1(t) &= -2\sin\left( \omega_1t + \frac{\omega_1T}{2} \right)\sin\frac{\omega_1T}{2}\\
					g_2(t) &= -2\sin\left( \omega_2t + \frac{\omega_2T}{2} \right)\sin\frac{\omega_2T}{2}
				\end{align*}

				Comme les $\sin$ sont ind\'ependants, on en d\'eduit que $g_1$ et $g_2$ le sont aussi.

				Comme $a_1,a_2 \neq 0$, il faut donc que $g_1(t)=g_2(t)=0$.

				Ainsi,
				\begin{align*}
					\cos\omega_1t + \omega_1T&= \cos\omega_1t\\
					\cos\omega_2t + \omega_2T&= \cos\omega_2t
				\end{align*}

				Donc, $\omega_1T = 2\pi m_1$ et $\omega_2T = 2\pi m_2$, pour $m_1, m_2 \in \entiers$.
			\end{itemize}
		\end{proof}
	\end{prop}
	\begin{rema}
		On obtient $\omega_i = \dfrac{2m_i\pi}{T}$, pour $i \in \{1,2\}$.
	\end{rema}
	\begin{prop}~

		$c_1\sin\omega t+c_2\cos\omega t = B\cos(\omega t+\phi)$, pour des constantes $B$ et $\phi$.
		\begin{proof}~

			Prenons $\theta = \arctan\frac{c_2}{c_1}$.

			On a $\tan\theta = \frac{c_2}{c_1}$ et
			\begin{align*}
				\sin^2\theta + \cos^2\theta = 1 &\Rightarrow \tan^1\theta + 1 = \dfrac{1}{\cos^2\theta}\\
				&\Rightarrow \dfrac{c_2^2}{c_1^2} + 1 = \dfrac{1}{\cos^2\theta}\\
				&\Rightarrow \cos\theta = \dfrac{c_1}{\sqrt{c_1^2+c_2^2}}
			\end{align*}

			et
			\begin{equation*}
				\sin\theta = \dfrac{c_2}{\sqrt{c_1^2+c_2^2}}
			\end{equation*}

			Posons $B=-\sqrt{c_1^2+c_2^2}$ et $\phi = \theta+\frac{\pi}{2}$.

			On obtient
			\begin{align*}
				B\cos(\omega t+\phi)&= B\cos\omega t\cos\phi - B\sin\omega t\sin\phi\\
				&= B\cos\omega t(-\sin\theta) - B\sin\omega t\cos\theta\\
				&= \sqrt{c_1^2+c_2^2}\cos\omega t\dfrac{c_2}{\sqrt{c_1^2+c_2^2}} + \sqrt{c_1^2+c_2^2}\sin\omega t\dfrac{c_1}{\sqrt{c_1^2+c_2^2}}\\
				&= c_1\sin\omega t+c_2\cos\omega t
			\end{align*}
		\end{proof}
	\end{prop}
	\begin{defin}~

		\begin{enumerate}[label=\alph*)]
			\item Un \emph{polyn\^ome trigonom\'etrique} est une somme de la forme
			\begin{equation*}
				\dsum{k}{0}{n}{\left[ a_k\cos\dfrac{2k\pi}{T}t + b_k\sin\dfrac{2k\pi}{T}t \right]}
			\end{equation*}
			\item Lorsque $n=\infty$, c'est une \emph{s\'erie trigonom\'etrique}.
		\end{enumerate}
	\end{defin}
	\begin{prop}
		Tout polyn\^ome trigonom\'etrique est $T$-p\'eriodique.
	\end{prop}
	\begin{prop}
		Si une s\'erie trigonom\'etrique converge $(\forall x)$, alors sa somme est $T$-p\'eriodique.
	\end{prop}
	\begin{rema}
		Si $f$ n'est pas p\'eriodique, alors $f$ ne pourra pas \^etre la somme d'une s\'erie trigonom\'etrique.
	\end{rema}
	\begin{defin}
		Soient $f:[a,b] \to \reels$ t.q. $f(a)=f(b)$ et $T=b-a$. L'\emph{extension $T$-p\'eriodique de $f$} est
		\begin{equation*}
			\begin{array}{rcl}
				\tilde{f}:\reels&\to&\reels\\
				x&\mapsto&\left\{ \begin{array}{lcll}
					f(x)&\text{si}&x \in [a,b]\\
					f(x-nT)&\text{si}&x \in [a+nT, b+nT]&\text{pour un } n \in \entiers
				\end{array} \right.
			\end{array}
		\end{equation*}
	\end{defin}
	\begin{exem}~

		$f(t) = \abs{t}$, sur $[-3,3]$.
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}[x=7mm,y=5mm]
				\draw[->] (-3.2,0) -- (3.2,0) node[right] {$x$};
				\draw[->] (0,-.1) -- (0,3.2) node[above] {$y$};
				\draw plot[domain=-3:3] (\x,{abs(\x)});
				\draw (-3,.1) -- (-3,-.2) node[below] {$-3$};
				\draw (3,.1) -- (3,-.2) node[below] {$3$};
			\end{tikzpicture}
			\caption{$f$ sur $[-3,3]$}
		\end{figure}

		L'extension $6$-p\'eriodique de $f$ est
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}[x=7mm,y=5mm]
				\draw[->] (-9.2,0) -- (9.2,0) node[right] {$x$};
				\draw[->] (0,-.1) -- (0,3.2) node[above] {$y$};
				\draw[dashed,xshift=-42mm] plot[domain=-3:3] (\x,{abs(\x)});
				\draw plot[domain=-3:3] (\x,{abs(\x)});
				\draw[dashed,xshift=42mm] plot[domain=-3:3] (\x,{abs(\x)});
				\draw (-3,.1) -- (-3,-.2) node[below] {$-3$};
				\draw (3,.1) -- (3,-.2) node[below] {$3$};
				\draw (-9,.1) -- (-9,-.2) node[below] {$-9$};
				\draw (9,.1) -- (9,-.2) node[below] {$9$};
			\end{tikzpicture}
			\caption{$\tilde{f}$ sur $[-9,9]$}
		\end{figure}
	\end{exem}
	\begin{rapp}~

		Soit $E$ un $K$-espace vectoriel.

		Un \emph{produit scalaire} sur $E$ est une fonction
		\begin{equation*}
			\begin{array}{rcl}
				\langle \cdot , \cdot \rangle:E \times E&\to&K\\
				(x,y)&\mapsto&\langle x,y \rangle
			\end{array}
		\end{equation*}
		t.q.
		\begin{enumerate}[label=\roman*)]
			\item $\langle x,x \rangle \gte 0$;

			$\langle x,x \rangle = 0$ si, et seulement si, $x=\vec{0}$;
			\item $\langle a_1x_1+a_2x_2, y \rangle = a_1 \langle x_1,y \rangle + a_2 \langle x_2,y \rangle$;
			\item $\langle x,y \rangle = \overline{\langle y,x \rangle}$.
		\end{enumerate}
	\end{rapp}
	\begin{prop}~

		L'ensemble $E=\{f:[-\pi,\pi]\to\reels \mid f \text{ continue}\}$ est un $\reels$-espace vectoriel et
		\begin{equation*}
			\langle f,g \rangle = \dint{-\pi}{\pi}{f(t)g(t) dt}
		\end{equation*}
		est un produit scalaire sur $E$.
	\end{prop}
	\begin{defin}
		La norme de $x \in E$ est
		\begin{equation*}
			\norme{x} = \sqrt{\langle x,x \rangle}
		\end{equation*}
	\end{defin}
	\begin{rema}
		Si on prend $T=2\pi$, le polyn\^ome trigonom\'etrique s'\'ecrit
		\begin{equation*}
			\dsum{k}{0}{n}{\left[ a_k\cos kt + b_k\sin kt \right]} = a_0 + \dsum{k}{1}{n}{\left[ a_k\cos kt + b_k\sin kt \right]}
		\end{equation*}
	\end{rema}
	\begin{prop}
		$\{1, \cos kt, \sin kt \mid k \gte 1\}$ est une famille de fonctions orthogonales.
		\begin{proof}~

			\begin{align*}
				\begin{split}
					\langle \cos nt, \sin mt \rangle&= \dint{-\pi}{\pi}{\underbrace{\overbrace{(\cos nt)}^{\text{paire}}\overbrace{(\sin mt)}^{\text{impaire}}}_{\text{impaire}} dt}\\
					&= 0
				\end{split}
				\\[1em]
				\begin{split}
					\langle \cos nt, \cos mt \rangle&= \dint{-\pi}{\pi}{(\cos nt)(\cos mt) dt}\\
					&= 0
				\end{split}
				\\[1em]
				\begin{split}
					\langle \sin nt, \sin mt \rangle&= \dint{-\pi}{\pi}{(\sin nt)(\sin mt) dt}\\
					&= 0
				\end{split}
			\end{align*}
		\end{proof}
	\end{prop}
	\begin{coro}~

		$\mathcal{B} = \left\{ \dfrac{1}{\sqrt{2\pi}}, \dfrac{\cos nx}{\sqrt{\pi}}, \dfrac{\sin mx}{\sqrt{\pi}} ~\middle|~ m,n \gte 1 \right\}$ est un ensemble de fonctions orthonormales.
		\begin{proof}~

			\begin{align*}
				\begin{split}
					\norme{1}&= \sqrt{\langle 1,1 \rangle}\\
					&= \sqrt{\dint{-\pi}{\pi}{dt}}\\
					&= \sqrt{2\pi}
				\end{split}
				&
				\begin{split}
					\Rightarrow\norme{\dfrac{1}{\sqrt{2\pi}}}&= \abs{\dfrac{1}{\sqrt{2\pi}}} \norme{1}\\
					&= \abs{\dfrac{1}{\sqrt{2\pi}}} \sqrt{2\pi}\\
					&= 1
				\end{split}
				\\[1em]
				\begin{split}
					\norme{\cos nx}&= \sqrt{\langle \cos nx, \cos nx \rangle}\\
					&= \sqrt{\dint{-\pi}{\pi}{(\cos nx)(\cos nx)} dx}\\
					&= \sqrt{\pi}
				\end{split}
				&
				\begin{split}
					\norme{\sin mx}&= \sqrt{\langle \sin mx, \sin mx \rangle}\\
					&= \sqrt{\dint{-\pi}{\pi}{(\sin mx)(\sin mx)} dx}\\
					&= \sqrt{\pi}
				\end{split}
			\end{align*}
		\end{proof}
	\end{coro}
	\begin{coro}~

		$\mathcal{B} = \left\{ \dfrac{1}{\sqrt{2\pi}}, \dfrac{\cos nx}{\sqrt{\pi}}, \dfrac{\sin mx}{\sqrt{\pi}} ~\middle|~ m,n \gte 1 \right\}$ est un ensemble lin\'eairement ind\'ependant.
	\end{coro}
	\begin{prop}~

		Si $f(x) = a_0 + \dsum{k}{1}{n}{a_k\cos kx} + \dsum{k}{1}{n}{b_k\sin kx}$, alors
		\begin{enumerate}[label=\roman*)]
			\item $a_0 = \dfrac{1}{2\pi} \dint{-\pi}{\pi}{f(t) dt}$;
			\item $a_k = \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t)\cos kt dt}$;
			\item $b_k = \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t)\sin kt dt}$.
		\end{enumerate}
		\begin{proof}~

			\begin{enumerate}[label=\roman*)]
				\item
				\begin{align*}
					\left\langle f, \dfrac{1}{\sqrt{2\pi}} \right\rangle&= \left\langle a_0 + \dsum{k}{1}{n}{a_k \cos kx} + \dsum{k}{1}{n}{b_k \sin kx}, \dfrac{1}{\sqrt{2\pi}} \right\rangle\\
					&= \left\langle a_0, \dfrac{1}{\sqrt{2\pi}} \right\rangle + \dsum{k}{1}{n}{a_k \left\langle \cos kx, \dfrac{1}{\sqrt{2\pi}} \right\rangle} + \dsum{k}{1}{n}{b_k \left\langle \sin kx, \dfrac{1}{2\pi} \right\rangle}\\
					&= a_0 \dfrac{1}{\sqrt{2\pi}} \langle 1,1 \rangle\\
					&= \dfrac{a_0}{\sqrt{2\pi}} 2\pi\\
					&= a_0\sqrt{2\pi}
				\end{align*}

				Ainsi, $a_0 = \dfrac{1}{\sqrt{2\pi}} \left\langle f, \dfrac{1}{\sqrt{2\pi}} \right\rangle = \dfrac{1}{2\pi} \langle f,1 \rangle = \dfrac{1}{2\pi} \dint{-\pi}{\pi}{f(t) dt}$.
				\item
				\begin{align*}
					\left\langle f, \dfrac{\cos nx}{\sqrt{\pi}} \right\rangle&= \left\langle a_0 + \sum{a_k \cos kx} + \sum{b_k \sin kx}, \dfrac{\cos nx}{\sqrt{\pi}} \right\rangle\\
					&= \left\langle a_n \cos nx, \dfrac{\cos nx}{\sqrt{\pi}} \right\rangle\\
					&= \dfrac{a_n}{\sqrt{\pi}} \langle \cos nx, \cos nx \rangle\\
					&= \dfrac{a_n}{\sqrt{\pi}}\pi\\
					&= a_n\sqrt{\pi}
				\end{align*}

				Ainsi, $a_n = \dfrac{1}{\sqrt{\pi}} \left\langle f, \dfrac{\cos nx}{\sqrt{\pi}} \right\rangle = \dfrac{1}{\pi} \langle f,\cos nx \rangle = \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \cos nt dt}$.
				\item idem%TODO
			\end{enumerate}
		\end{proof}
	\end{prop}
	\begin{defin}
		Soit $f:[a,b] \to \reels$ une fonction continue par morceaux. Posons $T=b-a$. La \emph{s\'erie de Fourier $T$-p\'eriodique} de $f$ est
		\begin{equation*}
			S(f) = a_0 + \dsum{k}{1}{\infty}{a_k \cos\dfrac{2k\pi}{T}t} + \dsum{k}{1}{\infty}{b_k \sin\dfrac{2k\pi}{T}t}
		\end{equation*}
		o\`u
		\begin{enumerate}[label=\roman*)]
			\item $a_0 = \dfrac{1}{T} \dint{a}{b}{f(t) dt}$;
			\item $a_k = \dfrac{2}{T} \dint{a}{b}{f(t)\cos \dfrac{2k\pi}{T}t dt}$;
			\item $b_k = \dfrac{2}{T} \dint{a}{b}{f(t)\sin \dfrac{2k\pi}{T}t dt}$.
		\end{enumerate}
	\end{defin}
	\begin{exem}~

		\begin{enumerate}[label=\alph*)]
			\item $f(x) = \abs{x}$ sur $[-\pi,\pi]$. On a $T=2\pi$.
			\begin{align*}
				\begin{split}
					T&= 2\pi
				\end{split}
				&
				\begin{split}
					a_0&= \dfrac{1}{2\pi} \dint{-\pi}{\pi}{f(t) dt}\\
					&= \dfrac{1}{2\pi} \dint{-\pi}{\pi}{\abs{t} dt}\\
					&= \dfrac{1}{\pi} \dint{0}{\pi}{t dt}\\
					&= \dfrac{\pi}{2}
				\end{split}
				&
				\begin{split}
					a_k&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \cos kt dt}\\
					&= \dfrac{2}{\pi} \dint{0}{\pi}{t \cos kt dt}\\
					&= \dotsb\\
					&= \dfrac{2}{k^2\pi}\left[\cos k\pi - 1\right]\\
					&= \left\{ \begin{array}{rll}
						0&\text{si}&k \text{ pair}\\
						\dfrac{-4}{k^2\pi}&\text{si}&k \text{ impair}
					\end{array} \right.
				\end{split}
				&
				\begin{split}
					b_k&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \sin kt dt}\\
					&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{\abs{t} \sin kt dt}\\
					&= 0
				\end{split}
			\end{align*}

			Donc, $S(f) = \dfrac{\pi}{2} - \dfrac{4}{\pi} \cos t - \dfrac{4}{9\pi} \cos 3t - \dfrac{4}{25\pi} \cos 5t - \dotsb = \frac{\pi}{2} - \dfrac{4}{\pi} \dsum{n}{0}{\infty}{\dfrac{\cos(2n+1)t}{(2n+1)^2}}$.

			On a $\abs{\dfrac{\cos(2n+1)t}{(2n+1)^2}} \lte \dfrac{1}{(2n+1)^2} \eqcolon M_n$.

			$\dsum{n}{0}{\infty}{M_n} = \dsum{n}{0}{\infty}{\dfrac{1}{(2n+1)^2}} = \dfrac{\pi}{8}$ converge.

			Du crit\`ere de Weierstrass, $S(f)$ converge uniform\'ement.
			\item $f(t) = \left\{\begin{array}{rll}
				t&\text{si}&0 \lte t <3\\
				f(t-3)&\text{sinon}
			\end{array}\right.$. On a $T=3$ avec $a=0$ et $b=3$.
			\begin{align*}
				\begin{split}
					a_0&= \text{valeur moyenne de $f$ sur $[0,3[$}\\
					&= \dfrac{3}{2}
				\end{split}
				&
				\begin{split}
					a_k&= \dfrac{2}{T} \dint{a}{b}{f(t) \cos \dfrac{2k\pi}{T}t dt}\\
					&= \dfrac{2}{3} \dint{0}{3}{t \cos\dfrac{2k\pi}{3}t dt}\\
					&= 0
				\end{split}
				&
				\begin{split}
					b_k&= \dfrac{2}{T} \dint{a}{b}{f(t) \sin\dfrac{2k\pi}{T}t dt}\\
					&= \dfrac{2}{3} \dint{0}{3}{t \sin\dfrac{2k\pi}{3}t dt}\\
					&= -\dfrac{3}{k\pi}
				\end{split}
			\end{align*}

			Donc, $S(f) = \dfrac{3}{2} + \dsum{k}{1}{\infty}{\dfrac{-3}{k\pi} \sin\dfrac{2k\pi}{3}t}$.
		\end{enumerate}
	\end{exem}

	\section{Convergence}
	\begin{thm}
		Supposons
		\begin{enumerate}[label=\roman*)]
			\item $f:[a,b] \to \reels$ continue par morceaux;
			\item $f'$ existe, sauf peut-\^etre en un nombre fini de points;
			\item $f'$ continue par morceaux.
		\end{enumerate}

		Soit
		\begin{equation*}
			\begin{array}{rcl}
				g:[a,b]&\to&\reels\\
				x&\mapsto&\left\{\begin{array}{rllll}
					f(x)&\text{si}&x \in ]a,b[&\text{et}&\text{$f$ continue en $x$}\\
					\dfrac{f(x^-)+f(x^+)}{2}&\text{si}&x \in ]a,b[&\text{et}&\text{$f$ non continue en $x$}\\
					\dfrac{f(a^+)+f(b^-)}{2}&\text{si}&x=a&\text{ou}&x=b
				\end{array}\right.
			\end{array}
		\end{equation*}
		o\`u $f(x^-) = \dlim{t}{x^-}{f(t)}$ et $f(x^+) = \dlim{t}{x^+}{f(t)}$.

		Alors, la s\'erie de Fourier $T$-p\'eriodique de $f$ converge ponctuellement vers l'extension $T$-p\'eriodique de $g$.
	\end{thm}
	\begin{exem}~

		Soit $\begin{array}{rcl}
			f:[-\pi,\pi]&\to&\reels\\
			x&\mapsto&\left\{\begin{array}{rll}
				-1&\text{si}&-\pi\lte x <0\\
				1&\text{si}&0\lte x \lte\pi
			\end{array}\right.
		\end{array}$. On a $\begin{array}{rcl}
			g:[-\pi,\pi]&\to&\reels\\
			x&\mapsto&\left\{\begin{array}{rll}
				-1&\text{si}&-\pi<x<0\\
				1&\text{si}&0<x<\pi\\
				0&\text{si}&x \in \{-\pi,0,\pi\}
			\end{array}\right\}
		\end{array}$.
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}
				\draw[-{To[length=1.5mm]}] (-3.3,0) -- (3.3,0) node[right] {$x$};
				\draw[-{To[length=1.5mm]}] (0,-1.3) -- (0,1.3) node[above] {$y$};
				\draw (-3,-1) -- (0,-1);
				\draw (0,1) -- (3,1);
				\fill (-3,-1) circle (3pt);
				\fill (0,1) circle (3pt);
				\fill (3,1) circle (3pt);
				\draw (0,-1) circle (3pt);
				\node () at (1.5,.7) {$f$};
				\node[anchor=west, inner sep=5pt] () at (0,-1) {$-1$};
				\node[anchor=east, inner sep=5pt] () at (0,1) {$1$};
				\draw (-3,-.2) -- (-3,.2) node[above] {$-\pi$};
				\draw (3,.2) -- (3,-.2) node[below] {$\pi$};
			\end{tikzpicture}
			\qquad
			\begin{tikzpicture}
				\draw[-{To[length=1.5mm]}] (-3.3,0) -- (3.3,0) node[right] {$x$};
				\draw[-{To[length=1.5mm]}] (0,-1.3) -- (0,1.3) node[above] {$y$};
				\draw (-3,-1) -- (0,-1);
				\draw (0,1) -- (3,1);
				\fill (-3,0) circle(3pt);
				\fill (0,0) circle(3pt);
				\fill (3,0) circle(3pt);
				\draw (-3,-1) circle(3pt);
				\draw (0,-1) circle(3pt);
				\draw (0,1) circle(3pt);
				\draw (3,1) circle(3pt);
				\node () at (1.5,.7) {$g$};
				\node[anchor=south, inner sep=5pt] () at (-3,0) {$-\pi$};
				\node[anchor=north, inner sep=5pt] () at (3,0) {$\pi$};
				\node[anchor=west, inner sep=5pt] () at (0,-1) {$-1$};
				\node[anchor=east, inner sep=5pt] () at (0,1) {$1$};
			\end{tikzpicture}
			\caption{$f$ et $g$}
		\end{figure}

		Calculons $S(f)$. On a
		\begin{align*}
			\begin{split}
				a_0&= \dfrac{1}{2\pi} \dint{-\pi}{-\pi}{f(t) dt}\\
				&= 0
			\end{split}
			&
			\begin{split}
				a_k&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \cos kt dt}\\
				&= 0
			\end{split}
			&
			\begin{split}
				b_k&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \sin kt dt}\\
				&= \dfrac{2}{\pi} \dint{0}{\pi}{\sin kt dt}\\
				&= -\dfrac{2}{\pi} \left.\dfrac{\cos kt}{k}\right|_0^\pi\\
				&= -\dfrac{2}{k\pi}\underbrace{\left(\cos k\pi-1\right)}_{\left\lbrace \begin{array}{rcl}
						0&\text{si}&k\text{ pair}\\
						-2&\text{si}&k\text{ impair}
				\end{array} \right.}
			\end{split}
		\end{align*}

		On obtient
		\begin{align*}
			S(f)&= \underbrace{\dfrac{4}{\pi} \sin t}_{k=1} + \underbrace{\dfrac{4}{3\pi} \sin 3t}_{k=3} + \underbrace{\dfrac{4}{5\pi} \sin 5t}_{k=5} + \dotsb\\
			&= \dfrac{4}{\pi} \dsum{n}{0}{\infty}{\dfrac{\sin(2n+1)t}{2n+1}}
		\end{align*}
		qui converge ponctuellement vers l'extension $2\pi$-p\'eriodique de $g$.

		Comme $\dfrac{\sin(2n+1)t}{2n+1}$ est continue, si la convergence \'etait uniforme, on aurait que l'extension $2\pi$-p\'eriodique de $g$ serait continue. Or, $g$ n'est pas continue et la convergence n'est pas uniforme.

		En $x=\sfrac{\pi}{2}$, on a $f(\sfrac{\pi}{2}) = 1$ et $S(f)(\sfrac{\pi}{2}) = \dfrac{4}{\pi} \dsum{n}{0}{\infty}{\dfrac{\sin(2n+1)\frac{\pi}{2}}{2n+1}} = \dfrac{4}{\pi} \dsum{n}{0}{\infty}{\dfrac{(-1)^n}{2n+1}}$.

		Comme $f$ est continue en $x=\sfrac{\pi}{2}$, on a $g(\sfrac{\pi}{2})=1$ et on obtient $1 = \dfrac{4}{\pi} \dsum{n}{0}{\infty}{\dfrac{(-1)^n}{2n+1}}$, d'o\`u $\dsum{n}{0}{\infty}{\dfrac{(-1)^n}{2n+1}} = \dfrac{\pi}{4}$.
	\end{exem}
	\begin{prop}~

		Si une s\'erie trigonom\'etrique
		\begin{equation*}
			a_0 + \dsum{k}{1}{\infty}{\left( a_k \cos\dfrac{2k\pi}{T}t + b_k \sin\dfrac{2k\pi}{T}t \right)}\tag{$*$}
		\end{equation*}
		converge uniform\'ement vers, disons, $f$, alors la s\'erie de Fourier de $f$ est $(*)$, c'est-\`a-dire, $S(f) = (*)$.
		\begin{proof}~

			Supposons $f(t) = \alpha_0 + \dsum{k}{1}{\infty}{\left(\alpha_k\cos\dfrac{2k\pi}{T}t + \beta_k\sin\dfrac{2k\pi}{T}t\right)}$.

			On a
			\begin{align*}
				a_0&= \dfrac{1}{T} \dint{a}{b}{f(t) dt}\\
				&= \dfrac{1}{T} \dint{a}{b}{\alpha_0 + \dsum{k}{1}{\infty}{\left(\alpha_k\cos\dfrac{2k\pi}{T}t + \beta_k\sin\dfrac{2k\pi}{T}t\right)} dt}\\
				\shortintertext{comme il y convergence uniforme}
				&= \dfrac{1}{T} \dint{a}{b}{\alpha_0 dt} + \dsum{k}{1}{\infty}{\dfrac{1}{T} \underbrace{\dint{a}{b}{\alpha_k\cos\dfrac{2k\pi}{T}t dt}}_{\langle 1,\cos \rangle}} + \dsum{k}{1}{\infty}{\dfrac{1}{T} \underbrace{\dint{a}{b}{\beta_k\sin\dfrac{2k\pi}{T}t dt}}_{\langle 1,\sin \rangle}}\\
				&= \alpha_0 + \dsum{k}{1}{\infty}{0} + \dsum{k}{1}{\infty}{0}\\
				&= \alpha_0
			\end{align*}

			De m\^eme,
			\begin{align*}
				a_k&= \dfrac{2}{T} \dint{a}{b}{f(t)\cos\dfrac{2k\pi}{T}t dt}\\
				&= \dfrac{2}{T} \dint{a}{b}{\left[ \alpha_0 + \dsum{k}{1}{\infty}{\left(\alpha_k \cos\dfrac{2k\pi}{T}t + \beta_k\sin\dfrac{2k\pi}{T}t\right)} \right] \cos\dfrac{2k\pi}{T}t dt}\\
				\shortintertext{comme il y convergence uniforme}
				&= \dfrac{2}{T} \underbrace{\dint{a}{b}{\alpha_0 \cos\dfrac{2k\pi}{T}t dt}}_{\langle 1,\cos \rangle} + \dsum{j}{1}{\infty}{\dfrac{2}{T} \dint{a}{b}{\alpha_k \cos\dfrac{2j\pi}{T}t \cos\dfrac{2k\pi}{T}t}} + \dsum{j}{1}{\infty}{\dfrac{2}{T} \underbrace{\dint{a}{b}{\beta_k \sin\dfrac{2j\pi}{T}t \cos\dfrac{2k\pi}{T}t}}_{\langle \sin,\cos \rangle}}\\
				&= \dfrac{2}{T} \dint{a}{b}{\alpha_k \left(\cos\dfrac{2k\pi}{T}t\right)^2 dt}\\
				&= \dfrac{2}{T} \dint{a}{b}{\alpha_k \cdot \dfrac{1}{2} \left[\cos\left(\dfrac{4k\pi}{T}t\right) + \cos0\right] dt}\\
				&= \dfrac{\alpha_k}{T} \dint{a}{b}{\cos\dfrac{4k\pi}{T}t dt} + \dfrac{\alpha_k}{T} \dint{a}{b}{dt}\\
				&= 0 + \dfrac{\alpha_k}{T} (b-a)\\
				&= a_k
			\end{align*}

			De m\^eme, $b_k = \beta_k$.
		\end{proof}
	\end{prop}
	\begin{coro}~

		Si deux s\'eries trigonom\'etriques convergent uniform\'ement vers la m\^eme fonction, alors leurs coefficients sont les m\^emes.
	\end{coro}
	\begin{coro}~

		Si $f_1,f_2:[a,b] \to \reels$ sont continues et $S(f_1) = S(f_2)$, alors $f_1=f_2$.
	\end{coro}
	\begin{thm}~

		Soit $f:[a,b] \to \reels$ de classe $C^2$ avec $f(a)=f(b)$. Alors, la s\'erie de Fourier $T$-p\'eriodique de $f$ converge uniform\'ement vers l'extension $T$-p\'eriodique de $f$.
		\begin{proof}~

			Supposons $[a,b]=[\pi,\pi]$.

			Soit $\dsum{k}{0}{\infty}{\left(a_k\cos kt + b_k\sin kt\right)}$ la s\'erie $T$-p\'eriodique de $f$.

			On veut
			\begin{enumerate}[label=\roman*)]
				\item borner $\abs{a_k\cos kt+b_k\sin kt} \lte \dfrac{2M}{k^2}$;
				\item m.q. $\dsum{k}{0}{\infty}{\dfrac{2M}{k^2}}$ converge.
			\end{enumerate}

			Pour i), on veut m.q. $\abs{a_k} \lte \dfrac{M}{k^2}$ et $\abs{b_k} \lte \dfrac{M}{k^2}$. On a
			\begin{align*}
				a_k&= \dfrac{1}{\pi} \dint{-\pi}{\pi}{f(t) \cos kt dt}\\
				\shortintertext{posons $u=f$, $du=f'(t)dt$, $dv=\cos kt dt$, $v=\frac{1}{k}\sin kt$}
				&= \dfrac{1}{\pi} \left[ \left. \dfrac{1}{k} f(t) \sin kt \right|_{-\pi}^{\pi} - \dfrac{1}{k} \dint{-\pi}{\pi}{f'(t) \sin kt dt} \right]\\
				&= -\dfrac{1}{k\pi} \dint{-\pi}{\pi}{f'(t) \sin kt dt}\\
				\shortintertext{posons $u=f'$, $du=f''(t)dt$, $dv=\sin kt dt$, $v=-\frac{1}{k} \cos kt$}
				&= -\dfrac{1}{k\pi} \left[ \left. \dfrac{-1}{k} f'(t) \cos kt \right|_{-\pi}^{\pi} + \dfrac{1}{k} \dint{-\pi}{\pi}{f''(t) \cos kt dt} \right]\\
				&= \dfrac{1}{k^2\pi} \left[ f'(\pi) \underbrace{\cos k\pi}_{(-1)^k} - f'(-\pi) \underbrace{\cos(-k\pi)}_{(-1)^k} \right] - \dfrac{1}{k^2\pi} \dint{-\pi}{\pi}{f''(t) \cos kt dt}\\
				&= \dfrac{(-1)^k}{k^2\pi} (f'(\pi)-f'(-\pi)) - \dfrac{1}{k^2\pi} \dint{-\pi}{\pi}{f''(t) \cos kt dt}\\
				\intertext{ainsi,}
				\abs{a_k}&=\lte \dfrac{1}{k^2\pi} \abs{f'(\pi)-f'(-\pi)} + \dfrac{1}{k^2\pi} \dint{-\pi}{\pi}{\abs{f''(t) dt}}\\
				&\lte \dfrac{1}{k^2\pi} \abs{f'(\pi)-f'(-\pi)} + \dfrac{1}{k^2\pi} \cdot 2\pi \cdot \sup\limits_{t \in [-\pi,\pi]}\abs{f''(t)}\\
				&= \dfrac{1}{k^2} \underbrace{\left[ \dfrac{\abs{f'(\pi)-f'(-\pi)}}{\pi} + 2 \sup \abs{f''(t)} \right]}_{\coloneq M}
			\end{align*}

			Donc, $\abs{a_k} \lte \dfrac{M}{k^2}$.

			De m\^eme, $\abs{b_k} \lte \dfrac{M}{k^2}$.

			Donc, $\abs{a_k\cos kt+b_k\sin kt} \lte \abs{a_k} + \abs{b_k} = \dfrac{2M}{k^2}$.

			Or,
			\begin{align*}
				\dsum{k}{1}{\infty}{\dfrac{2M}{k^2}}&= 2M \dsum{k}{1}{\infty}{\dfrac{1}{k^2}}\\
				&= 2M \dfrac{\pi^2}{6}
			\end{align*}
			qui converge.

			Du crtit\`ere de Weierstrass, $\dsum{k}{0}{\infty}{\left(a_k\cos kt+b_k\sin kt\right)}$ converge uniform\'ement.

			Par unicit\'e de la limite, la s\'erie converge vers l'extension $T$-p\'eriodique de $f$.
		\end{proof}
	\end{thm}

	\section{\'Egalit\'e de Parseval}
	\begin{rapp}~

		$\mathcal{B} = \left\{ \dfrac{1}{\sqrt{2\pi}}, \dfrac{\cos kt}{\sqrt{\pi}}, \dfrac{\sin kt}{\sqrt{\pi}} ~\middle|~ a \lte k \lte n \right\}$ est un ensemble de fonctions orthonormales.

		\'Ecrivons $\mathcal{B} = \{v_1,v_2,\dots,v_{2n+1}\}$.

		Supposons $v \in <\mathcal{B}>$.

		Alors, $v = \dsum{i}{1}{2n+1}{\alpha_iv_i}$ avec $\alpha_i \in \reels$.

		On a
		\begin{align*}
			\langle v, v_i \rangle&= \left\langle \dsum{j}{1}{2n+2}{\alpha_jv_j}, v_i \right\rangle\\
			&= \dsum{j}{1}{2n+1}{\alpha_j \langle v_j, v_i \rangle}\\
			&= \alpha_i \langle v_i, v_i \rangle\\
			&= \alpha_i
		\end{align*}

		Ainsi, $v = \dsum{i}{1}{2n+1}{\alpha_i v_i} = \dsum{i}{1}{2n+1}{\langle v,v_i \rangle v_i}$.

		On trouve
		\begin{align*}
			\langle v,v \rangle&= \left\langle v, \dsum{i}{1}{2n+1}{\langle v,v_i \rangle v_i} \right\rangle\\
			&= \dsum{i}{1}{2n+1}{\langle v,v_i \rangle \langle v,v_i \rangle}\\
			&= \dsum{i}{1}{2n+1}{\langle v,v_i \rangle^2}\\
			\intertext{ainsi,}
			\norme{v}^2 = \langle v,v \rangle&= \dsum{i}{1}{2n+1}{\alpha_1}
		\end{align*}
	\end{rapp}
	\begin{prop}~

		Soit $f(t) = a_0 + \dsum{k}{1}{n}{\left[a_k\cos\dfrac{2k\pi}{T}t + b_k\sin\dfrac{2k\pi}{T}t\right]}$ un polyn\^ome trigonom\'etrique de degr\'e $n$. Alors,
		\begin{align*}
			a_0^2 + \dfrac{1}{2} \dsum{k}{1}{n}{\left(a_k^2+b_k^2\right)}&= \dfrac{1}{T} \dint{a}{b}{(f(t))^2 dt}
		\end{align*}
		\begin{proof}~

			Supposons $[a,b]=[-\pi,\pi]$.

			On a $\langle f,f \rangle = \dsum{j}{1}{2n+1}{\langle f, v_j \rangle^2}$, avec $v_j$ les vecteurs de la base \'enonc\'ee dans le rappel

			Or,
			\begin{enumerate}[label=\alph*)]
				\item
				\begin{align*}
					\left\langle f,\dfrac{1}{\sqrt{2\pi}} \right\rangle^2&= \left(\dint{-\pi}{\pi}{f(t) \dfrac{1}{\sqrt{2\pi}} dt}\right)^2\\
					&= \dfrac{1}{2\pi} \left(\dint{-\pi}{\pi}{f(t) dt}\right)^2\\
					&= \dfrac{1}{2\pi} (2\pi a_0)^2\\
					&= 2\pi a_0^2
				\end{align*}
				\item
				\begin{align*}
					\left\langle f, \dfrac{\cos kt}{\sqrt{\pi}} \right\rangle^2&= \left(\dint{-\pi}{\pi}{f(t) \dfrac{\cos kt}{\sqrt{\pi}} dt}\right)^2\\
					&= \dfrac{1}{\pi} \left(\dint{-\pi}{\pi}{f(t) \cos kt dt}\right)^2\\
					&= \dfrac{1}{\pi} (\pi a_k)^2\\
					&= \pi a_k^2
				\end{align*}
				\item De m\^eme, $\left\langle f, \dfrac{\sin kt}{\sqrt{\pi}} \right\rangle = \pi b_k^2$.
			\end{enumerate}

			Ainsi,
			\begin{align*}
				\dint{a}{b}{f^2(t) dt}&= \langle f,f \rangle\\
				&= \dsum{j}{1}{2n+1}{\langle f,v_j \rangle}\\
				&= 2\pi a_0^2 + \dsum{k}{1}{n}{\left(\pi a_k^2 + \pi b_k^2\right)}\\
				\intertext{donc,}
				\dfrac{1}{T} \dint{a}{b}{f^2(t) dt}&= a_0^2 + \dfrac{1}{2} \dsum{k}{1}{n}{\left( a_k^2 + b_k^2 \right)}
			\end{align*}
		\end{proof}
	\end{prop}
	\begin{defin}~

		Soit $f:[-\pi,\pi] \to \reels$ continue par morceaux.

		Soit $g:[-\pi,\pi] \to \reels$ un polyn\^ome trigonom\'etrique de degr\'e $n$.
		\begin{enumerate}[label=\alph*)]
			\item L'\emph{erreur ponctuelle} (de degr\'e $n$) est $\eps_n(t) = (f-g)(t)$;
			\item L'\emph{erreur quadratique moyenne} est $E_n(t) = \dfrac{1}{2\pi} \dint{-\pi}{\pi}{\eps_n^2(t) dt} = \dfrac{1}{2\pi} \dint{-\pi}{\pi}{(f-g)^2(t) dt} = \dfrac{1}{2\pi} \langle f-g,f-g \rangle = \dfrac{1}{2\pi} \norme{f-g}^2$.

			Dans le cas d'une fonction d\'efinie sur $[a,b]$, on a
			\begin{equation*}%TODO finir
				E_n(t) = \dfrac{1}{T} \dint{a}{b}{\eps_n^2(t) dt} = \dfrac{1}{T} \dint{a}{b}{(f-g)^2(t) dt} = \dfrac{1}{T} \langle f-g,f-g \rangle = \dfrac{1}{T} \norme{f-g}^2
			\end{equation*}
		\end{enumerate}
	\end{defin}
	\begin{thm}~

		$E_n(t)$ est minimale quand $g = S_n(f)(t)$, o\`u $S_n(f)(t)$ est la s\'erie de Fourier de $f$ tronqu\'ee \`a l'ordre $n$, c'est-\`a-dire, $S_n(f)(t) = a_0 + \dsum{k}{1}{n}{\left[a_k\cos\dfrac{2k\pi}{T}t + b_k\sin\dfrac{2k\pi}{T}t\right]}$.
		\begin{proof}~

			Supposons $g(t) = \alpha_0 + \dsum{k}{1}{n}{\left[\alpha_k\cos kt + \beta_k\sin kt\right]}$. On a
			\begin{align*}
				E_n(t)&= \dfrac{1}{2\pi} \dint{-\pi}{\pi}{(f-g)^2(t) dt}\\
				&= \dfrac{1}{2\pi} \langle f-g,f-g \rangle\\
				&= \dfrac{1}{2\pi} \left[\langle f,f \rangle - 2 \langle f,g \rangle + \langle g,g \rangle\right]
			\end{align*}

			De plus,
			\begin{enumerate}[label=\alph*)]
				\item
				\begin{align*}
					\langle f,f \rangle&= \norme{f}^2
				\end{align*}
				\item
				\begin{align*}
					\langle f,g \rangle&= \langle f, \alpha_0 + \dsum{k}{1}{n}{\left[\alpha_k\cos kt + \beta_k\sin kt\right]} \rangle\\
					&= \alpha_0 \langle f,1 \rangle + \dsum{k}{1}{n}{\left[\alpha_k \langle f,\cos kt \rangle + \beta_k \langle f,\sin kt \rangle\right]}\\
					&= \alpha_0 \underbrace{\dint{-\pi}{\pi}{f(t) dt}}_{2\pi a_0} + \dsum{k}{1}{n}{\alpha_k \underbrace{\dint{-\pi}{\pi}{f(t) \cos kt dt}}_{\pi a_k}} + \dsum{k}{1}{n}{\beta_k \underbrace{\dint{-\pi}{\pi}{f(t) \sin kt dt}}_{\pi b_k}}\\
					&= 2\pi \alpha_0 a_0 + \dsum{k}{1}{n}{\pi \alpha_k a_k} + \dsum{k}{1}{n}{\pi \beta_k b_k}
				\end{align*}
				\item
				\begin{align*}
					\langle g,g \rangle&= 2\pi \alpha_0^2 + \pi \dsum{k}{1}{n}{\left(\alpha_k^2 + \beta_k^2\right)}
				\end{align*}
			\end{enumerate}

			On obtient
			\begin{align*}
				E_n(t)&= \dfrac{1}{2\pi} \left[ \norme{f}^2 - 2\left( 2\pi \alpha_0 a_0 + \dsum{k}{1}{n}{\pi \alpha_k a_k} + \dsum{k}{1}{n}{\pi \beta_k b_k} \right) + 2\pi \alpha_0^2 + \pi \dsum{k}{1}{n}{\left(\alpha_k^2 + \beta_k^2\right)} \right]\\
				&= \dfrac{1}{2\pi} \left[ \norme{f}^2 + 2\pi \left( \alpha_0^2 - 2\alpha_0 a_0 \right) + \pi \dsum{k}{1}{n}{\left( \alpha_k^2 - 2\alpha_k a_k \right)} + \pi \dsum{k}{1}{n}{\left( \beta_k^2 - 2\beta_k b_k \right)} \right]\\
				&= \dfrac{1}{2\pi} \left[ \norme{f}^2 + 2\pi \left( [a_0-\alpha_0]^2 - a_0^2 \right) + \pi \dsum{k}{1}{n}{\left( [a_k - \alpha_k]^2 - a_k^2 \right)} + \pi \dsum{k}{1}{n}{\left( [b_k - \beta_k]^2 - b_k^2 \right)} \right]\\
				&= \dfrac{1}{2\pi} \left[ \norme{f}^2 - \pi \left( 2a_0^2 + \dsum{k}{1}{n}{\left[ a_k^2 + b_k^2 \right]} \right) + 2\pi (a_0-\alpha_0)^2 + \pi \dsum{k}{1}{n}{(a_k-\alpha_k)^2} + \pi \dsum{k}{1}{n}{(b_k-\beta_k)^2} \right]
			\end{align*}

			Donc, $E_n(t)$ est minimale si, et seulement si, $a_0 = \alpha_0$, $a_k = \alpha_k$ et $b_k = \beta_k$, pour $k \gte 1$.
		\end{proof}
	\end{thm}
	\begin{coro}
		La valeur minimale de $E_n(t)$ est
		\begin{equation*}
			\dfrac{1}{2\pi} \left[ \norme{f}^2 - \pi \left( 2a_0^2 + \dsum{k}{1}{n}{\left( a_k^2+b_k^2 \right)} \right) \right]
		\end{equation*}
	\end{coro}
	\begin{coro}
		\begin{equation*}
			\dfrac{1}{\pi} \norme{f}^2 \gte 2a_0^2 + \dsum{k}{1}{n}{\left( a_k^2+b_k^2 \right)}
		\end{equation*}
	\end{coro}
	\begin{coro}
		Soient $f$ continue par morceaux et $a_0,a_k,b_k$ les coefficients de la s\'erie de Fourier $S(f)$. Alors,
		\begin{equation*}
			2a_0^2 + \dsum{k}{1}{\infty}{\left( a_k^2+b_k^2 \right)} \lte \dfrac{1}{\pi} \norme{f}^2 < \infty
		\end{equation*}
		\begin{proof}~

			Posons $s_n = 2a_0^2 + \dsum{k}{1}{n}{\left( a_k^2+b_k^2 \right)}$. On a $s_{n+1} = s_n + a_{n+1}^2 + b_{n+1}^2 \gte s_n$.

			Ainsi, $\left(s_n\right)_{n \in \naturels}$ est monotone croissante et born\'ee, donc convergente.
		\end{proof}
	\end{coro}
	\begin{coro}[Lemme de Riemann-Lebesgue]~

		Soit $f:[-\pi,\pi] \to \reels$ continue par morceaux. Alors, $a_k,b_k \to 0$.
		\begin{proof}~

			$\dsum{n}{1}{\infty}{(a_k^2+b_k^2)}$ converge, donc $(a_k^2+b_k^2) \to 0$, donc $a_k,b_k \to 0$.
		\end{proof}
	\end{coro}
\end{document}
